{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2119,
     "status": "ok",
     "timestamp": 1616981753549,
     "user": {
      "displayName": "Shankar Pendse",
      "photoUrl": "",
      "userId": "07611606062666259316"
     },
     "user_tz": -60
    },
    "id": "tl9KfcjsB09Q",
    "outputId": "4cc83b94-4dd8-464a-a58b-0eac92e92a3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1160,
     "status": "ok",
     "timestamp": 1616981755680,
     "user": {
      "displayName": "Shankar Pendse",
      "photoUrl": "",
      "userId": "07611606062666259316"
     },
     "user_tz": -60
    },
    "id": "f1I7TLooA7uG",
    "outputId": "b41134cb-59bb-4f42-8c37-1e42ae42035a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training features  (60000, 784)\n",
      "Shape of test features  (10000, 784)\n",
      "Shape of training labels  (10, 60000)\n",
      "Shape of testing labels  (10, 10000)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "# load the training and test data    \n",
    "(tr_x, tr_y), (te_x, te_y) = fashion_mnist.load_data()\n",
    "\n",
    "# reshape the feature data\n",
    "tr_x = tr_x.reshape(tr_x.shape[0], 784)\n",
    "te_x = te_x.reshape(te_x.shape[0], 784)\n",
    "\n",
    "# noramlise feature data\n",
    "tr_x = tr_x / 255.0\n",
    "te_x = te_x / 255.0\n",
    "\n",
    "print( \"Shape of training features \", tr_x.shape)\n",
    "print( \"Shape of test features \", te_x.shape)\n",
    "\n",
    "\n",
    "# one hot encode the training labels and get the transpose\n",
    "tr_y = np_utils.to_categorical(tr_y,10)\n",
    "tr_y = tr_y.T\n",
    "print (\"Shape of training labels \", tr_y.shape)\n",
    "\n",
    "# one hot encode the test labels and get the transpose\n",
    "te_y = np_utils.to_categorical(te_y,10)\n",
    "te_y = te_y.T\n",
    "print (\"Shape of testing labels \", te_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1043,
     "status": "ok",
     "timestamp": 1616981758314,
     "user": {
      "displayName": "Shankar Pendse",
      "photoUrl": "",
      "userId": "07611606062666259316"
     },
     "user_tz": -60
    },
    "id": "6GEnhF8Ff9CP"
   },
   "outputs": [],
   "source": [
    "# Converting the numpy arrays to tensors\n",
    "tr_x = tf.convert_to_tensor(tr_x, dtype=tf.float64)\n",
    "tr_y = tf.convert_to_tensor(tr_y, dtype=tf.float64)\n",
    "te_x = tf.convert_to_tensor(te_x, dtype=tf.float64)\n",
    "te_y = tf.convert_to_tensor(te_y, dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 472,
     "status": "ok",
     "timestamp": 1616981759342,
     "user": {
      "displayName": "Shankar Pendse",
      "photoUrl": "",
      "userId": "07611606062666259316"
     },
     "user_tz": -60
    },
    "id": "YJfviVH2PKQc"
   },
   "outputs": [],
   "source": [
    "# Implementation of softmax\n",
    "def softmax(previous_activations):\n",
    "    t = tf.cast(tf.exp(previous_activations), tf.float64) # Numerator part of the softmax (exp(x))\n",
    "    pred_probabilities = tf.cast(t / tf.reduce_sum(t, axis = 0), tf.float64) # Summing along the rows (each column represents one data point)\n",
    "    return pred_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 586,
     "status": "ok",
     "timestamp": 1616981762042,
     "user": {
      "displayName": "Shankar Pendse",
      "photoUrl": "",
      "userId": "07611606062666259316"
     },
     "user_tz": -60
    },
    "id": "MPjDkI98ajEx"
   },
   "outputs": [],
   "source": [
    "def forward_pass(data, W1, b1, W2, b2, W3, b3):\n",
    "    # set dropout probability\n",
    "    dropout_prob = 0.5\n",
    "    prob_threshold = 1 - dropout_prob\n",
    "\n",
    "    # Create the dropout matrix which will be of type boolean, then convert it to numerical\n",
    "    dropout_matrix_hidden_layer1 = tf.random.uniform(shape=[W1.shape[0], data.shape[0]]) < prob_threshold\n",
    "    dropout_matrix_hidden_layer1 = tf.cast(dropout_matrix_hidden_layer1, dtype = tf.float64)\n",
    "\n",
    "    # Calculating activations of Layer1\n",
    "    hypothesis_hidden_layer1 = tf.cast(tf.matmul(W1, tf.transpose(data)) + b1, tf.float64)\n",
    "    activations_hidden_layer1 = tf.cast(tf.nn.relu(hypothesis_hidden_layer1), tf.float64)\n",
    "\n",
    "    # Applying the dropout functionality at Layer1 before feeding it to the next layer\n",
    "    activations_hidden_layer1 = tf.multiply(activations_hidden_layer1, dropout_matrix_hidden_layer1)\n",
    "    activations_hidden_layer1 /= prob_threshold\n",
    "\n",
    "    # Calculating activations of Layer2\n",
    "    hypothesis_hidden_layer2 = tf.cast(tf.matmul(W2, activations_hidden_layer1) + b2, tf.float64)\n",
    "    activations_hidden_layer2 = tf.cast(tf.nn.relu(hypothesis_hidden_layer2), tf.float64)\n",
    "\n",
    "    # Calculating class probabilities\n",
    "    hypothesis_output_layer = tf.cast(tf.matmul(W3, activations_hidden_layer2) + b3, tf.float64)\n",
    "    class_probabilities = tf.cast(softmax(hypothesis_output_layer), tf.float64)\n",
    "    \n",
    "    # returning the predictions\n",
    "    return class_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 495,
     "status": "ok",
     "timestamp": 1616981763519,
     "user": {
      "displayName": "Shankar Pendse",
      "photoUrl": "",
      "userId": "07611606062666259316"
     },
     "user_tz": -60
    },
    "id": "oEMpoIi9dcm9"
   },
   "outputs": [],
   "source": [
    "def cross_entropy(_predictions, _true_labels):\n",
    "    # Computing negative log likelihood, adding a small number within the log function to avoid log(0)\n",
    "    loss = tf.cast(tf.reduce_mean(-tf.reduce_sum(_true_labels * tf.math.log(_predictions+1e-7), axis=0)), tf.float64)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 390,
     "status": "ok",
     "timestamp": 1616981764352,
     "user": {
      "displayName": "Shankar Pendse",
      "photoUrl": "",
      "userId": "07611606062666259316"
     },
     "user_tz": -60
    },
    "id": "hPza-0UkfEh0"
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(true_labels, predictions):\n",
    "    predictions = tf.round(predictions) # Rounding off the decimal representation of softmax output to nearest integer(>0.5 to 1 and <0.5 to 0)\n",
    "    \n",
    "    # argmax to get the index of the predicted array, axis = 0 to get the index for each data point prediction\n",
    "    accuracy = tf.cast(accuracy_score(np.argmax(predictions, axis = 0), np.argmax(true_labels, axis = 0)), tf.float64)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 603,
     "status": "ok",
     "timestamp": 1616981765706,
     "user": {
      "displayName": "Shankar Pendse",
      "photoUrl": "",
      "userId": "07611606062666259316"
     },
     "user_tz": -60
    },
    "id": "QaKEsjJKj0Hq"
   },
   "outputs": [],
   "source": [
    "# lists to store the loss and accuracy for train and test data\n",
    "tr_loss = []\n",
    "te_loss = []\n",
    "tr_accuracy = []\n",
    "te_accuracy = []\n",
    "\n",
    "# Function to iterate and update the weigths and bias values using adam optimizer\n",
    "def train(tr_x, W1, b1, W2, b2, W3, b3, tr_y, te_x, te_y):\n",
    "    max_iterations = 1000\n",
    "    adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        # Record the computation\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = forward_pass(tr_x, W1, b1, W2, b2, W3, b3)\n",
    "            train_loss = cross_entropy(predictions, tr_y)\n",
    "\n",
    "        # Calculate the gradients\n",
    "        gradients = tape.gradient(train_loss, [W1, b1, W2, b2, W3, b3])\n",
    "        train_accuracy = calculate_accuracy(tr_y, predictions)\n",
    "\n",
    "        test_predictions = forward_pass(te_x, W1, b1, W2, b2, W3, b3)\n",
    "        test_loss = cross_entropy(test_predictions, te_y)\n",
    "        test_accuracy = calculate_accuracy(te_y, test_predictions)\n",
    "        \n",
    "        tr_loss.append(train_loss)\n",
    "        te_loss.append(test_loss)\n",
    "\n",
    "        tr_accuracy.append(train_accuracy)\n",
    "        te_accuracy.append(test_accuracy)\n",
    "\n",
    "        # update the weights and bias values as per calculated gradients\n",
    "        adam_optimizer.apply_gradients(zip(gradients, [W1, b1, W2, b2, W3, b3]))\n",
    "        \n",
    "        print(\"Iteraions {}: train_loss: {} train_accuracy: {} test_loss: {} test_accuracy: {}\".format(i, train_loss, train_accuracy, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 484,
     "status": "ok",
     "timestamp": 1616981766503,
     "user": {
      "displayName": "Shankar Pendse",
      "photoUrl": "",
      "userId": "07611606062666259316"
     },
     "user_tz": -60
    },
    "id": "ASGYORplX9-K"
   },
   "outputs": [],
   "source": [
    "# Defining the model\n",
    "no_of_features = tr_x.shape[1]\n",
    "no_of_neurons_hidden_layer1 = 300\n",
    "no_of_neurons_hidden_layer2 = 100\n",
    "no_of_output_units = 10\n",
    "\n",
    "# Declaring weights and bias for the NN\n",
    "W1 = tf.Variable(tf.random.normal(shape=(no_of_neurons_hidden_layer1, no_of_features), seed=0, dtype=tf.float64) * 0.01)\n",
    "b1 = tf.Variable([0], dtype=tf.float64)\n",
    "\n",
    "W2 = tf.Variable(tf.random.normal(shape=(no_of_neurons_hidden_layer2, no_of_neurons_hidden_layer1), seed=0, dtype=tf.float64) * 0.01)\n",
    "b2 = tf.Variable([0], dtype=tf.float64)\n",
    "\n",
    "W3 = tf.Variable(tf.random.normal(shape=(no_of_output_units, no_of_neurons_hidden_layer2), seed=0, dtype=tf.float64) * 0.01)\n",
    "b3 = tf.Variable([0], dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is for dropout prob = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 0: train_loss: 2.302551451564751 train_accuracy: 0.1 test_loss: 2.302541590541721 test_accuracy: 0.1\n",
      "Iteraions 1: train_loss: 2.2990545073228663 train_accuracy: 0.1 test_loss: 2.29908482879066 test_accuracy: 0.1\n",
      "Iteraions 2: train_loss: 2.292396926305358 train_accuracy: 0.1 test_loss: 2.2924556218323686 test_accuracy: 0.1\n",
      "Iteraions 3: train_loss: 2.2810110670234534 train_accuracy: 0.1 test_loss: 2.281063747330615 test_accuracy: 0.1\n",
      "Iteraions 4: train_loss: 2.263184059001613 train_accuracy: 0.1 test_loss: 2.263398027280038 test_accuracy: 0.1\n",
      "Iteraions 5: train_loss: 2.237303216806063 train_accuracy: 0.1 test_loss: 2.237598989128144 test_accuracy: 0.1\n",
      "Iteraions 6: train_loss: 2.2021116597679375 train_accuracy: 0.1 test_loss: 2.2024020678809966 test_accuracy: 0.1\n",
      "Iteraions 7: train_loss: 2.1564709286934276 train_accuracy: 0.1 test_loss: 2.156704352626812 test_accuracy: 0.1\n",
      "Iteraions 8: train_loss: 2.100293502718194 train_accuracy: 0.1 test_loss: 2.101102065848616 test_accuracy: 0.1\n",
      "Iteraions 9: train_loss: 2.0344246909576142 train_accuracy: 0.1 test_loss: 2.03532992745147 test_accuracy: 0.1\n",
      "Iteraions 10: train_loss: 1.9605092036793101 train_accuracy: 0.1 test_loss: 1.9619073863029175 test_accuracy: 0.1\n",
      "Iteraions 11: train_loss: 1.8803304072182407 train_accuracy: 0.1 test_loss: 1.8818702506195146 test_accuracy: 0.1\n",
      "Iteraions 12: train_loss: 1.7966371913720596 train_accuracy: 0.10001666666666667 test_loss: 1.7980882159753107 test_accuracy: 0.1\n",
      "Iteraions 13: train_loss: 1.7129892778097875 train_accuracy: 0.10463333333333333 test_loss: 1.714799969979069 test_accuracy: 0.1061\n",
      "Iteraions 14: train_loss: 1.6340125465364255 train_accuracy: 0.1323 test_loss: 1.6359250757321113 test_accuracy: 0.1326\n",
      "Iteraions 15: train_loss: 1.5593782901228983 train_accuracy: 0.15666666666666668 test_loss: 1.562276432092845 test_accuracy: 0.1551\n",
      "Iteraions 16: train_loss: 1.4921343557516957 train_accuracy: 0.17403333333333335 test_loss: 1.4956845475757619 test_accuracy: 0.1725\n",
      "Iteraions 17: train_loss: 1.4303844051174035 train_accuracy: 0.19251666666666667 test_loss: 1.4354690095282712 test_accuracy: 0.1886\n",
      "Iteraions 18: train_loss: 1.3743117232265787 train_accuracy: 0.20043333333333332 test_loss: 1.378298495614373 test_accuracy: 0.2001\n",
      "Iteraions 19: train_loss: 1.3218221307726863 train_accuracy: 0.20221666666666666 test_loss: 1.3281806598397863 test_accuracy: 0.2\n",
      "Iteraions 20: train_loss: 1.2745045076836667 train_accuracy: 0.20071666666666665 test_loss: 1.2813111301474502 test_accuracy: 0.1996\n",
      "Iteraions 21: train_loss: 1.2345340127829962 train_accuracy: 0.19906666666666667 test_loss: 1.2423664435361315 test_accuracy: 0.1953\n",
      "Iteraions 22: train_loss: 1.200266328012721 train_accuracy: 0.1928 test_loss: 1.208886429804534 test_accuracy: 0.1931\n",
      "Iteraions 23: train_loss: 1.167283146760033 train_accuracy: 0.20116666666666666 test_loss: 1.1780814096266286 test_accuracy: 0.2012\n",
      "Iteraions 24: train_loss: 1.1341906859269093 train_accuracy: 0.23766666666666666 test_loss: 1.1494407664094712 test_accuracy: 0.2355\n",
      "Iteraions 25: train_loss: 1.105119367998931 train_accuracy: 0.28995 test_loss: 1.119207937303566 test_accuracy: 0.2865\n",
      "Iteraions 26: train_loss: 1.078648477841626 train_accuracy: 0.3381 test_loss: 1.0964577122466532 test_accuracy: 0.3343\n",
      "Iteraions 27: train_loss: 1.05561827535192 train_accuracy: 0.3602666666666667 test_loss: 1.07227305917285 test_accuracy: 0.3598\n",
      "Iteraions 28: train_loss: 1.0313678606272227 train_accuracy: 0.3803166666666667 test_loss: 1.0490762191764431 test_accuracy: 0.3774\n",
      "Iteraions 29: train_loss: 1.0077883515300292 train_accuracy: 0.4119833333333333 test_loss: 1.0237393728718533 test_accuracy: 0.4082\n",
      "Iteraions 30: train_loss: 0.9857615902034682 train_accuracy: 0.43705 test_loss: 1.0047930748504588 test_accuracy: 0.4356\n",
      "Iteraions 31: train_loss: 0.9659283080399911 train_accuracy: 0.4596166666666667 test_loss: 0.9854432637203118 test_accuracy: 0.4513\n",
      "Iteraions 32: train_loss: 0.9472242337103665 train_accuracy: 0.46958333333333335 test_loss: 0.9695302341771167 test_accuracy: 0.4632\n",
      "Iteraions 33: train_loss: 0.9291536641219393 train_accuracy: 0.49178333333333335 test_loss: 0.952104255360374 test_accuracy: 0.4866\n",
      "Iteraions 34: train_loss: 0.9117181414685745 train_accuracy: 0.50655 test_loss: 0.9335169021108446 test_accuracy: 0.4995\n",
      "Iteraions 35: train_loss: 0.8981952600018048 train_accuracy: 0.5090333333333333 test_loss: 0.9191213547781554 test_accuracy: 0.502\n",
      "Iteraions 36: train_loss: 0.8835924635827711 train_accuracy: 0.529 test_loss: 0.9034165716570537 test_accuracy: 0.5213\n",
      "Iteraions 37: train_loss: 0.8734539807864538 train_accuracy: 0.5325833333333333 test_loss: 0.8961045568194939 test_accuracy: 0.5239\n",
      "Iteraions 38: train_loss: 0.8594879643318813 train_accuracy: 0.5465 test_loss: 0.8829146160709468 test_accuracy: 0.5399\n",
      "Iteraions 39: train_loss: 0.8520465327466472 train_accuracy: 0.5585333333333333 test_loss: 0.8753354170053416 test_accuracy: 0.5547\n",
      "Iteraions 40: train_loss: 0.8395558484612052 train_accuracy: 0.5587 test_loss: 0.86200041859761 test_accuracy: 0.5496\n",
      "Iteraions 41: train_loss: 0.831484771721182 train_accuracy: 0.576 test_loss: 0.8544592297386302 test_accuracy: 0.5704\n",
      "Iteraions 42: train_loss: 0.8229485282629411 train_accuracy: 0.5744666666666667 test_loss: 0.8459269306700815 test_accuracy: 0.5702\n",
      "Iteraions 43: train_loss: 0.8155599791318097 train_accuracy: 0.58145 test_loss: 0.836227829221441 test_accuracy: 0.5735\n",
      "Iteraions 44: train_loss: 0.8050243652890369 train_accuracy: 0.5913333333333334 test_loss: 0.8275890237068033 test_accuracy: 0.5841\n",
      "Iteraions 45: train_loss: 0.798695790849401 train_accuracy: 0.5892833333333334 test_loss: 0.8176911930984351 test_accuracy: 0.5848\n",
      "Iteraions 46: train_loss: 0.7907525083999744 train_accuracy: 0.6003166666666667 test_loss: 0.8121411037906764 test_accuracy: 0.5936\n",
      "Iteraions 47: train_loss: 0.7846383337714125 train_accuracy: 0.6022166666666666 test_loss: 0.8032182210224961 test_accuracy: 0.5955\n",
      "Iteraions 48: train_loss: 0.7738287946610449 train_accuracy: 0.6061333333333333 test_loss: 0.7968469527487545 test_accuracy: 0.5994\n",
      "Iteraions 49: train_loss: 0.7651859987158766 train_accuracy: 0.6143833333333333 test_loss: 0.7869784856563974 test_accuracy: 0.6046\n",
      "Iteraions 50: train_loss: 0.7571217040125674 train_accuracy: 0.6144166666666667 test_loss: 0.781795141559486 test_accuracy: 0.6069\n",
      "Iteraions 51: train_loss: 0.7493442807250434 train_accuracy: 0.6197833333333334 test_loss: 0.7716965548040392 test_accuracy: 0.614\n",
      "Iteraions 52: train_loss: 0.7421270332483155 train_accuracy: 0.62735 test_loss: 0.7663370930603651 test_accuracy: 0.6207\n",
      "Iteraions 53: train_loss: 0.7354438781346697 train_accuracy: 0.6286833333333334 test_loss: 0.7532934217851853 test_accuracy: 0.6239\n",
      "Iteraions 54: train_loss: 0.7267124304234754 train_accuracy: 0.6352666666666666 test_loss: 0.7517273486275695 test_accuracy: 0.6278\n",
      "Iteraions 55: train_loss: 0.7180361473996166 train_accuracy: 0.6368333333333334 test_loss: 0.7383670788855217 test_accuracy: 0.6308\n",
      "Iteraions 56: train_loss: 0.7110537356594745 train_accuracy: 0.6421666666666667 test_loss: 0.7362733365251796 test_accuracy: 0.6351\n",
      "Iteraions 57: train_loss: 0.7058510091223669 train_accuracy: 0.6486333333333333 test_loss: 0.7318626859667907 test_accuracy: 0.6421\n",
      "Iteraions 58: train_loss: 0.700563808827735 train_accuracy: 0.6508166666666667 test_loss: 0.7239311545492801 test_accuracy: 0.6465\n",
      "Iteraions 59: train_loss: 0.695875222207187 train_accuracy: 0.6569 test_loss: 0.7160570441998514 test_accuracy: 0.6502\n",
      "Iteraions 60: train_loss: 0.6884927606436512 train_accuracy: 0.6613333333333333 test_loss: 0.715401189656553 test_accuracy: 0.6528\n",
      "Iteraions 61: train_loss: 0.6826111039866535 train_accuracy: 0.6644166666666667 test_loss: 0.7059439158354317 test_accuracy: 0.6575\n",
      "Iteraions 62: train_loss: 0.676955043933275 train_accuracy: 0.6718166666666666 test_loss: 0.702262625053596 test_accuracy: 0.6628\n",
      "Iteraions 63: train_loss: 0.6711457804652907 train_accuracy: 0.6731666666666667 test_loss: 0.6938129046850811 test_accuracy: 0.6698\n",
      "Iteraions 64: train_loss: 0.6658426035305269 train_accuracy: 0.6795166666666667 test_loss: 0.6928799252506013 test_accuracy: 0.6693\n",
      "Iteraions 65: train_loss: 0.6603153315948339 train_accuracy: 0.6825833333333333 test_loss: 0.6837377493085687 test_accuracy: 0.675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 66: train_loss: 0.6558600874548676 train_accuracy: 0.6871 test_loss: 0.6792502617604212 test_accuracy: 0.6801\n",
      "Iteraions 67: train_loss: 0.6500926761888415 train_accuracy: 0.6897833333333333 test_loss: 0.6729276644208894 test_accuracy: 0.6843\n",
      "Iteraions 68: train_loss: 0.6468535104891772 train_accuracy: 0.6951166666666667 test_loss: 0.6722288137823184 test_accuracy: 0.6838\n",
      "Iteraions 69: train_loss: 0.6406425033800801 train_accuracy: 0.6989333333333333 test_loss: 0.6662719457857974 test_accuracy: 0.6864\n",
      "Iteraions 70: train_loss: 0.6354884409479263 train_accuracy: 0.7000666666666666 test_loss: 0.6618527027443 test_accuracy: 0.6927\n",
      "Iteraions 71: train_loss: 0.6303463405268243 train_accuracy: 0.7028333333333333 test_loss: 0.6583793367955746 test_accuracy: 0.6933\n",
      "Iteraions 72: train_loss: 0.625745169796736 train_accuracy: 0.7077166666666667 test_loss: 0.6558657149319447 test_accuracy: 0.697\n",
      "Iteraions 73: train_loss: 0.6229928337732925 train_accuracy: 0.7103833333333334 test_loss: 0.650148145064896 test_accuracy: 0.7001\n",
      "Iteraions 74: train_loss: 0.616801430582773 train_accuracy: 0.7125166666666667 test_loss: 0.6466951456351342 test_accuracy: 0.7027\n",
      "Iteraions 75: train_loss: 0.612244089750232 train_accuracy: 0.7153 test_loss: 0.6408565884431398 test_accuracy: 0.7025\n",
      "Iteraions 76: train_loss: 0.6085050489291631 train_accuracy: 0.7173666666666667 test_loss: 0.6356286511739753 test_accuracy: 0.7082\n",
      "Iteraions 77: train_loss: 0.6039678303067969 train_accuracy: 0.7204 test_loss: 0.6338884988896034 test_accuracy: 0.706\n",
      "Iteraions 78: train_loss: 0.5996547697693945 train_accuracy: 0.72425 test_loss: 0.6269315387986767 test_accuracy: 0.7134\n",
      "Iteraions 79: train_loss: 0.5959822890804315 train_accuracy: 0.7251666666666666 test_loss: 0.6249278878472562 test_accuracy: 0.7143\n",
      "Iteraions 80: train_loss: 0.5908413993252352 train_accuracy: 0.7288833333333333 test_loss: 0.6218211376474212 test_accuracy: 0.715\n",
      "Iteraions 81: train_loss: 0.5871865764503704 train_accuracy: 0.7315 test_loss: 0.6135507022687614 test_accuracy: 0.7206\n",
      "Iteraions 82: train_loss: 0.584614047578426 train_accuracy: 0.7323333333333333 test_loss: 0.6153592408075987 test_accuracy: 0.7204\n",
      "Iteraions 83: train_loss: 0.5790326099670572 train_accuracy: 0.7352 test_loss: 0.6102621101450861 test_accuracy: 0.7229\n",
      "Iteraions 84: train_loss: 0.5755037280174795 train_accuracy: 0.7377666666666667 test_loss: 0.6052062751858284 test_accuracy: 0.724\n",
      "Iteraions 85: train_loss: 0.5714820992065411 train_accuracy: 0.74045 test_loss: 0.5999775044072824 test_accuracy: 0.727\n",
      "Iteraions 86: train_loss: 0.5674394988047305 train_accuracy: 0.7428166666666667 test_loss: 0.5942786627088282 test_accuracy: 0.729\n",
      "Iteraions 87: train_loss: 0.56394119174474 train_accuracy: 0.7452333333333333 test_loss: 0.5933953805640032 test_accuracy: 0.7315\n",
      "Iteraions 88: train_loss: 0.5597458189509563 train_accuracy: 0.74565 test_loss: 0.5906289217002323 test_accuracy: 0.734\n",
      "Iteraions 89: train_loss: 0.556703932799289 train_accuracy: 0.7489166666666667 test_loss: 0.5858612152689257 test_accuracy: 0.7367\n",
      "Iteraions 90: train_loss: 0.5538880629882611 train_accuracy: 0.7522 test_loss: 0.5809123167936419 test_accuracy: 0.7378\n",
      "Iteraions 91: train_loss: 0.5503124652860867 train_accuracy: 0.7513333333333333 test_loss: 0.5798832644667398 test_accuracy: 0.74\n",
      "Iteraions 92: train_loss: 0.5475026983550851 train_accuracy: 0.75555 test_loss: 0.5764565359510009 test_accuracy: 0.7422\n",
      "Iteraions 93: train_loss: 0.5422226629233089 train_accuracy: 0.7577 test_loss: 0.5742427057826859 test_accuracy: 0.741\n",
      "Iteraions 94: train_loss: 0.5378076110902018 train_accuracy: 0.7605166666666666 test_loss: 0.5712412689630901 test_accuracy: 0.746\n",
      "Iteraions 95: train_loss: 0.5363230583160861 train_accuracy: 0.7614166666666666 test_loss: 0.5657147004629779 test_accuracy: 0.7477\n",
      "Iteraions 96: train_loss: 0.5333824144651006 train_accuracy: 0.7634166666666666 test_loss: 0.5657675119737301 test_accuracy: 0.7514\n",
      "Iteraions 97: train_loss: 0.5301861085975552 train_accuracy: 0.7658666666666667 test_loss: 0.5622824323370732 test_accuracy: 0.7517\n",
      "Iteraions 98: train_loss: 0.5268066572305369 train_accuracy: 0.7687 test_loss: 0.5612652741511741 test_accuracy: 0.7527\n",
      "Iteraions 99: train_loss: 0.5241897002272335 train_accuracy: 0.7700666666666667 test_loss: 0.5576604472801456 test_accuracy: 0.7559\n",
      "Iteraions 100: train_loss: 0.520987067784519 train_accuracy: 0.7720833333333333 test_loss: 0.5548303622052894 test_accuracy: 0.7564\n",
      "Iteraions 101: train_loss: 0.5190578293249434 train_accuracy: 0.77315 test_loss: 0.5530692983388743 test_accuracy: 0.7592\n",
      "Iteraions 102: train_loss: 0.5169950222836684 train_accuracy: 0.7765666666666666 test_loss: 0.5459886743985287 test_accuracy: 0.7628\n",
      "Iteraions 103: train_loss: 0.513365221125304 train_accuracy: 0.7771166666666667 test_loss: 0.5456112337475438 test_accuracy: 0.761\n",
      "Iteraions 104: train_loss: 0.5115883477176209 train_accuracy: 0.7792 test_loss: 0.5413229005681247 test_accuracy: 0.7657\n",
      "Iteraions 105: train_loss: 0.5086749973686108 train_accuracy: 0.7819 test_loss: 0.5387737106549527 test_accuracy: 0.7651\n",
      "Iteraions 106: train_loss: 0.5046758995526505 train_accuracy: 0.7815 test_loss: 0.5369117044079508 test_accuracy: 0.7684\n",
      "Iteraions 107: train_loss: 0.5024583134298826 train_accuracy: 0.7841833333333333 test_loss: 0.5353669405620336 test_accuracy: 0.7694\n",
      "Iteraions 108: train_loss: 0.49928363318178504 train_accuracy: 0.7858833333333334 test_loss: 0.5307685791410791 test_accuracy: 0.771\n",
      "Iteraions 109: train_loss: 0.4966579189588259 train_accuracy: 0.7873333333333333 test_loss: 0.529961513552498 test_accuracy: 0.7713\n",
      "Iteraions 110: train_loss: 0.49678715778783833 train_accuracy: 0.7856833333333333 test_loss: 0.5282866837239569 test_accuracy: 0.7746\n",
      "Iteraions 111: train_loss: 0.4927168346963623 train_accuracy: 0.7887833333333333 test_loss: 0.5257936509564461 test_accuracy: 0.7773\n",
      "Iteraions 112: train_loss: 0.4898326396083121 train_accuracy: 0.7904833333333333 test_loss: 0.5233159871692331 test_accuracy: 0.778\n",
      "Iteraions 113: train_loss: 0.4884793889412238 train_accuracy: 0.7913833333333333 test_loss: 0.5211829785859782 test_accuracy: 0.7767\n",
      "Iteraions 114: train_loss: 0.487323797700603 train_accuracy: 0.7902166666666667 test_loss: 0.5220853734635958 test_accuracy: 0.7782\n",
      "Iteraions 115: train_loss: 0.4855521788503165 train_accuracy: 0.7937 test_loss: 0.5183780144489342 test_accuracy: 0.7821\n",
      "Iteraions 116: train_loss: 0.4816350659844569 train_accuracy: 0.7964333333333333 test_loss: 0.5151363210958968 test_accuracy: 0.7805\n",
      "Iteraions 117: train_loss: 0.4795383226787038 train_accuracy: 0.79595 test_loss: 0.5131542876322843 test_accuracy: 0.7831\n",
      "Iteraions 118: train_loss: 0.47707065045139607 train_accuracy: 0.7985 test_loss: 0.5088519224949776 test_accuracy: 0.7853\n",
      "Iteraions 119: train_loss: 0.47584656134432507 train_accuracy: 0.79745 test_loss: 0.5095717185108087 test_accuracy: 0.7868\n",
      "Iteraions 120: train_loss: 0.47300870053175637 train_accuracy: 0.8011666666666667 test_loss: 0.5082625136412127 test_accuracy: 0.7869\n",
      "Iteraions 121: train_loss: 0.4711451761005689 train_accuracy: 0.7999333333333334 test_loss: 0.5106017314031005 test_accuracy: 0.7866\n",
      "Iteraions 122: train_loss: 0.46919122555760606 train_accuracy: 0.8034333333333333 test_loss: 0.5055019687644855 test_accuracy: 0.7873\n",
      "Iteraions 123: train_loss: 0.46812353968848924 train_accuracy: 0.8028666666666666 test_loss: 0.4999434696871396 test_accuracy: 0.7873\n",
      "Iteraions 124: train_loss: 0.46531153785277835 train_accuracy: 0.8046666666666666 test_loss: 0.5031026373557557 test_accuracy: 0.7914\n",
      "Iteraions 125: train_loss: 0.46567941091996823 train_accuracy: 0.8043833333333333 test_loss: 0.4987341927085994 test_accuracy: 0.7897\n",
      "Iteraions 126: train_loss: 0.46333346290658983 train_accuracy: 0.8041 test_loss: 0.4965962365424897 test_accuracy: 0.7931\n",
      "Iteraions 127: train_loss: 0.46099099573819863 train_accuracy: 0.80755 test_loss: 0.4973364746675636 test_accuracy: 0.7901\n",
      "Iteraions 128: train_loss: 0.4589903562528615 train_accuracy: 0.8063333333333333 test_loss: 0.4951535138867272 test_accuracy: 0.7961\n",
      "Iteraions 129: train_loss: 0.4568015335419951 train_accuracy: 0.8086 test_loss: 0.48994759612287514 test_accuracy: 0.7969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 130: train_loss: 0.45455692826621963 train_accuracy: 0.809 test_loss: 0.4937306706038633 test_accuracy: 0.7911\n",
      "Iteraions 131: train_loss: 0.4539641579691795 train_accuracy: 0.8103666666666667 test_loss: 0.48991536257234863 test_accuracy: 0.7987\n",
      "Iteraions 132: train_loss: 0.45144574252805786 train_accuracy: 0.8111333333333334 test_loss: 0.48787453121253577 test_accuracy: 0.7944\n",
      "Iteraions 133: train_loss: 0.45017403922142296 train_accuracy: 0.8123166666666667 test_loss: 0.482353182429588 test_accuracy: 0.802\n",
      "Iteraions 134: train_loss: 0.44821537922613847 train_accuracy: 0.81265 test_loss: 0.4805750002557403 test_accuracy: 0.8009\n",
      "Iteraions 135: train_loss: 0.4467017066546307 train_accuracy: 0.8143833333333333 test_loss: 0.48047566098091954 test_accuracy: 0.801\n",
      "Iteraions 136: train_loss: 0.4443528327058254 train_accuracy: 0.8150166666666666 test_loss: 0.4812959221703488 test_accuracy: 0.8018\n",
      "Iteraions 137: train_loss: 0.44261326183493166 train_accuracy: 0.81535 test_loss: 0.48026702837654395 test_accuracy: 0.803\n",
      "Iteraions 138: train_loss: 0.4421458197332499 train_accuracy: 0.81595 test_loss: 0.47448536568124744 test_accuracy: 0.8042\n",
      "Iteraions 139: train_loss: 0.44088010252832016 train_accuracy: 0.8159666666666666 test_loss: 0.4738337973438492 test_accuracy: 0.8037\n",
      "Iteraions 140: train_loss: 0.43977863443620385 train_accuracy: 0.8189166666666666 test_loss: 0.47623961305086115 test_accuracy: 0.8029\n",
      "Iteraions 141: train_loss: 0.43722583325796865 train_accuracy: 0.8177333333333333 test_loss: 0.47219225901305556 test_accuracy: 0.8036\n",
      "Iteraions 142: train_loss: 0.4358642117718868 train_accuracy: 0.8191 test_loss: 0.469833200452525 test_accuracy: 0.8063\n",
      "Iteraions 143: train_loss: 0.43407594188604914 train_accuracy: 0.8211166666666667 test_loss: 0.4719415041478066 test_accuracy: 0.8042\n",
      "Iteraions 144: train_loss: 0.4324691981761201 train_accuracy: 0.81915 test_loss: 0.46967117559953686 test_accuracy: 0.8078\n",
      "Iteraions 145: train_loss: 0.43044389856641463 train_accuracy: 0.8213 test_loss: 0.4655633461065869 test_accuracy: 0.8082\n",
      "Iteraions 146: train_loss: 0.4294363108666336 train_accuracy: 0.8236666666666667 test_loss: 0.4676420032148173 test_accuracy: 0.809\n",
      "Iteraions 147: train_loss: 0.4288808899618081 train_accuracy: 0.8222833333333334 test_loss: 0.46359871620543963 test_accuracy: 0.809\n",
      "Iteraions 148: train_loss: 0.42569140109499776 train_accuracy: 0.8245 test_loss: 0.4642853020153976 test_accuracy: 0.8084\n",
      "Iteraions 149: train_loss: 0.423383986950845 train_accuracy: 0.82425 test_loss: 0.4595027822840702 test_accuracy: 0.8084\n",
      "Iteraions 150: train_loss: 0.42270515711523593 train_accuracy: 0.8263333333333334 test_loss: 0.4596314670119966 test_accuracy: 0.809\n",
      "Iteraions 151: train_loss: 0.42215212788213585 train_accuracy: 0.8251833333333334 test_loss: 0.4570667427481803 test_accuracy: 0.8136\n",
      "Iteraions 152: train_loss: 0.4201999099100219 train_accuracy: 0.8266833333333333 test_loss: 0.4547702315734968 test_accuracy: 0.8139\n",
      "Iteraions 153: train_loss: 0.41787876847471267 train_accuracy: 0.828 test_loss: 0.45192023182021224 test_accuracy: 0.8134\n",
      "Iteraions 154: train_loss: 0.41764456458785437 train_accuracy: 0.8291 test_loss: 0.4541390618135689 test_accuracy: 0.813\n",
      "Iteraions 155: train_loss: 0.4153066379717876 train_accuracy: 0.8289666666666666 test_loss: 0.45590015242613974 test_accuracy: 0.812\n",
      "Iteraions 156: train_loss: 0.41320170435590137 train_accuracy: 0.8293166666666667 test_loss: 0.45082579298920855 test_accuracy: 0.8143\n",
      "Iteraions 157: train_loss: 0.4136000308581776 train_accuracy: 0.8304833333333334 test_loss: 0.44773757792118996 test_accuracy: 0.8147\n",
      "Iteraions 158: train_loss: 0.4111102807371683 train_accuracy: 0.8313333333333334 test_loss: 0.4504214453424007 test_accuracy: 0.814\n",
      "Iteraions 159: train_loss: 0.41020123860161267 train_accuracy: 0.8300833333333333 test_loss: 0.447949642266877 test_accuracy: 0.8163\n",
      "Iteraions 160: train_loss: 0.40985754150752923 train_accuracy: 0.83055 test_loss: 0.4446814226638412 test_accuracy: 0.8162\n",
      "Iteraions 161: train_loss: 0.4078675617204285 train_accuracy: 0.8317833333333333 test_loss: 0.4478974721179004 test_accuracy: 0.8164\n",
      "Iteraions 162: train_loss: 0.40601916937881677 train_accuracy: 0.83315 test_loss: 0.44215320927455815 test_accuracy: 0.8187\n",
      "Iteraions 163: train_loss: 0.4056573179859073 train_accuracy: 0.8332166666666667 test_loss: 0.44065984099361377 test_accuracy: 0.8194\n",
      "Iteraions 164: train_loss: 0.40320890224668415 train_accuracy: 0.8334833333333334 test_loss: 0.4401973391694909 test_accuracy: 0.8201\n",
      "Iteraions 165: train_loss: 0.4019712335768888 train_accuracy: 0.8351166666666666 test_loss: 0.44036331718635646 test_accuracy: 0.8191\n",
      "Iteraions 166: train_loss: 0.4003067802696336 train_accuracy: 0.8345833333333333 test_loss: 0.43904552375015393 test_accuracy: 0.8205\n",
      "Iteraions 167: train_loss: 0.4008674654402933 train_accuracy: 0.8366166666666667 test_loss: 0.43726645504075934 test_accuracy: 0.8192\n",
      "Iteraions 168: train_loss: 0.39976948601937395 train_accuracy: 0.8364666666666667 test_loss: 0.4359052745270298 test_accuracy: 0.8205\n",
      "Iteraions 169: train_loss: 0.3962226732339949 train_accuracy: 0.8375166666666667 test_loss: 0.43368500476492083 test_accuracy: 0.8206\n",
      "Iteraions 170: train_loss: 0.3967538152212698 train_accuracy: 0.8385166666666667 test_loss: 0.43696136833285526 test_accuracy: 0.8209\n",
      "Iteraions 171: train_loss: 0.39536608533205464 train_accuracy: 0.8374333333333334 test_loss: 0.43172372768946055 test_accuracy: 0.8222\n",
      "Iteraions 172: train_loss: 0.393999219312045 train_accuracy: 0.8389 test_loss: 0.4322790206142513 test_accuracy: 0.8215\n",
      "Iteraions 173: train_loss: 0.3927409329325373 train_accuracy: 0.8397333333333333 test_loss: 0.43172105013126555 test_accuracy: 0.823\n",
      "Iteraions 174: train_loss: 0.3908115149684189 train_accuracy: 0.83965 test_loss: 0.4299261516795903 test_accuracy: 0.8258\n",
      "Iteraions 175: train_loss: 0.39032162062928133 train_accuracy: 0.8405 test_loss: 0.4303816330618589 test_accuracy: 0.824\n",
      "Iteraions 176: train_loss: 0.3882395070948474 train_accuracy: 0.84175 test_loss: 0.42851958711828375 test_accuracy: 0.8234\n",
      "Iteraions 177: train_loss: 0.38907736173037205 train_accuracy: 0.8403166666666667 test_loss: 0.4233121775801607 test_accuracy: 0.8249\n",
      "Iteraions 178: train_loss: 0.3867436212228571 train_accuracy: 0.8413666666666667 test_loss: 0.4267485829108316 test_accuracy: 0.8247\n",
      "Iteraions 179: train_loss: 0.38667423548273155 train_accuracy: 0.8422333333333333 test_loss: 0.426054488451118 test_accuracy: 0.8258\n",
      "Iteraions 180: train_loss: 0.38395287974433995 train_accuracy: 0.8423 test_loss: 0.4253187159364359 test_accuracy: 0.8242\n",
      "Iteraions 181: train_loss: 0.3835428719726884 train_accuracy: 0.8437666666666667 test_loss: 0.42085958032755505 test_accuracy: 0.8259\n",
      "Iteraions 182: train_loss: 0.38348037122841494 train_accuracy: 0.8429666666666666 test_loss: 0.41851799378889637 test_accuracy: 0.8264\n",
      "Iteraions 183: train_loss: 0.3816554984563064 train_accuracy: 0.8431 test_loss: 0.41810166900431767 test_accuracy: 0.826\n",
      "Iteraions 184: train_loss: 0.380358391958352 train_accuracy: 0.8437833333333333 test_loss: 0.4189950060175739 test_accuracy: 0.8292\n",
      "Iteraions 185: train_loss: 0.3796633736290221 train_accuracy: 0.8438666666666667 test_loss: 0.4168218406091435 test_accuracy: 0.8316\n",
      "Iteraions 186: train_loss: 0.37775324428940754 train_accuracy: 0.8454 test_loss: 0.4183026808878468 test_accuracy: 0.8293\n",
      "Iteraions 187: train_loss: 0.3756270115514534 train_accuracy: 0.8459833333333333 test_loss: 0.4181368059753286 test_accuracy: 0.8274\n",
      "Iteraions 188: train_loss: 0.37553288089793324 train_accuracy: 0.8457166666666667 test_loss: 0.41649449820491663 test_accuracy: 0.8292\n",
      "Iteraions 189: train_loss: 0.374340342470217 train_accuracy: 0.84665 test_loss: 0.41430344779884765 test_accuracy: 0.8303\n",
      "Iteraions 190: train_loss: 0.3738262612045503 train_accuracy: 0.8477333333333333 test_loss: 0.41611750104771256 test_accuracy: 0.8276\n",
      "Iteraions 191: train_loss: 0.37298231736340715 train_accuracy: 0.84805 test_loss: 0.4159566510014223 test_accuracy: 0.8315\n",
      "Iteraions 192: train_loss: 0.37235219167189315 train_accuracy: 0.84705 test_loss: 0.411919269099243 test_accuracy: 0.8294\n",
      "Iteraions 193: train_loss: 0.37042254594248164 train_accuracy: 0.8488333333333333 test_loss: 0.4128844382798323 test_accuracy: 0.833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 194: train_loss: 0.36954489130459334 train_accuracy: 0.849 test_loss: 0.4124426260131098 test_accuracy: 0.8299\n",
      "Iteraions 195: train_loss: 0.36894161035768663 train_accuracy: 0.84845 test_loss: 0.4080675942766284 test_accuracy: 0.831\n",
      "Iteraions 196: train_loss: 0.3675955369720903 train_accuracy: 0.8496333333333334 test_loss: 0.41109694071521163 test_accuracy: 0.833\n",
      "Iteraions 197: train_loss: 0.36586795202210953 train_accuracy: 0.8499833333333333 test_loss: 0.406396250487121 test_accuracy: 0.8319\n",
      "Iteraions 198: train_loss: 0.36576195630433816 train_accuracy: 0.8507166666666667 test_loss: 0.40738527478732556 test_accuracy: 0.8335\n",
      "Iteraions 199: train_loss: 0.3649271287211369 train_accuracy: 0.85165 test_loss: 0.4074742371141945 test_accuracy: 0.8329\n",
      "Iteraions 200: train_loss: 0.36298200483410353 train_accuracy: 0.85235 test_loss: 0.406336171066613 test_accuracy: 0.8346\n",
      "Iteraions 201: train_loss: 0.3630167433967115 train_accuracy: 0.851 test_loss: 0.40355022856201284 test_accuracy: 0.833\n",
      "Iteraions 202: train_loss: 0.36160436067098795 train_accuracy: 0.8524833333333334 test_loss: 0.40447222468321614 test_accuracy: 0.8344\n",
      "Iteraions 203: train_loss: 0.3611324818370939 train_accuracy: 0.8534166666666667 test_loss: 0.4042609183235977 test_accuracy: 0.8348\n",
      "Iteraions 204: train_loss: 0.359800852903991 train_accuracy: 0.8529 test_loss: 0.40514893702548155 test_accuracy: 0.8358\n",
      "Iteraions 205: train_loss: 0.35860135447151564 train_accuracy: 0.85415 test_loss: 0.4026156661899037 test_accuracy: 0.8366\n",
      "Iteraions 206: train_loss: 0.3587183919676137 train_accuracy: 0.8528833333333333 test_loss: 0.40369240578234794 test_accuracy: 0.8345\n",
      "Iteraions 207: train_loss: 0.35776290769267377 train_accuracy: 0.8534833333333334 test_loss: 0.40354648987685093 test_accuracy: 0.836\n",
      "Iteraions 208: train_loss: 0.35790319223079 train_accuracy: 0.8543666666666667 test_loss: 0.4033026424433218 test_accuracy: 0.8368\n",
      "Iteraions 209: train_loss: 0.3566108670206402 train_accuracy: 0.8553666666666667 test_loss: 0.4001951608428667 test_accuracy: 0.8335\n",
      "Iteraions 210: train_loss: 0.35537318100773047 train_accuracy: 0.8556166666666667 test_loss: 0.39937495405513734 test_accuracy: 0.8379\n",
      "Iteraions 211: train_loss: 0.3538347218061106 train_accuracy: 0.8558 test_loss: 0.398497922891145 test_accuracy: 0.8356\n",
      "Iteraions 212: train_loss: 0.3520797396621701 train_accuracy: 0.8562333333333333 test_loss: 0.40150269175819514 test_accuracy: 0.839\n",
      "Iteraions 213: train_loss: 0.3517880020341467 train_accuracy: 0.8562666666666666 test_loss: 0.3995681786509878 test_accuracy: 0.8371\n",
      "Iteraions 214: train_loss: 0.3508698280541445 train_accuracy: 0.8570166666666666 test_loss: 0.3947913414868969 test_accuracy: 0.8373\n",
      "Iteraions 215: train_loss: 0.34902125375518567 train_accuracy: 0.8575333333333334 test_loss: 0.39804727841119764 test_accuracy: 0.8386\n",
      "Iteraions 216: train_loss: 0.3491003846048854 train_accuracy: 0.8582166666666666 test_loss: 0.39621373183618996 test_accuracy: 0.8412\n",
      "Iteraions 217: train_loss: 0.34739905934470033 train_accuracy: 0.8584166666666667 test_loss: 0.3957485759976949 test_accuracy: 0.8396\n",
      "Iteraions 218: train_loss: 0.3484175978151082 train_accuracy: 0.8582833333333333 test_loss: 0.39394092626947746 test_accuracy: 0.8397\n",
      "Iteraions 219: train_loss: 0.34668026653572537 train_accuracy: 0.85895 test_loss: 0.3937778086279227 test_accuracy: 0.8409\n",
      "Iteraions 220: train_loss: 0.346547567458794 train_accuracy: 0.8587333333333333 test_loss: 0.3898430492446649 test_accuracy: 0.842\n",
      "Iteraions 221: train_loss: 0.3444974699839681 train_accuracy: 0.8591666666666666 test_loss: 0.39264656163667705 test_accuracy: 0.8411\n",
      "Iteraions 222: train_loss: 0.3441858107372518 train_accuracy: 0.86135 test_loss: 0.3935801803135816 test_accuracy: 0.8388\n",
      "Iteraions 223: train_loss: 0.3445479707175964 train_accuracy: 0.8596333333333334 test_loss: 0.39001981648393513 test_accuracy: 0.8414\n",
      "Iteraions 224: train_loss: 0.34292464926572025 train_accuracy: 0.8609666666666667 test_loss: 0.3899210704848296 test_accuracy: 0.8401\n",
      "Iteraions 225: train_loss: 0.3417065109453051 train_accuracy: 0.8608333333333333 test_loss: 0.3872901115008503 test_accuracy: 0.8421\n",
      "Iteraions 226: train_loss: 0.34052577413345253 train_accuracy: 0.86245 test_loss: 0.38805295496492115 test_accuracy: 0.8423\n",
      "Iteraions 227: train_loss: 0.34034163116327 train_accuracy: 0.8618333333333333 test_loss: 0.38629459585260506 test_accuracy: 0.8424\n",
      "Iteraions 228: train_loss: 0.33915698392964816 train_accuracy: 0.8630333333333333 test_loss: 0.3888037827218402 test_accuracy: 0.8403\n",
      "Iteraions 229: train_loss: 0.33916798509915413 train_accuracy: 0.8617166666666667 test_loss: 0.38870507013168143 test_accuracy: 0.8434\n",
      "Iteraions 230: train_loss: 0.33613683213650764 train_accuracy: 0.8642833333333333 test_loss: 0.3902965217967965 test_accuracy: 0.8405\n",
      "Iteraions 231: train_loss: 0.3366289595240156 train_accuracy: 0.8638666666666667 test_loss: 0.387617769785608 test_accuracy: 0.8422\n",
      "Iteraions 232: train_loss: 0.33654339669546574 train_accuracy: 0.8634166666666667 test_loss: 0.3865184014975248 test_accuracy: 0.8408\n",
      "Iteraions 233: train_loss: 0.33557254771847317 train_accuracy: 0.8627666666666667 test_loss: 0.3862037276561967 test_accuracy: 0.8425\n",
      "Iteraions 234: train_loss: 0.33510696373089754 train_accuracy: 0.8643333333333333 test_loss: 0.38428191860464894 test_accuracy: 0.8425\n",
      "Iteraions 235: train_loss: 0.33436431478498224 train_accuracy: 0.8644333333333334 test_loss: 0.38450569367597 test_accuracy: 0.8442\n",
      "Iteraions 236: train_loss: 0.33282888690810625 train_accuracy: 0.8643166666666666 test_loss: 0.38544149016824547 test_accuracy: 0.8451\n",
      "Iteraions 237: train_loss: 0.33202995800056756 train_accuracy: 0.8655833333333334 test_loss: 0.38151361591545463 test_accuracy: 0.8464\n",
      "Iteraions 238: train_loss: 0.3316366554316463 train_accuracy: 0.8658 test_loss: 0.3819579584567455 test_accuracy: 0.847\n",
      "Iteraions 239: train_loss: 0.3309589938964988 train_accuracy: 0.8660333333333333 test_loss: 0.38146261048898017 test_accuracy: 0.8484\n",
      "Iteraions 240: train_loss: 0.3310525938740155 train_accuracy: 0.8657333333333334 test_loss: 0.38183781877590917 test_accuracy: 0.8486\n",
      "Iteraions 241: train_loss: 0.32895409790617947 train_accuracy: 0.8667666666666667 test_loss: 0.38003626650810346 test_accuracy: 0.8494\n",
      "Iteraions 242: train_loss: 0.3275886560342593 train_accuracy: 0.8662333333333333 test_loss: 0.3801519252122569 test_accuracy: 0.8457\n",
      "Iteraions 243: train_loss: 0.3275980755505513 train_accuracy: 0.8662333333333333 test_loss: 0.37589763372128093 test_accuracy: 0.8469\n",
      "Iteraions 244: train_loss: 0.32780016241428234 train_accuracy: 0.8668833333333333 test_loss: 0.3793638238643612 test_accuracy: 0.8442\n",
      "Iteraions 245: train_loss: 0.3273032033267426 train_accuracy: 0.86765 test_loss: 0.38100085011739426 test_accuracy: 0.8493\n",
      "Iteraions 246: train_loss: 0.3261661157780953 train_accuracy: 0.8687833333333334 test_loss: 0.37990041754407583 test_accuracy: 0.8475\n",
      "Iteraions 247: train_loss: 0.325526267592103 train_accuracy: 0.86795 test_loss: 0.3802233108151906 test_accuracy: 0.8486\n",
      "Iteraions 248: train_loss: 0.3242923269320193 train_accuracy: 0.86665 test_loss: 0.3781160747281166 test_accuracy: 0.8487\n",
      "Iteraions 249: train_loss: 0.3247349461480621 train_accuracy: 0.8684833333333334 test_loss: 0.3786697916021025 test_accuracy: 0.8474\n",
      "Iteraions 250: train_loss: 0.32450342854642855 train_accuracy: 0.8676333333333334 test_loss: 0.375761898531242 test_accuracy: 0.8491\n",
      "Iteraions 251: train_loss: 0.32393073605291417 train_accuracy: 0.869 test_loss: 0.3763945541294549 test_accuracy: 0.8513\n",
      "Iteraions 252: train_loss: 0.3223995016501815 train_accuracy: 0.8695166666666667 test_loss: 0.37868445481058444 test_accuracy: 0.8452\n",
      "Iteraions 253: train_loss: 0.321033911026304 train_accuracy: 0.8694666666666667 test_loss: 0.3731108001226627 test_accuracy: 0.8524\n",
      "Iteraions 254: train_loss: 0.3204398450028303 train_accuracy: 0.8718666666666667 test_loss: 0.3743086062739565 test_accuracy: 0.8488\n",
      "Iteraions 255: train_loss: 0.3206799779044456 train_accuracy: 0.8698333333333333 test_loss: 0.37105397462915707 test_accuracy: 0.8501\n",
      "Iteraions 256: train_loss: 0.3195523258215895 train_accuracy: 0.8718666666666667 test_loss: 0.3750683644810447 test_accuracy: 0.8484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 257: train_loss: 0.31899799860687833 train_accuracy: 0.8707833333333334 test_loss: 0.3762928987067943 test_accuracy: 0.8494\n",
      "Iteraions 258: train_loss: 0.3187349660450732 train_accuracy: 0.87205 test_loss: 0.3756890375360218 test_accuracy: 0.8508\n",
      "Iteraions 259: train_loss: 0.31696918417972786 train_accuracy: 0.8722 test_loss: 0.375637022734327 test_accuracy: 0.8501\n",
      "Iteraions 260: train_loss: 0.31652082847011126 train_accuracy: 0.8716 test_loss: 0.37212131557424616 test_accuracy: 0.8524\n",
      "Iteraions 261: train_loss: 0.3166972952504463 train_accuracy: 0.8720666666666667 test_loss: 0.3720654429232764 test_accuracy: 0.8494\n",
      "Iteraions 262: train_loss: 0.3163211305259203 train_accuracy: 0.87225 test_loss: 0.37262202139410744 test_accuracy: 0.8488\n",
      "Iteraions 263: train_loss: 0.31434596306875734 train_accuracy: 0.8728333333333333 test_loss: 0.3694761139610305 test_accuracy: 0.8532\n",
      "Iteraions 264: train_loss: 0.31369851111858144 train_accuracy: 0.8734666666666666 test_loss: 0.36712202995063115 test_accuracy: 0.8521\n",
      "Iteraions 265: train_loss: 0.31384562794197784 train_accuracy: 0.8735 test_loss: 0.37369425898134717 test_accuracy: 0.8526\n",
      "Iteraions 266: train_loss: 0.31212367016828185 train_accuracy: 0.8741833333333333 test_loss: 0.3706068440083821 test_accuracy: 0.854\n",
      "Iteraions 267: train_loss: 0.31197229786928 train_accuracy: 0.8746833333333334 test_loss: 0.37438728790174475 test_accuracy: 0.8492\n",
      "Iteraions 268: train_loss: 0.3114228992155147 train_accuracy: 0.8749833333333333 test_loss: 0.3698377148247462 test_accuracy: 0.8514\n",
      "Iteraions 269: train_loss: 0.3119707825156805 train_accuracy: 0.8739166666666667 test_loss: 0.370039627446014 test_accuracy: 0.853\n",
      "Iteraions 270: train_loss: 0.3097528718998311 train_accuracy: 0.8747666666666667 test_loss: 0.3708954388078961 test_accuracy: 0.8502\n",
      "Iteraions 271: train_loss: 0.31077033506175966 train_accuracy: 0.8751666666666666 test_loss: 0.3683778821285614 test_accuracy: 0.8513\n",
      "Iteraions 272: train_loss: 0.30991776450826763 train_accuracy: 0.8749666666666667 test_loss: 0.3678654479670905 test_accuracy: 0.8526\n",
      "Iteraions 273: train_loss: 0.30872799655657096 train_accuracy: 0.8761166666666667 test_loss: 0.36343505422106964 test_accuracy: 0.8535\n",
      "Iteraions 274: train_loss: 0.3067848365215066 train_accuracy: 0.8752833333333333 test_loss: 0.3652079895330772 test_accuracy: 0.8507\n",
      "Iteraions 275: train_loss: 0.30825390916300893 train_accuracy: 0.8751333333333333 test_loss: 0.365614498754352 test_accuracy: 0.8534\n",
      "Iteraions 276: train_loss: 0.3074545285831477 train_accuracy: 0.8761 test_loss: 0.36614388793520236 test_accuracy: 0.8514\n",
      "Iteraions 277: train_loss: 0.3065094883099195 train_accuracy: 0.8768333333333334 test_loss: 0.36652822972905597 test_accuracy: 0.853\n",
      "Iteraions 278: train_loss: 0.30571911421534326 train_accuracy: 0.8776666666666667 test_loss: 0.364964977484265 test_accuracy: 0.854\n",
      "Iteraions 279: train_loss: 0.30599521633257704 train_accuracy: 0.87635 test_loss: 0.3677642251116255 test_accuracy: 0.8531\n",
      "Iteraions 280: train_loss: 0.30447571924512556 train_accuracy: 0.87595 test_loss: 0.3631899707755701 test_accuracy: 0.854\n",
      "Iteraions 281: train_loss: 0.30411444697697526 train_accuracy: 0.8780833333333333 test_loss: 0.3653417621812252 test_accuracy: 0.8527\n",
      "Iteraions 282: train_loss: 0.30465116675008114 train_accuracy: 0.8764166666666666 test_loss: 0.36385676872261186 test_accuracy: 0.8545\n",
      "Iteraions 283: train_loss: 0.30405827392077106 train_accuracy: 0.8779666666666667 test_loss: 0.362437946529406 test_accuracy: 0.8534\n",
      "Iteraions 284: train_loss: 0.30279623936618166 train_accuracy: 0.87885 test_loss: 0.3657467208093369 test_accuracy: 0.8551\n",
      "Iteraions 285: train_loss: 0.3033150905273804 train_accuracy: 0.87645 test_loss: 0.3617855546668069 test_accuracy: 0.8538\n",
      "Iteraions 286: train_loss: 0.30138711516341243 train_accuracy: 0.87925 test_loss: 0.36212826475797805 test_accuracy: 0.8558\n",
      "Iteraions 287: train_loss: 0.30168987658910884 train_accuracy: 0.8772166666666666 test_loss: 0.36197844498567977 test_accuracy: 0.8537\n",
      "Iteraions 288: train_loss: 0.3014527841168441 train_accuracy: 0.87805 test_loss: 0.3613808580051713 test_accuracy: 0.8551\n",
      "Iteraions 289: train_loss: 0.30012782229186485 train_accuracy: 0.8794 test_loss: 0.36291478872346955 test_accuracy: 0.8549\n",
      "Iteraions 290: train_loss: 0.2982368358435344 train_accuracy: 0.8792333333333333 test_loss: 0.35984174952065107 test_accuracy: 0.8569\n",
      "Iteraions 291: train_loss: 0.2983694281764733 train_accuracy: 0.8802833333333333 test_loss: 0.3606159994880879 test_accuracy: 0.8558\n",
      "Iteraions 292: train_loss: 0.2967739779620469 train_accuracy: 0.8794333333333333 test_loss: 0.36124396682757265 test_accuracy: 0.8573\n",
      "Iteraions 293: train_loss: 0.2970449051326758 train_accuracy: 0.8797 test_loss: 0.3622513195282053 test_accuracy: 0.8576\n",
      "Iteraions 294: train_loss: 0.2960711425626436 train_accuracy: 0.8802333333333333 test_loss: 0.36158310519381903 test_accuracy: 0.8562\n",
      "Iteraions 295: train_loss: 0.2959898566506424 train_accuracy: 0.8807 test_loss: 0.36233144415036744 test_accuracy: 0.8548\n",
      "Iteraions 296: train_loss: 0.2961701604664807 train_accuracy: 0.88075 test_loss: 0.3606986505655982 test_accuracy: 0.8581\n",
      "Iteraions 297: train_loss: 0.29589819800478895 train_accuracy: 0.8807333333333334 test_loss: 0.36100165601785145 test_accuracy: 0.8574\n",
      "Iteraions 298: train_loss: 0.2952745072742798 train_accuracy: 0.8797666666666667 test_loss: 0.3551233844857963 test_accuracy: 0.8546\n",
      "Iteraions 299: train_loss: 0.29447307824953184 train_accuracy: 0.8813 test_loss: 0.36252934348218213 test_accuracy: 0.8612\n",
      "Iteraions 300: train_loss: 0.2954082135272316 train_accuracy: 0.88035 test_loss: 0.3633786784194439 test_accuracy: 0.8543\n",
      "Iteraions 301: train_loss: 0.2952149994439352 train_accuracy: 0.8814166666666666 test_loss: 0.36145553967815464 test_accuracy: 0.8577\n",
      "Iteraions 302: train_loss: 0.29647006548162536 train_accuracy: 0.8809666666666667 test_loss: 0.35975964429421076 test_accuracy: 0.8576\n",
      "Iteraions 303: train_loss: 0.2944706223547565 train_accuracy: 0.8816 test_loss: 0.35774009895865194 test_accuracy: 0.8591\n",
      "Iteraions 304: train_loss: 0.2911104174160363 train_accuracy: 0.8817 test_loss: 0.358603878280157 test_accuracy: 0.8591\n",
      "Iteraions 305: train_loss: 0.2910677334102214 train_accuracy: 0.88225 test_loss: 0.35523525530630523 test_accuracy: 0.8581\n",
      "Iteraions 306: train_loss: 0.2917174769470531 train_accuracy: 0.8823166666666666 test_loss: 0.35811791701550544 test_accuracy: 0.8612\n",
      "Iteraions 307: train_loss: 0.2921084254832361 train_accuracy: 0.8822 test_loss: 0.35691287017642 test_accuracy: 0.8578\n",
      "Iteraions 308: train_loss: 0.29220097083552865 train_accuracy: 0.8815833333333334 test_loss: 0.3583515543242194 test_accuracy: 0.8586\n",
      "Iteraions 309: train_loss: 0.28960737858476193 train_accuracy: 0.8827333333333334 test_loss: 0.35579690491846233 test_accuracy: 0.86\n",
      "Iteraions 310: train_loss: 0.2897944645509187 train_accuracy: 0.8837 test_loss: 0.35702187798771046 test_accuracy: 0.8592\n",
      "Iteraions 311: train_loss: 0.2892402416034145 train_accuracy: 0.8832833333333333 test_loss: 0.35514782994821065 test_accuracy: 0.8614\n",
      "Iteraions 312: train_loss: 0.28908326806026097 train_accuracy: 0.8834166666666666 test_loss: 0.35687839218374373 test_accuracy: 0.859\n",
      "Iteraions 313: train_loss: 0.28698937971802213 train_accuracy: 0.8850666666666667 test_loss: 0.3550865872438455 test_accuracy: 0.8606\n",
      "Iteraions 314: train_loss: 0.28699192123696327 train_accuracy: 0.8839 test_loss: 0.3546749847537852 test_accuracy: 0.8576\n",
      "Iteraions 315: train_loss: 0.28746564558999066 train_accuracy: 0.8840833333333333 test_loss: 0.35324128146054656 test_accuracy: 0.8622\n",
      "Iteraions 316: train_loss: 0.28507454265869503 train_accuracy: 0.8856 test_loss: 0.3564783063067843 test_accuracy: 0.8601\n",
      "Iteraions 317: train_loss: 0.28574672540093554 train_accuracy: 0.8838 test_loss: 0.35268881112136935 test_accuracy: 0.8606\n",
      "Iteraions 318: train_loss: 0.28538065964528003 train_accuracy: 0.88585 test_loss: 0.3527296433819243 test_accuracy: 0.8595\n",
      "Iteraions 319: train_loss: 0.28498783846899045 train_accuracy: 0.8852333333333333 test_loss: 0.356942606548241 test_accuracy: 0.8615\n",
      "Iteraions 320: train_loss: 0.2851967220739521 train_accuracy: 0.8861666666666667 test_loss: 0.35447282235311384 test_accuracy: 0.8585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 321: train_loss: 0.2849678921609925 train_accuracy: 0.8854 test_loss: 0.3545428593213295 test_accuracy: 0.8589\n",
      "Iteraions 322: train_loss: 0.2839776858142498 train_accuracy: 0.8860333333333333 test_loss: 0.35053593065736605 test_accuracy: 0.8633\n",
      "Iteraions 323: train_loss: 0.28277605342162127 train_accuracy: 0.8863833333333333 test_loss: 0.3531134135046323 test_accuracy: 0.8607\n",
      "Iteraions 324: train_loss: 0.28335771243070956 train_accuracy: 0.8862333333333333 test_loss: 0.35340940590918385 test_accuracy: 0.8597\n",
      "Iteraions 325: train_loss: 0.28254845921118105 train_accuracy: 0.8857166666666667 test_loss: 0.3537915464965955 test_accuracy: 0.86\n",
      "Iteraions 326: train_loss: 0.2818989866423286 train_accuracy: 0.8865166666666666 test_loss: 0.3558151203713212 test_accuracy: 0.8606\n",
      "Iteraions 327: train_loss: 0.281124529611213 train_accuracy: 0.8873833333333333 test_loss: 0.3519519944221328 test_accuracy: 0.8617\n",
      "Iteraions 328: train_loss: 0.2803727368417007 train_accuracy: 0.887 test_loss: 0.35308581903600483 test_accuracy: 0.8617\n",
      "Iteraions 329: train_loss: 0.2791344925474302 train_accuracy: 0.8868666666666667 test_loss: 0.351782216799861 test_accuracy: 0.8597\n",
      "Iteraions 330: train_loss: 0.27851577239457154 train_accuracy: 0.8869166666666667 test_loss: 0.34912297617415644 test_accuracy: 0.8623\n",
      "Iteraions 331: train_loss: 0.2798473409434562 train_accuracy: 0.8865833333333333 test_loss: 0.34979592051989866 test_accuracy: 0.8631\n",
      "Iteraions 332: train_loss: 0.27876328910826753 train_accuracy: 0.8879166666666667 test_loss: 0.35054778392936575 test_accuracy: 0.863\n",
      "Iteraions 333: train_loss: 0.2778149105428478 train_accuracy: 0.8885333333333333 test_loss: 0.34808814225982526 test_accuracy: 0.8653\n",
      "Iteraions 334: train_loss: 0.2778846637744258 train_accuracy: 0.8882666666666666 test_loss: 0.35240711443796097 test_accuracy: 0.8639\n",
      "Iteraions 335: train_loss: 0.2779752893586355 train_accuracy: 0.8885333333333333 test_loss: 0.34671791837829385 test_accuracy: 0.8626\n",
      "Iteraions 336: train_loss: 0.2775531843099585 train_accuracy: 0.8889833333333333 test_loss: 0.35392797575561136 test_accuracy: 0.8639\n",
      "Iteraions 337: train_loss: 0.2777680323191128 train_accuracy: 0.8877333333333334 test_loss: 0.34981203113255377 test_accuracy: 0.8624\n",
      "Iteraions 338: train_loss: 0.27459397886652137 train_accuracy: 0.8901333333333333 test_loss: 0.3491287013747463 test_accuracy: 0.8633\n",
      "Iteraions 339: train_loss: 0.2761734286257923 train_accuracy: 0.8891166666666667 test_loss: 0.3492600054411488 test_accuracy: 0.8648\n",
      "Iteraions 340: train_loss: 0.27484863055919095 train_accuracy: 0.8889833333333333 test_loss: 0.34923865301666807 test_accuracy: 0.8624\n",
      "Iteraions 341: train_loss: 0.2763063495778947 train_accuracy: 0.8890666666666667 test_loss: 0.3483682089192097 test_accuracy: 0.8628\n",
      "Iteraions 342: train_loss: 0.2747746491605554 train_accuracy: 0.8897 test_loss: 0.34815275940280227 test_accuracy: 0.8631\n",
      "Iteraions 343: train_loss: 0.27443613892420193 train_accuracy: 0.8895166666666666 test_loss: 0.34907384586443146 test_accuracy: 0.8643\n",
      "Iteraions 344: train_loss: 0.27319339632146816 train_accuracy: 0.88895 test_loss: 0.3489909914475291 test_accuracy: 0.862\n",
      "Iteraions 345: train_loss: 0.27363540027329036 train_accuracy: 0.8896 test_loss: 0.34847793467602584 test_accuracy: 0.8634\n",
      "Iteraions 346: train_loss: 0.27317812148935955 train_accuracy: 0.8906 test_loss: 0.34865587050393315 test_accuracy: 0.8677\n",
      "Iteraions 347: train_loss: 0.2726880690808818 train_accuracy: 0.8902666666666667 test_loss: 0.3443708023015935 test_accuracy: 0.8647\n",
      "Iteraions 348: train_loss: 0.27235950209444454 train_accuracy: 0.8894666666666666 test_loss: 0.345832845767929 test_accuracy: 0.8652\n",
      "Iteraions 349: train_loss: 0.27130057725456863 train_accuracy: 0.89125 test_loss: 0.3475220512058351 test_accuracy: 0.8613\n",
      "Iteraions 350: train_loss: 0.2717425323311983 train_accuracy: 0.8901333333333333 test_loss: 0.35180437817437665 test_accuracy: 0.862\n",
      "Iteraions 351: train_loss: 0.2706291083450051 train_accuracy: 0.8907833333333334 test_loss: 0.3484120062227635 test_accuracy: 0.8655\n",
      "Iteraions 352: train_loss: 0.2703243763374072 train_accuracy: 0.8915333333333333 test_loss: 0.3476332267271187 test_accuracy: 0.8602\n",
      "Iteraions 353: train_loss: 0.26902228683913865 train_accuracy: 0.8908833333333334 test_loss: 0.3447654982369402 test_accuracy: 0.8662\n",
      "Iteraions 354: train_loss: 0.2692920310584708 train_accuracy: 0.8917 test_loss: 0.3452739031115779 test_accuracy: 0.8625\n",
      "Iteraions 355: train_loss: 0.26898672091747117 train_accuracy: 0.8907833333333334 test_loss: 0.34488322226749624 test_accuracy: 0.8654\n",
      "Iteraions 356: train_loss: 0.26824486815498927 train_accuracy: 0.8923166666666666 test_loss: 0.3476904018883943 test_accuracy: 0.8653\n",
      "Iteraions 357: train_loss: 0.2690795656335713 train_accuracy: 0.8915 test_loss: 0.3482463900619964 test_accuracy: 0.8665\n",
      "Iteraions 358: train_loss: 0.2688851506685503 train_accuracy: 0.8920333333333333 test_loss: 0.34520286978841225 test_accuracy: 0.8668\n",
      "Iteraions 359: train_loss: 0.26876516509993836 train_accuracy: 0.8916666666666667 test_loss: 0.3446423797600134 test_accuracy: 0.8662\n",
      "Iteraions 360: train_loss: 0.26603981611448774 train_accuracy: 0.8925333333333333 test_loss: 0.3459745197885201 test_accuracy: 0.8679\n",
      "Iteraions 361: train_loss: 0.26634621441710415 train_accuracy: 0.8923666666666666 test_loss: 0.3466791603717892 test_accuracy: 0.8635\n",
      "Iteraions 362: train_loss: 0.2673877222934548 train_accuracy: 0.8919666666666667 test_loss: 0.34546812592649445 test_accuracy: 0.8649\n",
      "Iteraions 363: train_loss: 0.26677308807571604 train_accuracy: 0.8922833333333333 test_loss: 0.34339915510309327 test_accuracy: 0.8666\n",
      "Iteraions 364: train_loss: 0.26611816150065276 train_accuracy: 0.8927666666666667 test_loss: 0.34553269860303637 test_accuracy: 0.865\n",
      "Iteraions 365: train_loss: 0.26701051858765 train_accuracy: 0.8920666666666667 test_loss: 0.3466473783250387 test_accuracy: 0.864\n",
      "Iteraions 366: train_loss: 0.26726443751435225 train_accuracy: 0.8933333333333333 test_loss: 0.34723675709319907 test_accuracy: 0.8645\n",
      "Iteraions 367: train_loss: 0.2658467708746482 train_accuracy: 0.8920333333333333 test_loss: 0.3436341100685005 test_accuracy: 0.8666\n",
      "Iteraions 368: train_loss: 0.2663571524729979 train_accuracy: 0.8936166666666666 test_loss: 0.3445572791815494 test_accuracy: 0.8677\n",
      "Iteraions 369: train_loss: 0.2665191894753712 train_accuracy: 0.8919666666666667 test_loss: 0.3493004547161904 test_accuracy: 0.8645\n",
      "Iteraions 370: train_loss: 0.2652773286449176 train_accuracy: 0.8935833333333333 test_loss: 0.34703133275590653 test_accuracy: 0.8631\n",
      "Iteraions 371: train_loss: 0.2649256742819805 train_accuracy: 0.8920666666666667 test_loss: 0.3428746707813677 test_accuracy: 0.8646\n",
      "Iteraions 372: train_loss: 0.2621872420539145 train_accuracy: 0.8952833333333333 test_loss: 0.3457498452664358 test_accuracy: 0.8676\n",
      "Iteraions 373: train_loss: 0.2617634749095324 train_accuracy: 0.8940666666666667 test_loss: 0.3453168237853198 test_accuracy: 0.8651\n",
      "Iteraions 374: train_loss: 0.2625485289197474 train_accuracy: 0.8941 test_loss: 0.3414580782657961 test_accuracy: 0.8677\n",
      "Iteraions 375: train_loss: 0.26201266537725565 train_accuracy: 0.8948666666666667 test_loss: 0.34056592790929474 test_accuracy: 0.8656\n",
      "Iteraions 376: train_loss: 0.26180980436906415 train_accuracy: 0.8948166666666667 test_loss: 0.34924440058584133 test_accuracy: 0.8636\n",
      "Iteraions 377: train_loss: 0.26179003045667826 train_accuracy: 0.8938166666666667 test_loss: 0.34671474350931575 test_accuracy: 0.8659\n",
      "Iteraions 378: train_loss: 0.2608762728345931 train_accuracy: 0.8951833333333333 test_loss: 0.3390144844753753 test_accuracy: 0.866\n",
      "Iteraions 379: train_loss: 0.2606385624626553 train_accuracy: 0.89555 test_loss: 0.3409487430306396 test_accuracy: 0.8666\n",
      "Iteraions 380: train_loss: 0.25995132410098476 train_accuracy: 0.8953333333333333 test_loss: 0.34139140782405275 test_accuracy: 0.8678\n",
      "Iteraions 381: train_loss: 0.25982939050168985 train_accuracy: 0.8953666666666666 test_loss: 0.34516313347327615 test_accuracy: 0.8676\n",
      "Iteraions 382: train_loss: 0.2605034810855264 train_accuracy: 0.8943833333333333 test_loss: 0.3410269293606446 test_accuracy: 0.8677\n",
      "Iteraions 383: train_loss: 0.26053094371385405 train_accuracy: 0.8959666666666667 test_loss: 0.34032708291659786 test_accuracy: 0.8691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 384: train_loss: 0.25765811611985184 train_accuracy: 0.8956333333333333 test_loss: 0.34536688057260334 test_accuracy: 0.8689\n",
      "Iteraions 385: train_loss: 0.2569142211431136 train_accuracy: 0.8966166666666666 test_loss: 0.34140314840023767 test_accuracy: 0.8672\n",
      "Iteraions 386: train_loss: 0.2588865946550013 train_accuracy: 0.8957166666666667 test_loss: 0.3483842992485266 test_accuracy: 0.8636\n",
      "Iteraions 387: train_loss: 0.25842220060036014 train_accuracy: 0.8954833333333333 test_loss: 0.342386790985608 test_accuracy: 0.8685\n",
      "Iteraions 388: train_loss: 0.2580836543505375 train_accuracy: 0.8960666666666667 test_loss: 0.34274464554613515 test_accuracy: 0.8683\n",
      "Iteraions 389: train_loss: 0.2556740805759563 train_accuracy: 0.8969166666666667 test_loss: 0.34044896459909674 test_accuracy: 0.8693\n",
      "Iteraions 390: train_loss: 0.2556682816786795 train_accuracy: 0.8969833333333334 test_loss: 0.3406977710779185 test_accuracy: 0.8681\n",
      "Iteraions 391: train_loss: 0.2559837913458963 train_accuracy: 0.89665 test_loss: 0.3432760019550873 test_accuracy: 0.8668\n",
      "Iteraions 392: train_loss: 0.2574762486642606 train_accuracy: 0.8967333333333334 test_loss: 0.3380881081712659 test_accuracy: 0.8703\n",
      "Iteraions 393: train_loss: 0.2548849844964087 train_accuracy: 0.8962333333333333 test_loss: 0.3432299533298854 test_accuracy: 0.87\n",
      "Iteraions 394: train_loss: 0.2567350285647467 train_accuracy: 0.8967833333333334 test_loss: 0.34080194069121444 test_accuracy: 0.868\n",
      "Iteraions 395: train_loss: 0.25423291763587164 train_accuracy: 0.8968166666666667 test_loss: 0.34375049006178615 test_accuracy: 0.8686\n",
      "Iteraions 396: train_loss: 0.2553398622620421 train_accuracy: 0.8968166666666667 test_loss: 0.342053522902259 test_accuracy: 0.8682\n",
      "Iteraions 397: train_loss: 0.25446174721362064 train_accuracy: 0.8966333333333333 test_loss: 0.34368558613792977 test_accuracy: 0.8683\n",
      "Iteraions 398: train_loss: 0.2527917284143925 train_accuracy: 0.8982333333333333 test_loss: 0.3372136425071256 test_accuracy: 0.8688\n",
      "Iteraions 399: train_loss: 0.2535352928599231 train_accuracy: 0.8982833333333333 test_loss: 0.3384358994888695 test_accuracy: 0.8675\n",
      "Iteraions 400: train_loss: 0.25391733639389363 train_accuracy: 0.89735 test_loss: 0.34378941487863474 test_accuracy: 0.8659\n",
      "Iteraions 401: train_loss: 0.2514731535833018 train_accuracy: 0.8981 test_loss: 0.3468606392205136 test_accuracy: 0.8651\n",
      "Iteraions 402: train_loss: 0.25291830924356085 train_accuracy: 0.8977666666666667 test_loss: 0.3410520272971131 test_accuracy: 0.8679\n",
      "Iteraions 403: train_loss: 0.25114416433347725 train_accuracy: 0.8987333333333334 test_loss: 0.34160560513530336 test_accuracy: 0.8671\n",
      "Iteraions 404: train_loss: 0.25126412202479187 train_accuracy: 0.8981166666666667 test_loss: 0.33719967095298226 test_accuracy: 0.869\n",
      "Iteraions 405: train_loss: 0.25171571675594306 train_accuracy: 0.8987166666666667 test_loss: 0.34381744921620877 test_accuracy: 0.8672\n",
      "Iteraions 406: train_loss: 0.25340106624593783 train_accuracy: 0.8977166666666667 test_loss: 0.33990295823045474 test_accuracy: 0.8691\n",
      "Iteraions 407: train_loss: 0.2510501159745988 train_accuracy: 0.8987 test_loss: 0.3426717061881326 test_accuracy: 0.8692\n",
      "Iteraions 408: train_loss: 0.25202593200165785 train_accuracy: 0.8975833333333333 test_loss: 0.34028557438521156 test_accuracy: 0.8706\n",
      "Iteraions 409: train_loss: 0.24915093472655092 train_accuracy: 0.90035 test_loss: 0.3403756131910099 test_accuracy: 0.8678\n",
      "Iteraions 410: train_loss: 0.24962282687455448 train_accuracy: 0.8994166666666666 test_loss: 0.3396606675170244 test_accuracy: 0.8706\n",
      "Iteraions 411: train_loss: 0.24778365403196403 train_accuracy: 0.8999166666666667 test_loss: 0.34091232491739343 test_accuracy: 0.8723\n",
      "Iteraions 412: train_loss: 0.2480996197777553 train_accuracy: 0.9005333333333333 test_loss: 0.337815464636243 test_accuracy: 0.87\n",
      "Iteraions 413: train_loss: 0.2477794744477431 train_accuracy: 0.9005166666666666 test_loss: 0.33944139702360254 test_accuracy: 0.8722\n",
      "Iteraions 414: train_loss: 0.2479997521054906 train_accuracy: 0.9003666666666666 test_loss: 0.3378198613735524 test_accuracy: 0.8692\n",
      "Iteraions 415: train_loss: 0.24800690252256846 train_accuracy: 0.9005333333333333 test_loss: 0.3354958279226841 test_accuracy: 0.8721\n",
      "Iteraions 416: train_loss: 0.2459940384647874 train_accuracy: 0.9011 test_loss: 0.33840496514185886 test_accuracy: 0.8719\n",
      "Iteraions 417: train_loss: 0.2460738563882383 train_accuracy: 0.9013166666666667 test_loss: 0.3428669810028042 test_accuracy: 0.8686\n",
      "Iteraions 418: train_loss: 0.24663702541297805 train_accuracy: 0.89995 test_loss: 0.33993482536417385 test_accuracy: 0.8686\n",
      "Iteraions 419: train_loss: 0.24529410624355677 train_accuracy: 0.90075 test_loss: 0.33852431543883754 test_accuracy: 0.8735\n",
      "Iteraions 420: train_loss: 0.2445548825358001 train_accuracy: 0.9018666666666667 test_loss: 0.33593344980700424 test_accuracy: 0.8718\n",
      "Iteraions 421: train_loss: 0.24442286369805652 train_accuracy: 0.9018333333333334 test_loss: 0.33493280415449805 test_accuracy: 0.8723\n",
      "Iteraions 422: train_loss: 0.24377723247148378 train_accuracy: 0.9012833333333333 test_loss: 0.3356794488311214 test_accuracy: 0.8717\n",
      "Iteraions 423: train_loss: 0.24411719621691522 train_accuracy: 0.9018833333333334 test_loss: 0.33991293214038043 test_accuracy: 0.8664\n",
      "Iteraions 424: train_loss: 0.24385779838995816 train_accuracy: 0.9019333333333334 test_loss: 0.3400804326590121 test_accuracy: 0.871\n",
      "Iteraions 425: train_loss: 0.24437049995177382 train_accuracy: 0.9014 test_loss: 0.3365695719005892 test_accuracy: 0.8711\n",
      "Iteraions 426: train_loss: 0.2428438982198358 train_accuracy: 0.9019166666666667 test_loss: 0.336201415567795 test_accuracy: 0.8746\n",
      "Iteraions 427: train_loss: 0.24241026416701753 train_accuracy: 0.9023166666666667 test_loss: 0.33826870091104044 test_accuracy: 0.8706\n",
      "Iteraions 428: train_loss: 0.24175381532381354 train_accuracy: 0.9032166666666667 test_loss: 0.3378382366135275 test_accuracy: 0.8694\n",
      "Iteraions 429: train_loss: 0.2419866106867766 train_accuracy: 0.9035333333333333 test_loss: 0.3374309440365476 test_accuracy: 0.8696\n",
      "Iteraions 430: train_loss: 0.24029262061518822 train_accuracy: 0.9028333333333334 test_loss: 0.337155592653043 test_accuracy: 0.8701\n",
      "Iteraions 431: train_loss: 0.2415354280363446 train_accuracy: 0.9030166666666667 test_loss: 0.3400156986037261 test_accuracy: 0.8697\n",
      "Iteraions 432: train_loss: 0.2423840544615463 train_accuracy: 0.9027666666666667 test_loss: 0.3342956588921123 test_accuracy: 0.8696\n",
      "Iteraions 433: train_loss: 0.24078876197708593 train_accuracy: 0.9032666666666667 test_loss: 0.33800131341672673 test_accuracy: 0.8704\n",
      "Iteraions 434: train_loss: 0.2399333215774742 train_accuracy: 0.9032833333333333 test_loss: 0.33618575268037143 test_accuracy: 0.8696\n",
      "Iteraions 435: train_loss: 0.24080867756324184 train_accuracy: 0.9043333333333333 test_loss: 0.3398402998856639 test_accuracy: 0.8729\n",
      "Iteraions 436: train_loss: 0.23901213714606756 train_accuracy: 0.9040666666666667 test_loss: 0.3327370546891816 test_accuracy: 0.8739\n",
      "Iteraions 437: train_loss: 0.24031591949930148 train_accuracy: 0.9031 test_loss: 0.34324706098347924 test_accuracy: 0.8715\n",
      "Iteraions 438: train_loss: 0.24045113148454578 train_accuracy: 0.9023666666666667 test_loss: 0.3385255687280196 test_accuracy: 0.8716\n",
      "Iteraions 439: train_loss: 0.24003885426802155 train_accuracy: 0.9030666666666667 test_loss: 0.33870815767968954 test_accuracy: 0.8699\n",
      "Iteraions 440: train_loss: 0.24027642277272404 train_accuracy: 0.9027833333333334 test_loss: 0.34032603855438703 test_accuracy: 0.8714\n",
      "Iteraions 441: train_loss: 0.23826311866722397 train_accuracy: 0.9041333333333333 test_loss: 0.3357322499578393 test_accuracy: 0.8719\n",
      "Iteraions 442: train_loss: 0.2394442875258205 train_accuracy: 0.9045 test_loss: 0.3348743159107916 test_accuracy: 0.8703\n",
      "Iteraions 443: train_loss: 0.23900905469352712 train_accuracy: 0.9032833333333333 test_loss: 0.33469186518358784 test_accuracy: 0.8737\n",
      "Iteraions 444: train_loss: 0.2388037995753864 train_accuracy: 0.90375 test_loss: 0.3380577324905017 test_accuracy: 0.8715\n",
      "Iteraions 445: train_loss: 0.2364768439673006 train_accuracy: 0.9052666666666667 test_loss: 0.33492721282696436 test_accuracy: 0.8696\n",
      "Iteraions 446: train_loss: 0.23579306465427527 train_accuracy: 0.9052833333333333 test_loss: 0.33323789999979053 test_accuracy: 0.874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 447: train_loss: 0.23758635165478026 train_accuracy: 0.9041166666666667 test_loss: 0.3406877000869018 test_accuracy: 0.8691\n",
      "Iteraions 448: train_loss: 0.23563039820378284 train_accuracy: 0.9057833333333334 test_loss: 0.33430055941829734 test_accuracy: 0.8731\n",
      "Iteraions 449: train_loss: 0.23501939963751386 train_accuracy: 0.9053833333333333 test_loss: 0.33604266702045327 test_accuracy: 0.8726\n",
      "Iteraions 450: train_loss: 0.23518583970076307 train_accuracy: 0.9057666666666667 test_loss: 0.3301669591240562 test_accuracy: 0.875\n",
      "Iteraions 451: train_loss: 0.2347504386895847 train_accuracy: 0.9052833333333333 test_loss: 0.33196132973079995 test_accuracy: 0.8743\n",
      "Iteraions 452: train_loss: 0.2347073776489083 train_accuracy: 0.9062833333333333 test_loss: 0.3333882242109691 test_accuracy: 0.8725\n",
      "Iteraions 453: train_loss: 0.2344793935068268 train_accuracy: 0.9052833333333333 test_loss: 0.3344752940615764 test_accuracy: 0.874\n",
      "Iteraions 454: train_loss: 0.23363271972642916 train_accuracy: 0.9064 test_loss: 0.33555002834960995 test_accuracy: 0.8729\n",
      "Iteraions 455: train_loss: 0.23382875221950702 train_accuracy: 0.9068166666666667 test_loss: 0.33421096920426807 test_accuracy: 0.8717\n",
      "Iteraions 456: train_loss: 0.23152121035912768 train_accuracy: 0.907 test_loss: 0.33557717093155354 test_accuracy: 0.8734\n",
      "Iteraions 457: train_loss: 0.23232430299969 train_accuracy: 0.90565 test_loss: 0.33670428787759693 test_accuracy: 0.8731\n",
      "Iteraions 458: train_loss: 0.2338987755389069 train_accuracy: 0.9061166666666667 test_loss: 0.33544797031536894 test_accuracy: 0.8723\n",
      "Iteraions 459: train_loss: 0.2321676850487078 train_accuracy: 0.9065 test_loss: 0.33625239485752434 test_accuracy: 0.8734\n",
      "Iteraions 460: train_loss: 0.23179305210072917 train_accuracy: 0.9067833333333334 test_loss: 0.3376143304179979 test_accuracy: 0.8754\n",
      "Iteraions 461: train_loss: 0.23072193474661518 train_accuracy: 0.9062666666666667 test_loss: 0.33002036162249065 test_accuracy: 0.8736\n",
      "Iteraions 462: train_loss: 0.23150813474774457 train_accuracy: 0.9070666666666667 test_loss: 0.33503292004102986 test_accuracy: 0.8708\n",
      "Iteraions 463: train_loss: 0.23104431442894832 train_accuracy: 0.9071833333333333 test_loss: 0.33346027867295314 test_accuracy: 0.8729\n",
      "Iteraions 464: train_loss: 0.23123008170862794 train_accuracy: 0.90755 test_loss: 0.3307760082445606 test_accuracy: 0.873\n",
      "Iteraions 465: train_loss: 0.23060076285684142 train_accuracy: 0.9072166666666667 test_loss: 0.33502289169929217 test_accuracy: 0.8733\n",
      "Iteraions 466: train_loss: 0.2300637106028935 train_accuracy: 0.9074333333333333 test_loss: 0.3365004461692006 test_accuracy: 0.871\n",
      "Iteraions 467: train_loss: 0.23116222772473619 train_accuracy: 0.907 test_loss: 0.33612570527867736 test_accuracy: 0.8703\n",
      "Iteraions 468: train_loss: 0.2314078632519592 train_accuracy: 0.9071666666666667 test_loss: 0.3350954012530387 test_accuracy: 0.8715\n",
      "Iteraions 469: train_loss: 0.22899316507012454 train_accuracy: 0.9074166666666666 test_loss: 0.3389935334060715 test_accuracy: 0.8742\n",
      "Iteraions 470: train_loss: 0.22858502251199683 train_accuracy: 0.9089833333333334 test_loss: 0.33294335876422504 test_accuracy: 0.8728\n",
      "Iteraions 471: train_loss: 0.2270120709618955 train_accuracy: 0.90845 test_loss: 0.3352986903233833 test_accuracy: 0.8725\n",
      "Iteraions 472: train_loss: 0.22833259787649407 train_accuracy: 0.909 test_loss: 0.3388945490642242 test_accuracy: 0.8743\n",
      "Iteraions 473: train_loss: 0.2293253328716626 train_accuracy: 0.9074166666666666 test_loss: 0.3357692005487649 test_accuracy: 0.8707\n",
      "Iteraions 474: train_loss: 0.22964606267656504 train_accuracy: 0.9082666666666667 test_loss: 0.33992615448157865 test_accuracy: 0.8718\n",
      "Iteraions 475: train_loss: 0.22890313322964098 train_accuracy: 0.9070833333333334 test_loss: 0.33483857083837865 test_accuracy: 0.872\n",
      "Iteraions 476: train_loss: 0.2278322637929178 train_accuracy: 0.9089 test_loss: 0.33737291749976667 test_accuracy: 0.8766\n",
      "Iteraions 477: train_loss: 0.22872836836158975 train_accuracy: 0.9080333333333334 test_loss: 0.33650463645278905 test_accuracy: 0.8742\n",
      "Iteraions 478: train_loss: 0.22932778664819523 train_accuracy: 0.9081666666666667 test_loss: 0.33912456151092174 test_accuracy: 0.8719\n",
      "Iteraions 479: train_loss: 0.22820935020889804 train_accuracy: 0.9071833333333333 test_loss: 0.33515144651357875 test_accuracy: 0.8735\n",
      "Iteraions 480: train_loss: 0.2270404674423254 train_accuracy: 0.9088 test_loss: 0.33399885389116285 test_accuracy: 0.8731\n",
      "Iteraions 481: train_loss: 0.22541325036808194 train_accuracy: 0.91 test_loss: 0.33750907957169607 test_accuracy: 0.8742\n",
      "Iteraions 482: train_loss: 0.2241600175852776 train_accuracy: 0.9096166666666666 test_loss: 0.33436705787846616 test_accuracy: 0.8735\n",
      "Iteraions 483: train_loss: 0.22499226175741932 train_accuracy: 0.9097666666666666 test_loss: 0.3361911558762463 test_accuracy: 0.8741\n",
      "Iteraions 484: train_loss: 0.22492404665773538 train_accuracy: 0.9098166666666667 test_loss: 0.33245024307239784 test_accuracy: 0.8766\n",
      "Iteraions 485: train_loss: 0.2238241970021227 train_accuracy: 0.90935 test_loss: 0.33376347049649696 test_accuracy: 0.8749\n",
      "Iteraions 486: train_loss: 0.22362825873233413 train_accuracy: 0.9108 test_loss: 0.33280631280112366 test_accuracy: 0.8748\n",
      "Iteraions 487: train_loss: 0.22494952546482963 train_accuracy: 0.9094 test_loss: 0.33907842290225626 test_accuracy: 0.8732\n",
      "Iteraions 488: train_loss: 0.22340830580528967 train_accuracy: 0.9094 test_loss: 0.3369367966739931 test_accuracy: 0.8744\n",
      "Iteraions 489: train_loss: 0.2218112535492833 train_accuracy: 0.9106333333333333 test_loss: 0.3363128381511436 test_accuracy: 0.8767\n",
      "Iteraions 490: train_loss: 0.22207002762919437 train_accuracy: 0.9111333333333334 test_loss: 0.32730324543417216 test_accuracy: 0.8726\n",
      "Iteraions 491: train_loss: 0.22169363223214247 train_accuracy: 0.91125 test_loss: 0.33493264094549063 test_accuracy: 0.8764\n",
      "Iteraions 492: train_loss: 0.22272285727844307 train_accuracy: 0.9111166666666667 test_loss: 0.3341250773930229 test_accuracy: 0.8751\n",
      "Iteraions 493: train_loss: 0.2219382558873695 train_accuracy: 0.9099 test_loss: 0.3372056497413581 test_accuracy: 0.8741\n",
      "Iteraions 494: train_loss: 0.22175276438077804 train_accuracy: 0.9115833333333333 test_loss: 0.3394243798187164 test_accuracy: 0.8747\n",
      "Iteraions 495: train_loss: 0.22153940680893927 train_accuracy: 0.9112166666666667 test_loss: 0.33165039088392234 test_accuracy: 0.8737\n",
      "Iteraions 496: train_loss: 0.22047188663168277 train_accuracy: 0.9119333333333334 test_loss: 0.33116856357036806 test_accuracy: 0.8747\n",
      "Iteraions 497: train_loss: 0.22077487432326293 train_accuracy: 0.9120833333333334 test_loss: 0.33322567856888713 test_accuracy: 0.8745\n",
      "Iteraions 498: train_loss: 0.22163200249532877 train_accuracy: 0.911 test_loss: 0.3318960582733538 test_accuracy: 0.8766\n",
      "Iteraions 499: train_loss: 0.2196221024186905 train_accuracy: 0.9114 test_loss: 0.33295394681955803 test_accuracy: 0.8751\n",
      "Iteraions 500: train_loss: 0.21838111299047144 train_accuracy: 0.91285 test_loss: 0.33379439328015104 test_accuracy: 0.8756\n",
      "Iteraions 501: train_loss: 0.2189726048471266 train_accuracy: 0.9127833333333333 test_loss: 0.33306475889989934 test_accuracy: 0.8768\n",
      "Iteraions 502: train_loss: 0.21955751108623225 train_accuracy: 0.9123333333333333 test_loss: 0.33088017014450427 test_accuracy: 0.8768\n",
      "Iteraions 503: train_loss: 0.2192132366565634 train_accuracy: 0.9116833333333333 test_loss: 0.3370377108755447 test_accuracy: 0.8749\n",
      "Iteraions 504: train_loss: 0.21863281623013864 train_accuracy: 0.9133 test_loss: 0.3321086039564176 test_accuracy: 0.8754\n",
      "Iteraions 505: train_loss: 0.2179616104572492 train_accuracy: 0.9129333333333334 test_loss: 0.33871318072517115 test_accuracy: 0.8752\n",
      "Iteraions 506: train_loss: 0.21626215610461788 train_accuracy: 0.9134666666666666 test_loss: 0.3352536049755755 test_accuracy: 0.8735\n",
      "Iteraions 507: train_loss: 0.2163660497214587 train_accuracy: 0.9128 test_loss: 0.33174341002366536 test_accuracy: 0.8765\n",
      "Iteraions 508: train_loss: 0.21807552902560068 train_accuracy: 0.9127333333333333 test_loss: 0.3369897080374586 test_accuracy: 0.8742\n",
      "Iteraions 509: train_loss: 0.2180593053350347 train_accuracy: 0.9130833333333334 test_loss: 0.33392891462933405 test_accuracy: 0.8741\n",
      "Iteraions 510: train_loss: 0.2180477305080806 train_accuracy: 0.9131666666666667 test_loss: 0.3348966829684917 test_accuracy: 0.8731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 511: train_loss: 0.21853432107893023 train_accuracy: 0.91245 test_loss: 0.3290256298739184 test_accuracy: 0.8748\n",
      "Iteraions 512: train_loss: 0.21656713277941508 train_accuracy: 0.9131333333333334 test_loss: 0.3340408643644162 test_accuracy: 0.8767\n",
      "Iteraions 513: train_loss: 0.21824150299242936 train_accuracy: 0.9132333333333333 test_loss: 0.3355984131211652 test_accuracy: 0.8755\n",
      "Iteraions 514: train_loss: 0.21898890098272683 train_accuracy: 0.91065 test_loss: 0.333960992580153 test_accuracy: 0.8752\n",
      "Iteraions 515: train_loss: 0.21715585202602078 train_accuracy: 0.9122333333333333 test_loss: 0.33440615827869735 test_accuracy: 0.8749\n",
      "Iteraions 516: train_loss: 0.21417405450420127 train_accuracy: 0.9148333333333334 test_loss: 0.3329070275462946 test_accuracy: 0.8769\n",
      "Iteraions 517: train_loss: 0.21529842877748717 train_accuracy: 0.9142833333333333 test_loss: 0.33270479597628744 test_accuracy: 0.8751\n",
      "Iteraions 518: train_loss: 0.21707522027523524 train_accuracy: 0.9123166666666667 test_loss: 0.3390979727323622 test_accuracy: 0.8756\n",
      "Iteraions 519: train_loss: 0.217307098188261 train_accuracy: 0.91275 test_loss: 0.3352221142934359 test_accuracy: 0.8762\n",
      "Iteraions 520: train_loss: 0.21433894033923523 train_accuracy: 0.9139833333333334 test_loss: 0.3313992473276663 test_accuracy: 0.8749\n",
      "Iteraions 521: train_loss: 0.21445731432344411 train_accuracy: 0.9144 test_loss: 0.334513785109264 test_accuracy: 0.8762\n",
      "Iteraions 522: train_loss: 0.2152733623926832 train_accuracy: 0.9138 test_loss: 0.33901561206354835 test_accuracy: 0.8766\n",
      "Iteraions 523: train_loss: 0.21549230614924295 train_accuracy: 0.9143 test_loss: 0.3367331850570908 test_accuracy: 0.8735\n",
      "Iteraions 524: train_loss: 0.21368376169830833 train_accuracy: 0.9140333333333334 test_loss: 0.3333564084703036 test_accuracy: 0.8756\n",
      "Iteraions 525: train_loss: 0.21266452630781266 train_accuracy: 0.9152833333333333 test_loss: 0.33599416390880266 test_accuracy: 0.8784\n",
      "Iteraions 526: train_loss: 0.21214978611461036 train_accuracy: 0.9144333333333333 test_loss: 0.3343791129324898 test_accuracy: 0.8743\n",
      "Iteraions 527: train_loss: 0.21184172125723902 train_accuracy: 0.91605 test_loss: 0.33040317675454706 test_accuracy: 0.8769\n",
      "Iteraions 528: train_loss: 0.21076731662450537 train_accuracy: 0.9161 test_loss: 0.3410964466916102 test_accuracy: 0.8741\n",
      "Iteraions 529: train_loss: 0.21162032173091638 train_accuracy: 0.91555 test_loss: 0.33317372755548863 test_accuracy: 0.8757\n",
      "Iteraions 530: train_loss: 0.21288869273972305 train_accuracy: 0.9151 test_loss: 0.33741585935066715 test_accuracy: 0.8774\n",
      "Iteraions 531: train_loss: 0.21251399651667796 train_accuracy: 0.9152333333333333 test_loss: 0.339069992801608 test_accuracy: 0.8752\n",
      "Iteraions 532: train_loss: 0.21232483307267197 train_accuracy: 0.9149 test_loss: 0.33452919651454266 test_accuracy: 0.8768\n",
      "Iteraions 533: train_loss: 0.2115858918759137 train_accuracy: 0.9161833333333333 test_loss: 0.33048335174938054 test_accuracy: 0.8776\n",
      "Iteraions 534: train_loss: 0.21124306408769614 train_accuracy: 0.9153333333333333 test_loss: 0.3299967318946886 test_accuracy: 0.8778\n",
      "Iteraions 535: train_loss: 0.21067775928831523 train_accuracy: 0.9160166666666667 test_loss: 0.33296066969447874 test_accuracy: 0.8771\n",
      "Iteraions 536: train_loss: 0.21008062665285315 train_accuracy: 0.9156833333333333 test_loss: 0.3341471634495437 test_accuracy: 0.8776\n",
      "Iteraions 537: train_loss: 0.20838244197932315 train_accuracy: 0.9167 test_loss: 0.32904309583668234 test_accuracy: 0.8792\n",
      "Iteraions 538: train_loss: 0.2112879554822819 train_accuracy: 0.9154833333333333 test_loss: 0.3367226446319289 test_accuracy: 0.8771\n",
      "Iteraions 539: train_loss: 0.2099235264588025 train_accuracy: 0.9151 test_loss: 0.33318180733132086 test_accuracy: 0.8751\n",
      "Iteraions 540: train_loss: 0.20829954232849085 train_accuracy: 0.9170166666666667 test_loss: 0.3330766226061932 test_accuracy: 0.8776\n",
      "Iteraions 541: train_loss: 0.20767050905472376 train_accuracy: 0.9166333333333333 test_loss: 0.33483257506705505 test_accuracy: 0.8783\n",
      "Iteraions 542: train_loss: 0.21054325895897752 train_accuracy: 0.9157166666666666 test_loss: 0.3345640130110782 test_accuracy: 0.8789\n",
      "Iteraions 543: train_loss: 0.2084356313078086 train_accuracy: 0.9168833333333334 test_loss: 0.3323978358737477 test_accuracy: 0.8766\n",
      "Iteraions 544: train_loss: 0.206315214325917 train_accuracy: 0.91745 test_loss: 0.3303591970532651 test_accuracy: 0.8778\n",
      "Iteraions 545: train_loss: 0.20602619129015975 train_accuracy: 0.9176 test_loss: 0.33512539445709394 test_accuracy: 0.876\n",
      "Iteraions 546: train_loss: 0.2061566370956723 train_accuracy: 0.9180333333333334 test_loss: 0.33361194972364266 test_accuracy: 0.8756\n",
      "Iteraions 547: train_loss: 0.2088593780475001 train_accuracy: 0.9163333333333333 test_loss: 0.32921902347703563 test_accuracy: 0.8783\n",
      "Iteraions 548: train_loss: 0.20778468460860758 train_accuracy: 0.9163166666666667 test_loss: 0.33361451116408886 test_accuracy: 0.8795\n",
      "Iteraions 549: train_loss: 0.2062221933790152 train_accuracy: 0.9185333333333333 test_loss: 0.33262555130468957 test_accuracy: 0.8788\n",
      "Iteraions 550: train_loss: 0.20634203314252522 train_accuracy: 0.9173833333333333 test_loss: 0.32833768451726303 test_accuracy: 0.8789\n",
      "Iteraions 551: train_loss: 0.20615786908264785 train_accuracy: 0.9179833333333334 test_loss: 0.33531077424361344 test_accuracy: 0.8788\n",
      "Iteraions 552: train_loss: 0.20546025850962826 train_accuracy: 0.9181333333333334 test_loss: 0.3351387238679373 test_accuracy: 0.8803\n",
      "Iteraions 553: train_loss: 0.2070206511975719 train_accuracy: 0.9167666666666666 test_loss: 0.33244516054027773 test_accuracy: 0.8791\n",
      "Iteraions 554: train_loss: 0.2043359980681974 train_accuracy: 0.91865 test_loss: 0.3353845293640412 test_accuracy: 0.8784\n",
      "Iteraions 555: train_loss: 0.2054083716252332 train_accuracy: 0.91765 test_loss: 0.3296642740040179 test_accuracy: 0.8786\n",
      "Iteraions 556: train_loss: 0.20413373862271822 train_accuracy: 0.9187333333333333 test_loss: 0.3321008753390562 test_accuracy: 0.8771\n",
      "Iteraions 557: train_loss: 0.20426147848672643 train_accuracy: 0.9183333333333333 test_loss: 0.3312082742610614 test_accuracy: 0.8789\n",
      "Iteraions 558: train_loss: 0.20341824665423422 train_accuracy: 0.9189666666666667 test_loss: 0.33795200653808416 test_accuracy: 0.8777\n",
      "Iteraions 559: train_loss: 0.2032031995293537 train_accuracy: 0.9189166666666667 test_loss: 0.33709697123729554 test_accuracy: 0.8758\n",
      "Iteraions 560: train_loss: 0.20345012185482417 train_accuracy: 0.9193333333333333 test_loss: 0.3313953295769064 test_accuracy: 0.8809\n",
      "Iteraions 561: train_loss: 0.20317994126646663 train_accuracy: 0.9192 test_loss: 0.33292233314224623 test_accuracy: 0.8792\n",
      "Iteraions 562: train_loss: 0.2036206315195517 train_accuracy: 0.9189 test_loss: 0.32876993926224035 test_accuracy: 0.8789\n",
      "Iteraions 563: train_loss: 0.2010723726722316 train_accuracy: 0.9201 test_loss: 0.3332326721586069 test_accuracy: 0.8817\n",
      "Iteraions 564: train_loss: 0.20170172978383294 train_accuracy: 0.91995 test_loss: 0.3352673837345688 test_accuracy: 0.8769\n",
      "Iteraions 565: train_loss: 0.20315040497704576 train_accuracy: 0.9184333333333333 test_loss: 0.3340118230156336 test_accuracy: 0.8777\n",
      "Iteraions 566: train_loss: 0.20538199417036382 train_accuracy: 0.9187 test_loss: 0.3302785686637539 test_accuracy: 0.8782\n",
      "Iteraions 567: train_loss: 0.2039978291052822 train_accuracy: 0.9189 test_loss: 0.3370257682936342 test_accuracy: 0.8772\n",
      "Iteraions 568: train_loss: 0.20533626009635633 train_accuracy: 0.91805 test_loss: 0.3336989448758258 test_accuracy: 0.8769\n",
      "Iteraions 569: train_loss: 0.2035793535917045 train_accuracy: 0.9183833333333333 test_loss: 0.335405673057814 test_accuracy: 0.8764\n",
      "Iteraions 570: train_loss: 0.2019874494537163 train_accuracy: 0.92 test_loss: 0.33075672406359263 test_accuracy: 0.879\n",
      "Iteraions 571: train_loss: 0.20105304994316162 train_accuracy: 0.9208166666666666 test_loss: 0.3294553789433725 test_accuracy: 0.8791\n",
      "Iteraions 572: train_loss: 0.20045926069371295 train_accuracy: 0.9202666666666667 test_loss: 0.33103706683383505 test_accuracy: 0.882\n",
      "Iteraions 573: train_loss: 0.20274595897481432 train_accuracy: 0.9191833333333334 test_loss: 0.32950246785865184 test_accuracy: 0.8777\n",
      "Iteraions 574: train_loss: 0.20324937774214982 train_accuracy: 0.9195666666666666 test_loss: 0.3375391062624802 test_accuracy: 0.8765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 575: train_loss: 0.20342268369816546 train_accuracy: 0.9198833333333334 test_loss: 0.33538116421573305 test_accuracy: 0.8781\n",
      "Iteraions 576: train_loss: 0.2023468825038577 train_accuracy: 0.9186166666666666 test_loss: 0.3322361175267884 test_accuracy: 0.8778\n",
      "Iteraions 577: train_loss: 0.1995398720709738 train_accuracy: 0.9211666666666667 test_loss: 0.32983077966913 test_accuracy: 0.8797\n",
      "Iteraions 578: train_loss: 0.19664242518467734 train_accuracy: 0.9220666666666667 test_loss: 0.33064595831338883 test_accuracy: 0.8798\n",
      "Iteraions 579: train_loss: 0.19990904020087133 train_accuracy: 0.9196333333333333 test_loss: 0.33103512860149076 test_accuracy: 0.8794\n",
      "Iteraions 580: train_loss: 0.20032566166960572 train_accuracy: 0.9206166666666666 test_loss: 0.3398399241248734 test_accuracy: 0.8751\n",
      "Iteraions 581: train_loss: 0.2019185925293198 train_accuracy: 0.9191833333333334 test_loss: 0.3380490487518383 test_accuracy: 0.876\n",
      "Iteraions 582: train_loss: 0.20063651259790058 train_accuracy: 0.9205 test_loss: 0.3334569073470706 test_accuracy: 0.878\n",
      "Iteraions 583: train_loss: 0.19942209919744036 train_accuracy: 0.9201 test_loss: 0.334261315322624 test_accuracy: 0.8764\n",
      "Iteraions 584: train_loss: 0.19684628666924603 train_accuracy: 0.9216833333333333 test_loss: 0.3351086619195453 test_accuracy: 0.8792\n",
      "Iteraions 585: train_loss: 0.19717497599171152 train_accuracy: 0.9228833333333334 test_loss: 0.3379584704381814 test_accuracy: 0.879\n",
      "Iteraions 586: train_loss: 0.1993966760549317 train_accuracy: 0.9205 test_loss: 0.33943186623466187 test_accuracy: 0.8771\n",
      "Iteraions 587: train_loss: 0.2003688838062851 train_accuracy: 0.9202 test_loss: 0.3347170761504274 test_accuracy: 0.8785\n",
      "Iteraions 588: train_loss: 0.19798946183791707 train_accuracy: 0.9206833333333333 test_loss: 0.3384595941947001 test_accuracy: 0.8782\n",
      "Iteraions 589: train_loss: 0.19741121820841812 train_accuracy: 0.9211833333333334 test_loss: 0.3295823856107515 test_accuracy: 0.8804\n",
      "Iteraions 590: train_loss: 0.19723406159038737 train_accuracy: 0.92185 test_loss: 0.3353303332450071 test_accuracy: 0.8766\n",
      "Iteraions 591: train_loss: 0.19769127204379833 train_accuracy: 0.9209333333333334 test_loss: 0.3394693149461464 test_accuracy: 0.8775\n",
      "Iteraions 592: train_loss: 0.19662383068703063 train_accuracy: 0.9221333333333334 test_loss: 0.3364170014214472 test_accuracy: 0.8774\n",
      "Iteraions 593: train_loss: 0.1961545260624867 train_accuracy: 0.922 test_loss: 0.32983952303066616 test_accuracy: 0.8809\n",
      "Iteraions 594: train_loss: 0.19426563834185878 train_accuracy: 0.9234333333333333 test_loss: 0.33438630322995194 test_accuracy: 0.8787\n",
      "Iteraions 595: train_loss: 0.1948801790152401 train_accuracy: 0.9224 test_loss: 0.3337018720703735 test_accuracy: 0.8788\n",
      "Iteraions 596: train_loss: 0.1948820110484354 train_accuracy: 0.92285 test_loss: 0.337202117242778 test_accuracy: 0.8793\n",
      "Iteraions 597: train_loss: 0.19439319148086906 train_accuracy: 0.9240833333333334 test_loss: 0.33933217339979593 test_accuracy: 0.8777\n",
      "Iteraions 598: train_loss: 0.19507164632570523 train_accuracy: 0.92275 test_loss: 0.3325349975637633 test_accuracy: 0.8803\n",
      "Iteraions 599: train_loss: 0.19324284778432949 train_accuracy: 0.9239 test_loss: 0.33408361986677326 test_accuracy: 0.8792\n",
      "Iteraions 600: train_loss: 0.19319085497022617 train_accuracy: 0.923 test_loss: 0.3355320648871478 test_accuracy: 0.8795\n",
      "Iteraions 601: train_loss: 0.19415218876946996 train_accuracy: 0.9232 test_loss: 0.3385582412910765 test_accuracy: 0.8771\n",
      "Iteraions 602: train_loss: 0.1938970890512087 train_accuracy: 0.9240333333333334 test_loss: 0.33414156676122075 test_accuracy: 0.8807\n",
      "Iteraions 603: train_loss: 0.19238163061895622 train_accuracy: 0.9241333333333334 test_loss: 0.33107382668322743 test_accuracy: 0.8792\n",
      "Iteraions 604: train_loss: 0.19210826513312496 train_accuracy: 0.9243 test_loss: 0.3330812175917109 test_accuracy: 0.8788\n",
      "Iteraions 605: train_loss: 0.19046203893512428 train_accuracy: 0.92405 test_loss: 0.33502418845868953 test_accuracy: 0.8793\n",
      "Iteraions 606: train_loss: 0.19258603182792025 train_accuracy: 0.9227 test_loss: 0.3290551386565224 test_accuracy: 0.8809\n",
      "Iteraions 607: train_loss: 0.193596483626305 train_accuracy: 0.9223 test_loss: 0.3388057938611434 test_accuracy: 0.8768\n",
      "Iteraions 608: train_loss: 0.19105101224554003 train_accuracy: 0.92405 test_loss: 0.33146813619548393 test_accuracy: 0.882\n",
      "Iteraions 609: train_loss: 0.1915805224202523 train_accuracy: 0.9242666666666667 test_loss: 0.3303835659962772 test_accuracy: 0.8815\n",
      "Iteraions 610: train_loss: 0.19157961485736755 train_accuracy: 0.9236333333333333 test_loss: 0.33672468098227076 test_accuracy: 0.8805\n",
      "Iteraions 611: train_loss: 0.19093841709297046 train_accuracy: 0.9241166666666667 test_loss: 0.33852807098819004 test_accuracy: 0.8804\n",
      "Iteraions 612: train_loss: 0.19318139937728673 train_accuracy: 0.9235 test_loss: 0.335462980234754 test_accuracy: 0.8781\n",
      "Iteraions 613: train_loss: 0.19198085755266575 train_accuracy: 0.9248166666666666 test_loss: 0.33795552451340477 test_accuracy: 0.8795\n",
      "Iteraions 614: train_loss: 0.18946120289806456 train_accuracy: 0.9249666666666667 test_loss: 0.3338350643911104 test_accuracy: 0.8808\n",
      "Iteraions 615: train_loss: 0.18983685706840359 train_accuracy: 0.9260833333333334 test_loss: 0.3364710697358748 test_accuracy: 0.88\n",
      "Iteraions 616: train_loss: 0.18926110986835337 train_accuracy: 0.9250166666666667 test_loss: 0.33242401534909205 test_accuracy: 0.8794\n",
      "Iteraions 617: train_loss: 0.18940673235253785 train_accuracy: 0.9253666666666667 test_loss: 0.3316594965977037 test_accuracy: 0.8804\n",
      "Iteraions 618: train_loss: 0.18926010519224673 train_accuracy: 0.9247166666666666 test_loss: 0.340616733042157 test_accuracy: 0.8801\n",
      "Iteraions 619: train_loss: 0.188159485666528 train_accuracy: 0.9258833333333333 test_loss: 0.33494328384336186 test_accuracy: 0.8808\n",
      "Iteraions 620: train_loss: 0.18828514662539234 train_accuracy: 0.9257666666666666 test_loss: 0.33599901914587255 test_accuracy: 0.8809\n",
      "Iteraions 621: train_loss: 0.18878880480714 train_accuracy: 0.9263833333333333 test_loss: 0.332425851857219 test_accuracy: 0.8805\n",
      "Iteraions 622: train_loss: 0.1889173607016322 train_accuracy: 0.9254666666666667 test_loss: 0.3356793666461007 test_accuracy: 0.8788\n",
      "Iteraions 623: train_loss: 0.18731452679268684 train_accuracy: 0.9257666666666666 test_loss: 0.3330178282390886 test_accuracy: 0.8846\n",
      "Iteraions 624: train_loss: 0.18780707990740253 train_accuracy: 0.9261666666666667 test_loss: 0.33870326661171757 test_accuracy: 0.8801\n",
      "Iteraions 625: train_loss: 0.18722392598409673 train_accuracy: 0.9255 test_loss: 0.33528582393772605 test_accuracy: 0.8793\n",
      "Iteraions 626: train_loss: 0.18879470074195148 train_accuracy: 0.9250333333333334 test_loss: 0.33519167461667954 test_accuracy: 0.8817\n",
      "Iteraions 627: train_loss: 0.18660655175550486 train_accuracy: 0.9262666666666667 test_loss: 0.3331760293373163 test_accuracy: 0.8812\n",
      "Iteraions 628: train_loss: 0.18646051658060203 train_accuracy: 0.9263 test_loss: 0.3328884765531419 test_accuracy: 0.8803\n",
      "Iteraions 629: train_loss: 0.18573517232852668 train_accuracy: 0.9271833333333334 test_loss: 0.33753643990149346 test_accuracy: 0.8789\n",
      "Iteraions 630: train_loss: 0.1866743756203341 train_accuracy: 0.9268666666666666 test_loss: 0.3334124743458602 test_accuracy: 0.8801\n",
      "Iteraions 631: train_loss: 0.18571448065330595 train_accuracy: 0.92655 test_loss: 0.33611888789093736 test_accuracy: 0.8788\n",
      "Iteraions 632: train_loss: 0.1860886061705205 train_accuracy: 0.9272833333333333 test_loss: 0.33446816959396736 test_accuracy: 0.8779\n",
      "Iteraions 633: train_loss: 0.1874715630184135 train_accuracy: 0.9256166666666666 test_loss: 0.3333580293920284 test_accuracy: 0.8803\n",
      "Iteraions 634: train_loss: 0.18599288285661317 train_accuracy: 0.9265666666666666 test_loss: 0.33181126871419747 test_accuracy: 0.8806\n",
      "Iteraions 635: train_loss: 0.18346174021639827 train_accuracy: 0.9283666666666667 test_loss: 0.33874053848400015 test_accuracy: 0.8797\n",
      "Iteraions 636: train_loss: 0.18445935623138637 train_accuracy: 0.9259166666666667 test_loss: 0.3314345185008938 test_accuracy: 0.8794\n",
      "Iteraions 637: train_loss: 0.18364158356620103 train_accuracy: 0.9273 test_loss: 0.3353575621431831 test_accuracy: 0.8796\n",
      "Iteraions 638: train_loss: 0.1841728624866225 train_accuracy: 0.9272166666666667 test_loss: 0.3304591085438278 test_accuracy: 0.8791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 639: train_loss: 0.18522298329873524 train_accuracy: 0.9269 test_loss: 0.3320601654454734 test_accuracy: 0.8823\n",
      "Iteraions 640: train_loss: 0.18476684835299317 train_accuracy: 0.9267833333333333 test_loss: 0.336526922430773 test_accuracy: 0.8793\n",
      "Iteraions 641: train_loss: 0.18402671839080265 train_accuracy: 0.9278833333333333 test_loss: 0.3366492820854705 test_accuracy: 0.8828\n",
      "Iteraions 642: train_loss: 0.18391966274471325 train_accuracy: 0.9286166666666666 test_loss: 0.3367528077272908 test_accuracy: 0.8785\n",
      "Iteraions 643: train_loss: 0.1830542078651084 train_accuracy: 0.92635 test_loss: 0.33848730192290605 test_accuracy: 0.8809\n",
      "Iteraions 644: train_loss: 0.1837123108208379 train_accuracy: 0.92735 test_loss: 0.3345258073343165 test_accuracy: 0.8791\n",
      "Iteraions 645: train_loss: 0.1827479537568579 train_accuracy: 0.92895 test_loss: 0.33731870149298976 test_accuracy: 0.8802\n",
      "Iteraions 646: train_loss: 0.1839703872727838 train_accuracy: 0.9272333333333334 test_loss: 0.3376456345364215 test_accuracy: 0.88\n",
      "Iteraions 647: train_loss: 0.18405895302845246 train_accuracy: 0.9265666666666666 test_loss: 0.3414694064127572 test_accuracy: 0.8802\n",
      "Iteraions 648: train_loss: 0.18342973248538755 train_accuracy: 0.9282 test_loss: 0.3397218950353351 test_accuracy: 0.881\n",
      "Iteraions 649: train_loss: 0.1800834450997844 train_accuracy: 0.9287666666666666 test_loss: 0.3362024884255644 test_accuracy: 0.8811\n",
      "Iteraions 650: train_loss: 0.18041497660004086 train_accuracy: 0.9285833333333333 test_loss: 0.3359309392915085 test_accuracy: 0.8802\n",
      "Iteraions 651: train_loss: 0.18069377247290175 train_accuracy: 0.92855 test_loss: 0.3362441232828612 test_accuracy: 0.8811\n",
      "Iteraions 652: train_loss: 0.1818355043199149 train_accuracy: 0.92745 test_loss: 0.3380850937680857 test_accuracy: 0.88\n",
      "Iteraions 653: train_loss: 0.18207071299043284 train_accuracy: 0.9283166666666667 test_loss: 0.3398826764751666 test_accuracy: 0.8787\n",
      "Iteraions 654: train_loss: 0.1830438185648386 train_accuracy: 0.9280333333333334 test_loss: 0.336947664758506 test_accuracy: 0.8813\n",
      "Iteraions 655: train_loss: 0.18371848242691904 train_accuracy: 0.9278333333333333 test_loss: 0.34312148088879235 test_accuracy: 0.8787\n",
      "Iteraions 656: train_loss: 0.1833720142304772 train_accuracy: 0.9275833333333333 test_loss: 0.3378564875622229 test_accuracy: 0.8789\n",
      "Iteraions 657: train_loss: 0.18347501821266207 train_accuracy: 0.9275666666666667 test_loss: 0.3377316292632763 test_accuracy: 0.8802\n",
      "Iteraions 658: train_loss: 0.1811619341780727 train_accuracy: 0.9281166666666667 test_loss: 0.3368143690961664 test_accuracy: 0.8818\n",
      "Iteraions 659: train_loss: 0.1787952646589296 train_accuracy: 0.9313666666666667 test_loss: 0.3349066988796332 test_accuracy: 0.8791\n",
      "Iteraions 660: train_loss: 0.17979368704627324 train_accuracy: 0.9287333333333333 test_loss: 0.33843588203104846 test_accuracy: 0.8807\n",
      "Iteraions 661: train_loss: 0.17995124685832667 train_accuracy: 0.9283833333333333 test_loss: 0.3407866214029159 test_accuracy: 0.8796\n",
      "Iteraions 662: train_loss: 0.18095178659818695 train_accuracy: 0.9290666666666667 test_loss: 0.33938563819047257 test_accuracy: 0.8784\n",
      "Iteraions 663: train_loss: 0.1808226387494707 train_accuracy: 0.9286333333333333 test_loss: 0.33983068054884835 test_accuracy: 0.88\n",
      "Iteraions 664: train_loss: 0.18182309717438633 train_accuracy: 0.9281666666666667 test_loss: 0.3364395292660551 test_accuracy: 0.8778\n",
      "Iteraions 665: train_loss: 0.18104007855482362 train_accuracy: 0.9280666666666667 test_loss: 0.3387170487289555 test_accuracy: 0.8816\n",
      "Iteraions 666: train_loss: 0.18024677785890308 train_accuracy: 0.9306 test_loss: 0.33883213329324574 test_accuracy: 0.8822\n",
      "Iteraions 667: train_loss: 0.1796113565337227 train_accuracy: 0.9289 test_loss: 0.3370646220268459 test_accuracy: 0.8801\n",
      "Iteraions 668: train_loss: 0.17907714275974185 train_accuracy: 0.9295 test_loss: 0.33097413081770344 test_accuracy: 0.8813\n",
      "Iteraions 669: train_loss: 0.17891264533151907 train_accuracy: 0.9296833333333333 test_loss: 0.33720011260103355 test_accuracy: 0.8829\n",
      "Iteraions 670: train_loss: 0.17886581750331693 train_accuracy: 0.9296666666666666 test_loss: 0.3432153323320811 test_accuracy: 0.88\n",
      "Iteraions 671: train_loss: 0.17892032827410762 train_accuracy: 0.9292833333333334 test_loss: 0.3399057278733835 test_accuracy: 0.8796\n",
      "Iteraions 672: train_loss: 0.18041976878524807 train_accuracy: 0.9286333333333333 test_loss: 0.33893661275341685 test_accuracy: 0.8784\n",
      "Iteraions 673: train_loss: 0.1827051690825752 train_accuracy: 0.9282666666666667 test_loss: 0.3410847313417552 test_accuracy: 0.8789\n",
      "Iteraions 674: train_loss: 0.17799654770841897 train_accuracy: 0.9300166666666667 test_loss: 0.3450065321237788 test_accuracy: 0.881\n",
      "Iteraions 675: train_loss: 0.17735674604622667 train_accuracy: 0.9297333333333333 test_loss: 0.33096584023469966 test_accuracy: 0.8824\n",
      "Iteraions 676: train_loss: 0.1777453741174115 train_accuracy: 0.9305166666666667 test_loss: 0.3378814612526936 test_accuracy: 0.8814\n",
      "Iteraions 677: train_loss: 0.17883158097541638 train_accuracy: 0.9296333333333333 test_loss: 0.34098865179476673 test_accuracy: 0.8801\n",
      "Iteraions 678: train_loss: 0.17762973386267397 train_accuracy: 0.9295833333333333 test_loss: 0.3418103593459012 test_accuracy: 0.8817\n",
      "Iteraions 679: train_loss: 0.17772884084372917 train_accuracy: 0.9288166666666666 test_loss: 0.34054103074344266 test_accuracy: 0.8802\n",
      "Iteraions 680: train_loss: 0.17552182087847687 train_accuracy: 0.9307166666666666 test_loss: 0.3405524685752665 test_accuracy: 0.8796\n",
      "Iteraions 681: train_loss: 0.17646932303520366 train_accuracy: 0.9303 test_loss: 0.3414102414954059 test_accuracy: 0.8794\n",
      "Iteraions 682: train_loss: 0.17686957998909092 train_accuracy: 0.9308166666666666 test_loss: 0.3439362417116997 test_accuracy: 0.877\n",
      "Iteraions 683: train_loss: 0.176933029251554 train_accuracy: 0.9305 test_loss: 0.34130018865539946 test_accuracy: 0.8826\n",
      "Iteraions 684: train_loss: 0.1768310467650498 train_accuracy: 0.9309 test_loss: 0.34562213242914785 test_accuracy: 0.8816\n",
      "Iteraions 685: train_loss: 0.17429361041402752 train_accuracy: 0.9314833333333333 test_loss: 0.34009176330209473 test_accuracy: 0.8803\n",
      "Iteraions 686: train_loss: 0.17254430970882167 train_accuracy: 0.9320666666666667 test_loss: 0.33807905590671133 test_accuracy: 0.8813\n",
      "Iteraions 687: train_loss: 0.17495802320284118 train_accuracy: 0.9305 test_loss: 0.3406676057309398 test_accuracy: 0.8791\n",
      "Iteraions 688: train_loss: 0.17398607642524322 train_accuracy: 0.9311 test_loss: 0.33596202101853934 test_accuracy: 0.8785\n",
      "Iteraions 689: train_loss: 0.17470703975167695 train_accuracy: 0.9301833333333334 test_loss: 0.3423043179098419 test_accuracy: 0.8795\n",
      "Iteraions 690: train_loss: 0.17363700742875007 train_accuracy: 0.93105 test_loss: 0.33112061523157243 test_accuracy: 0.8851\n",
      "Iteraions 691: train_loss: 0.1723761823837226 train_accuracy: 0.9325333333333333 test_loss: 0.33962436171382177 test_accuracy: 0.8825\n",
      "Iteraions 692: train_loss: 0.1721215915980422 train_accuracy: 0.9323 test_loss: 0.33704019042277666 test_accuracy: 0.8835\n",
      "Iteraions 693: train_loss: 0.17354929650010553 train_accuracy: 0.9312666666666667 test_loss: 0.33669868329540487 test_accuracy: 0.8831\n",
      "Iteraions 694: train_loss: 0.17202285245731225 train_accuracy: 0.9324833333333333 test_loss: 0.3430561376369709 test_accuracy: 0.8793\n",
      "Iteraions 695: train_loss: 0.1707756766187976 train_accuracy: 0.9332833333333334 test_loss: 0.3406747951546478 test_accuracy: 0.8814\n",
      "Iteraions 696: train_loss: 0.17235698534738997 train_accuracy: 0.93175 test_loss: 0.33579872026038143 test_accuracy: 0.8816\n",
      "Iteraions 697: train_loss: 0.17321336931783735 train_accuracy: 0.9322166666666667 test_loss: 0.345361669564859 test_accuracy: 0.8791\n",
      "Iteraions 698: train_loss: 0.17272453715773442 train_accuracy: 0.93295 test_loss: 0.33812543586786176 test_accuracy: 0.8834\n",
      "Iteraions 699: train_loss: 0.17347067944806804 train_accuracy: 0.9319166666666666 test_loss: 0.34150211643196837 test_accuracy: 0.8799\n",
      "Iteraions 700: train_loss: 0.1720355489210391 train_accuracy: 0.9323 test_loss: 0.34415925299235767 test_accuracy: 0.8801\n",
      "Iteraions 701: train_loss: 0.1722682509516857 train_accuracy: 0.93265 test_loss: 0.34070786084207483 test_accuracy: 0.8837\n",
      "Iteraions 702: train_loss: 0.17051520265507195 train_accuracy: 0.9339833333333334 test_loss: 0.34060625200681116 test_accuracy: 0.8815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 703: train_loss: 0.1724483035578746 train_accuracy: 0.9320333333333334 test_loss: 0.3363837351910606 test_accuracy: 0.8801\n",
      "Iteraions 704: train_loss: 0.17010904030894672 train_accuracy: 0.933 test_loss: 0.33775536051429206 test_accuracy: 0.8832\n",
      "Iteraions 705: train_loss: 0.17060199032756262 train_accuracy: 0.93425 test_loss: 0.3342705477525326 test_accuracy: 0.8819\n",
      "Iteraions 706: train_loss: 0.16850734124141514 train_accuracy: 0.93355 test_loss: 0.3435245772113155 test_accuracy: 0.8804\n",
      "Iteraions 707: train_loss: 0.16857607182599332 train_accuracy: 0.9331833333333334 test_loss: 0.3388740778410964 test_accuracy: 0.8823\n",
      "Iteraions 708: train_loss: 0.17085576300164726 train_accuracy: 0.93385 test_loss: 0.34862466827119754 test_accuracy: 0.8788\n",
      "Iteraions 709: train_loss: 0.16886714244845608 train_accuracy: 0.9338166666666666 test_loss: 0.3407856460784476 test_accuracy: 0.8804\n",
      "Iteraions 710: train_loss: 0.16995001354791275 train_accuracy: 0.9343166666666667 test_loss: 0.3426602047601317 test_accuracy: 0.8794\n",
      "Iteraions 711: train_loss: 0.16904037837104066 train_accuracy: 0.9328166666666666 test_loss: 0.34236536173318705 test_accuracy: 0.8811\n",
      "Iteraions 712: train_loss: 0.17101660275077227 train_accuracy: 0.9338 test_loss: 0.34359896058813555 test_accuracy: 0.8784\n",
      "Iteraions 713: train_loss: 0.1695091966707756 train_accuracy: 0.9341166666666667 test_loss: 0.34512943678844377 test_accuracy: 0.8801\n",
      "Iteraions 714: train_loss: 0.1696023348537855 train_accuracy: 0.93335 test_loss: 0.34689785421559427 test_accuracy: 0.8818\n",
      "Iteraions 715: train_loss: 0.1713445250504696 train_accuracy: 0.9326833333333333 test_loss: 0.34581694965266935 test_accuracy: 0.88\n",
      "Iteraions 716: train_loss: 0.1693815391659137 train_accuracy: 0.93265 test_loss: 0.3458928427210548 test_accuracy: 0.8808\n",
      "Iteraions 717: train_loss: 0.16830669338707743 train_accuracy: 0.9336666666666666 test_loss: 0.3407800154273012 test_accuracy: 0.8833\n",
      "Iteraions 718: train_loss: 0.16831482461117425 train_accuracy: 0.9343833333333333 test_loss: 0.3344021715841175 test_accuracy: 0.8833\n",
      "Iteraions 719: train_loss: 0.16813015719313057 train_accuracy: 0.9342333333333334 test_loss: 0.33844300362279334 test_accuracy: 0.8839\n",
      "Iteraions 720: train_loss: 0.16876155500353246 train_accuracy: 0.9344166666666667 test_loss: 0.34784557057158877 test_accuracy: 0.8808\n",
      "Iteraions 721: train_loss: 0.17006966040684435 train_accuracy: 0.9328166666666666 test_loss: 0.34380435268901205 test_accuracy: 0.8802\n",
      "Iteraions 722: train_loss: 0.17044343430577294 train_accuracy: 0.9322833333333334 test_loss: 0.34298400526759903 test_accuracy: 0.8805\n",
      "Iteraions 723: train_loss: 0.16855196125333496 train_accuracy: 0.9337 test_loss: 0.34339080695493146 test_accuracy: 0.8792\n",
      "Iteraions 724: train_loss: 0.16805554239525392 train_accuracy: 0.9343166666666667 test_loss: 0.3434931408403975 test_accuracy: 0.8812\n",
      "Iteraions 725: train_loss: 0.16664599377708778 train_accuracy: 0.9349833333333334 test_loss: 0.34164196357216997 test_accuracy: 0.883\n",
      "Iteraions 726: train_loss: 0.16945513863832376 train_accuracy: 0.9334166666666667 test_loss: 0.339089875201749 test_accuracy: 0.8818\n",
      "Iteraions 727: train_loss: 0.16576079349341816 train_accuracy: 0.9353833333333333 test_loss: 0.33973143403905054 test_accuracy: 0.8823\n",
      "Iteraions 728: train_loss: 0.16696644522482407 train_accuracy: 0.9345166666666667 test_loss: 0.3479223501339763 test_accuracy: 0.8826\n",
      "Iteraions 729: train_loss: 0.16471288978365417 train_accuracy: 0.9353833333333333 test_loss: 0.341625183884252 test_accuracy: 0.8809\n",
      "Iteraions 730: train_loss: 0.16468719876997887 train_accuracy: 0.9357166666666666 test_loss: 0.3409052731856378 test_accuracy: 0.8825\n",
      "Iteraions 731: train_loss: 0.1646541869977849 train_accuracy: 0.9356666666666666 test_loss: 0.3466951116807324 test_accuracy: 0.8807\n",
      "Iteraions 732: train_loss: 0.16434820422306087 train_accuracy: 0.9359833333333333 test_loss: 0.3410587600464998 test_accuracy: 0.8808\n",
      "Iteraions 733: train_loss: 0.16430009157411904 train_accuracy: 0.9355333333333333 test_loss: 0.33637174515836543 test_accuracy: 0.8847\n",
      "Iteraions 734: train_loss: 0.16385363326405386 train_accuracy: 0.9364 test_loss: 0.34233168117444907 test_accuracy: 0.8817\n",
      "Iteraions 735: train_loss: 0.16361765237254955 train_accuracy: 0.9363333333333334 test_loss: 0.34696504366199377 test_accuracy: 0.8808\n",
      "Iteraions 736: train_loss: 0.16339917941681306 train_accuracy: 0.9361166666666667 test_loss: 0.33813553029436655 test_accuracy: 0.8808\n",
      "Iteraions 737: train_loss: 0.16360997198890684 train_accuracy: 0.937 test_loss: 0.34063242129812554 test_accuracy: 0.8817\n",
      "Iteraions 738: train_loss: 0.16373727195204385 train_accuracy: 0.9362166666666667 test_loss: 0.34257134906418907 test_accuracy: 0.8841\n",
      "Iteraions 739: train_loss: 0.16262186949994215 train_accuracy: 0.9362 test_loss: 0.33400159799252643 test_accuracy: 0.8825\n",
      "Iteraions 740: train_loss: 0.16230548866164846 train_accuracy: 0.9362166666666667 test_loss: 0.34312630198861316 test_accuracy: 0.8811\n",
      "Iteraions 741: train_loss: 0.16338223232173607 train_accuracy: 0.9362666666666667 test_loss: 0.34487192159642666 test_accuracy: 0.8835\n",
      "Iteraions 742: train_loss: 0.16265486413248678 train_accuracy: 0.9358 test_loss: 0.34008642936785244 test_accuracy: 0.8845\n",
      "Iteraions 743: train_loss: 0.1610068703730717 train_accuracy: 0.93715 test_loss: 0.3458053587539798 test_accuracy: 0.8833\n",
      "Iteraions 744: train_loss: 0.16135318668393278 train_accuracy: 0.9368 test_loss: 0.34449355033624063 test_accuracy: 0.8845\n",
      "Iteraions 745: train_loss: 0.1620872642783891 train_accuracy: 0.9364666666666667 test_loss: 0.34369929626809737 test_accuracy: 0.8833\n",
      "Iteraions 746: train_loss: 0.1652004481646932 train_accuracy: 0.9344 test_loss: 0.35237233731854817 test_accuracy: 0.8776\n",
      "Iteraions 747: train_loss: 0.1697488794873228 train_accuracy: 0.9324166666666667 test_loss: 0.3497065123728222 test_accuracy: 0.8797\n",
      "Iteraions 748: train_loss: 0.17036794771530103 train_accuracy: 0.9325166666666667 test_loss: 0.3523970758135258 test_accuracy: 0.8794\n",
      "Iteraions 749: train_loss: 0.17117579671081512 train_accuracy: 0.9317666666666666 test_loss: 0.3507624505654288 test_accuracy: 0.8788\n",
      "Iteraions 750: train_loss: 0.17038730512426425 train_accuracy: 0.9327 test_loss: 0.3473627652482686 test_accuracy: 0.8797\n",
      "Iteraions 751: train_loss: 0.167434258329062 train_accuracy: 0.9343 test_loss: 0.3533191752229833 test_accuracy: 0.8791\n",
      "Iteraions 752: train_loss: 0.16255287438653065 train_accuracy: 0.9369333333333333 test_loss: 0.346981111667967 test_accuracy: 0.8796\n",
      "Iteraions 753: train_loss: 0.16517041233318838 train_accuracy: 0.9352833333333334 test_loss: 0.33691863774082975 test_accuracy: 0.8861\n",
      "Iteraions 754: train_loss: 0.16599490316208976 train_accuracy: 0.9336666666666666 test_loss: 0.3481262239385331 test_accuracy: 0.8812\n",
      "Iteraions 755: train_loss: 0.16576760521785386 train_accuracy: 0.9351833333333334 test_loss: 0.3446801542199455 test_accuracy: 0.8785\n",
      "Iteraions 756: train_loss: 0.16169084803346964 train_accuracy: 0.9364 test_loss: 0.3454047746111501 test_accuracy: 0.8848\n",
      "Iteraions 757: train_loss: 0.15958589748914806 train_accuracy: 0.9387666666666666 test_loss: 0.34369514837278375 test_accuracy: 0.884\n",
      "Iteraions 758: train_loss: 0.16136690872111104 train_accuracy: 0.9377333333333333 test_loss: 0.3425831428201693 test_accuracy: 0.8842\n",
      "Iteraions 759: train_loss: 0.1638498087685235 train_accuracy: 0.9350333333333334 test_loss: 0.3523162659177581 test_accuracy: 0.8812\n",
      "Iteraions 760: train_loss: 0.16191868624239475 train_accuracy: 0.937 test_loss: 0.34789718943404424 test_accuracy: 0.8791\n",
      "Iteraions 761: train_loss: 0.15925800645572774 train_accuracy: 0.9381666666666667 test_loss: 0.3442443929917667 test_accuracy: 0.8838\n",
      "Iteraions 762: train_loss: 0.16104302905105405 train_accuracy: 0.9375166666666667 test_loss: 0.34449696175751576 test_accuracy: 0.8798\n",
      "Iteraions 763: train_loss: 0.1612304998597717 train_accuracy: 0.9370666666666667 test_loss: 0.3456784619438387 test_accuracy: 0.8794\n",
      "Iteraions 764: train_loss: 0.1608591665827596 train_accuracy: 0.93605 test_loss: 0.3481869136069189 test_accuracy: 0.8841\n",
      "Iteraions 765: train_loss: 0.15883147446748505 train_accuracy: 0.9385 test_loss: 0.34405214250764365 test_accuracy: 0.8838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 766: train_loss: 0.15833048143912504 train_accuracy: 0.93835 test_loss: 0.34283701302611 test_accuracy: 0.8832\n",
      "Iteraions 767: train_loss: 0.159862257633528 train_accuracy: 0.9380333333333334 test_loss: 0.34475954664590597 test_accuracy: 0.884\n",
      "Iteraions 768: train_loss: 0.1610122224313118 train_accuracy: 0.9362666666666667 test_loss: 0.3482289648376089 test_accuracy: 0.8811\n",
      "Iteraions 769: train_loss: 0.16047178698313122 train_accuracy: 0.9378166666666666 test_loss: 0.3480264383061499 test_accuracy: 0.8846\n",
      "Iteraions 770: train_loss: 0.15712896239176424 train_accuracy: 0.9398 test_loss: 0.3464963369171465 test_accuracy: 0.8822\n",
      "Iteraions 771: train_loss: 0.15692456453063575 train_accuracy: 0.93925 test_loss: 0.34203350434093577 test_accuracy: 0.8851\n",
      "Iteraions 772: train_loss: 0.15688600224931193 train_accuracy: 0.9384833333333333 test_loss: 0.3481317713533523 test_accuracy: 0.882\n",
      "Iteraions 773: train_loss: 0.1569471595703635 train_accuracy: 0.9388833333333333 test_loss: 0.34678566479240897 test_accuracy: 0.8813\n",
      "Iteraions 774: train_loss: 0.15821655902135082 train_accuracy: 0.93895 test_loss: 0.3440141699701657 test_accuracy: 0.8822\n",
      "Iteraions 775: train_loss: 0.15762663432208124 train_accuracy: 0.9382833333333334 test_loss: 0.3456071704355937 test_accuracy: 0.8827\n",
      "Iteraions 776: train_loss: 0.15540277339179434 train_accuracy: 0.9396166666666667 test_loss: 0.3462613861475135 test_accuracy: 0.8819\n",
      "Iteraions 777: train_loss: 0.15587178861130924 train_accuracy: 0.9388166666666666 test_loss: 0.34436311470624376 test_accuracy: 0.8832\n",
      "Iteraions 778: train_loss: 0.15604766863392977 train_accuracy: 0.9399666666666666 test_loss: 0.3412025576844664 test_accuracy: 0.8833\n",
      "Iteraions 779: train_loss: 0.1558487949790169 train_accuracy: 0.93925 test_loss: 0.34826999913470275 test_accuracy: 0.884\n",
      "Iteraions 780: train_loss: 0.15602061423586042 train_accuracy: 0.93905 test_loss: 0.34922797670152367 test_accuracy: 0.8811\n",
      "Iteraions 781: train_loss: 0.1548784650672089 train_accuracy: 0.9405 test_loss: 0.3431045756762967 test_accuracy: 0.883\n",
      "Iteraions 782: train_loss: 0.15466273480295958 train_accuracy: 0.9405333333333333 test_loss: 0.34982081177343743 test_accuracy: 0.8818\n",
      "Iteraions 783: train_loss: 0.15576605556170323 train_accuracy: 0.9396666666666667 test_loss: 0.34799111650020315 test_accuracy: 0.8801\n",
      "Iteraions 784: train_loss: 0.15573772394810026 train_accuracy: 0.9391333333333334 test_loss: 0.34279687938414416 test_accuracy: 0.8843\n",
      "Iteraions 785: train_loss: 0.153873079171757 train_accuracy: 0.9405166666666667 test_loss: 0.3478909337246466 test_accuracy: 0.8821\n",
      "Iteraions 786: train_loss: 0.1549595600901445 train_accuracy: 0.9396333333333333 test_loss: 0.3499246112688562 test_accuracy: 0.8828\n",
      "Iteraions 787: train_loss: 0.15505468243924378 train_accuracy: 0.9398166666666666 test_loss: 0.35048117333598766 test_accuracy: 0.8823\n",
      "Iteraions 788: train_loss: 0.1526847503418825 train_accuracy: 0.9406166666666667 test_loss: 0.3506875159514959 test_accuracy: 0.8808\n",
      "Iteraions 789: train_loss: 0.1532143646901164 train_accuracy: 0.9396333333333333 test_loss: 0.3494499191613476 test_accuracy: 0.8831\n",
      "Iteraions 790: train_loss: 0.15362540103004477 train_accuracy: 0.94015 test_loss: 0.34804003996023297 test_accuracy: 0.8833\n",
      "Iteraions 791: train_loss: 0.15397578186925714 train_accuracy: 0.9407833333333333 test_loss: 0.3537819145402553 test_accuracy: 0.8822\n",
      "Iteraions 792: train_loss: 0.15272948205591516 train_accuracy: 0.9413833333333333 test_loss: 0.34763676121842885 test_accuracy: 0.8833\n",
      "Iteraions 793: train_loss: 0.15248893419295098 train_accuracy: 0.9412166666666667 test_loss: 0.34706212861937535 test_accuracy: 0.885\n",
      "Iteraions 794: train_loss: 0.15158594213532037 train_accuracy: 0.94115 test_loss: 0.3413561298583155 test_accuracy: 0.8841\n",
      "Iteraions 795: train_loss: 0.15193131485583153 train_accuracy: 0.9408833333333333 test_loss: 0.3466822858737458 test_accuracy: 0.885\n",
      "Iteraions 796: train_loss: 0.1521851717840594 train_accuracy: 0.9408833333333333 test_loss: 0.3509144487608311 test_accuracy: 0.8844\n",
      "Iteraions 797: train_loss: 0.15161870878602454 train_accuracy: 0.9411166666666667 test_loss: 0.349006583880084 test_accuracy: 0.8826\n",
      "Iteraions 798: train_loss: 0.14996076678409637 train_accuracy: 0.9418333333333333 test_loss: 0.34980597362797416 test_accuracy: 0.8844\n",
      "Iteraions 799: train_loss: 0.15173161647209835 train_accuracy: 0.94095 test_loss: 0.3515864525095167 test_accuracy: 0.8802\n",
      "Iteraions 800: train_loss: 0.15149474811017083 train_accuracy: 0.9416166666666667 test_loss: 0.34576022073601337 test_accuracy: 0.8834\n",
      "Iteraions 801: train_loss: 0.15241559918908246 train_accuracy: 0.94035 test_loss: 0.34844082752197675 test_accuracy: 0.8835\n",
      "Iteraions 802: train_loss: 0.15150685597293595 train_accuracy: 0.9406 test_loss: 0.34240631603284016 test_accuracy: 0.8862\n",
      "Iteraions 803: train_loss: 0.15081893310336886 train_accuracy: 0.9422666666666667 test_loss: 0.3555825673340483 test_accuracy: 0.8828\n",
      "Iteraions 804: train_loss: 0.15109229652677958 train_accuracy: 0.9418666666666666 test_loss: 0.34323106629037836 test_accuracy: 0.8826\n",
      "Iteraions 805: train_loss: 0.15020978836038326 train_accuracy: 0.9407333333333333 test_loss: 0.35071841466656956 test_accuracy: 0.8829\n",
      "Iteraions 806: train_loss: 0.15071060385197338 train_accuracy: 0.9416166666666667 test_loss: 0.3473648597610581 test_accuracy: 0.882\n",
      "Iteraions 807: train_loss: 0.14982432821030847 train_accuracy: 0.9427 test_loss: 0.3561573065228942 test_accuracy: 0.881\n",
      "Iteraions 808: train_loss: 0.15002891048021882 train_accuracy: 0.9421166666666667 test_loss: 0.35227709034407007 test_accuracy: 0.8825\n",
      "Iteraions 809: train_loss: 0.14925598479435362 train_accuracy: 0.9422333333333334 test_loss: 0.3502858757465024 test_accuracy: 0.8841\n",
      "Iteraions 810: train_loss: 0.1484083765536094 train_accuracy: 0.94355 test_loss: 0.3510991579567578 test_accuracy: 0.8857\n",
      "Iteraions 811: train_loss: 0.14968750549879442 train_accuracy: 0.94195 test_loss: 0.3458336853384932 test_accuracy: 0.8819\n",
      "Iteraions 812: train_loss: 0.14913221066840668 train_accuracy: 0.9420166666666666 test_loss: 0.3499360193123767 test_accuracy: 0.8838\n",
      "Iteraions 813: train_loss: 0.148185840380672 train_accuracy: 0.9420833333333334 test_loss: 0.3540471837309078 test_accuracy: 0.8799\n",
      "Iteraions 814: train_loss: 0.14933743482438006 train_accuracy: 0.9420333333333333 test_loss: 0.3562676165826999 test_accuracy: 0.8812\n",
      "Iteraions 815: train_loss: 0.14821876549287274 train_accuracy: 0.9421166666666667 test_loss: 0.35319762415881073 test_accuracy: 0.8849\n",
      "Iteraions 816: train_loss: 0.14986098372423168 train_accuracy: 0.94105 test_loss: 0.34547528649477877 test_accuracy: 0.8834\n",
      "Iteraions 817: train_loss: 0.14994496409411834 train_accuracy: 0.9425333333333333 test_loss: 0.35102875785494286 test_accuracy: 0.8871\n",
      "Iteraions 818: train_loss: 0.14712760154274226 train_accuracy: 0.9428 test_loss: 0.3453754013646609 test_accuracy: 0.8846\n",
      "Iteraions 819: train_loss: 0.14844283363354158 train_accuracy: 0.94225 test_loss: 0.3511510072298817 test_accuracy: 0.8838\n",
      "Iteraions 820: train_loss: 0.14733481145482152 train_accuracy: 0.94345 test_loss: 0.35752670891056376 test_accuracy: 0.8802\n",
      "Iteraions 821: train_loss: 0.14697773298055475 train_accuracy: 0.9437166666666666 test_loss: 0.3480894267827485 test_accuracy: 0.885\n",
      "Iteraions 822: train_loss: 0.14901293285152462 train_accuracy: 0.9423333333333334 test_loss: 0.35371463304226725 test_accuracy: 0.8821\n",
      "Iteraions 823: train_loss: 0.14890651582666595 train_accuracy: 0.9412 test_loss: 0.35053704540799835 test_accuracy: 0.8846\n",
      "Iteraions 824: train_loss: 0.1498391647461044 train_accuracy: 0.9419833333333333 test_loss: 0.348119784826217 test_accuracy: 0.8823\n",
      "Iteraions 825: train_loss: 0.1504322546221263 train_accuracy: 0.9409833333333333 test_loss: 0.3535760659539576 test_accuracy: 0.8821\n",
      "Iteraions 826: train_loss: 0.15027392348743351 train_accuracy: 0.9416166666666667 test_loss: 0.3541009518091425 test_accuracy: 0.8837\n",
      "Iteraions 827: train_loss: 0.14947673752817742 train_accuracy: 0.94235 test_loss: 0.3517939000297978 test_accuracy: 0.8831\n",
      "Iteraions 828: train_loss: 0.14925529276288224 train_accuracy: 0.9420833333333334 test_loss: 0.3560860816459404 test_accuracy: 0.8805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 829: train_loss: 0.1488387036635842 train_accuracy: 0.9416833333333333 test_loss: 0.3505582651255602 test_accuracy: 0.8838\n",
      "Iteraions 830: train_loss: 0.14786224309315643 train_accuracy: 0.94325 test_loss: 0.3494740337471026 test_accuracy: 0.8824\n",
      "Iteraions 831: train_loss: 0.1460126476030239 train_accuracy: 0.9434 test_loss: 0.34988309205238294 test_accuracy: 0.8871\n",
      "Iteraions 832: train_loss: 0.145044293311755 train_accuracy: 0.9449333333333333 test_loss: 0.3513470687094771 test_accuracy: 0.8823\n",
      "Iteraions 833: train_loss: 0.1465898141862554 train_accuracy: 0.9438666666666666 test_loss: 0.34882528715273686 test_accuracy: 0.8838\n",
      "Iteraions 834: train_loss: 0.14807030137630817 train_accuracy: 0.9431 test_loss: 0.34867498851745554 test_accuracy: 0.8821\n",
      "Iteraions 835: train_loss: 0.14717239842777377 train_accuracy: 0.9430833333333334 test_loss: 0.35533942547256164 test_accuracy: 0.8828\n",
      "Iteraions 836: train_loss: 0.14799604473806413 train_accuracy: 0.9425666666666667 test_loss: 0.3583388258082564 test_accuracy: 0.8831\n",
      "Iteraions 837: train_loss: 0.14668723064814548 train_accuracy: 0.9429666666666666 test_loss: 0.35444786953488144 test_accuracy: 0.8801\n",
      "Iteraions 838: train_loss: 0.14601654639213715 train_accuracy: 0.9431166666666667 test_loss: 0.3557611672142293 test_accuracy: 0.8821\n",
      "Iteraions 839: train_loss: 0.14590953550502506 train_accuracy: 0.9438166666666666 test_loss: 0.35099272443711377 test_accuracy: 0.8834\n",
      "Iteraions 840: train_loss: 0.1450932210797549 train_accuracy: 0.9441 test_loss: 0.3581248070739713 test_accuracy: 0.8824\n",
      "Iteraions 841: train_loss: 0.14549637291536952 train_accuracy: 0.9429166666666666 test_loss: 0.3504642563860233 test_accuracy: 0.8843\n",
      "Iteraions 842: train_loss: 0.14523721629807246 train_accuracy: 0.9435333333333333 test_loss: 0.35190561899529715 test_accuracy: 0.8837\n",
      "Iteraions 843: train_loss: 0.14452709381992343 train_accuracy: 0.9439 test_loss: 0.35412385286021486 test_accuracy: 0.8835\n",
      "Iteraions 844: train_loss: 0.14566565614449103 train_accuracy: 0.94385 test_loss: 0.36132199088704686 test_accuracy: 0.8836\n",
      "Iteraions 845: train_loss: 0.14398594862751815 train_accuracy: 0.9442333333333334 test_loss: 0.35087699415560597 test_accuracy: 0.884\n",
      "Iteraions 846: train_loss: 0.14445684593951225 train_accuracy: 0.9444166666666667 test_loss: 0.3481166388959831 test_accuracy: 0.882\n",
      "Iteraions 847: train_loss: 0.1450930123349841 train_accuracy: 0.9425833333333333 test_loss: 0.35580562410727784 test_accuracy: 0.8835\n",
      "Iteraions 848: train_loss: 0.144901612408372 train_accuracy: 0.94385 test_loss: 0.3571252223413633 test_accuracy: 0.8822\n",
      "Iteraions 849: train_loss: 0.1449572243486721 train_accuracy: 0.9444166666666667 test_loss: 0.3507181396483309 test_accuracy: 0.8857\n",
      "Iteraions 850: train_loss: 0.14401171562265147 train_accuracy: 0.9435833333333333 test_loss: 0.3493515413745181 test_accuracy: 0.885\n",
      "Iteraions 851: train_loss: 0.14390579801106215 train_accuracy: 0.9443666666666667 test_loss: 0.35250412995702785 test_accuracy: 0.885\n",
      "Iteraions 852: train_loss: 0.14306980966720775 train_accuracy: 0.9447666666666666 test_loss: 0.3572288782038754 test_accuracy: 0.8827\n",
      "Iteraions 853: train_loss: 0.1455626488112464 train_accuracy: 0.9439666666666666 test_loss: 0.35676315669447006 test_accuracy: 0.8822\n",
      "Iteraions 854: train_loss: 0.14567106088363016 train_accuracy: 0.9426833333333333 test_loss: 0.36374171630496455 test_accuracy: 0.8825\n",
      "Iteraions 855: train_loss: 0.1456193042232112 train_accuracy: 0.9434166666666667 test_loss: 0.36795267537516263 test_accuracy: 0.8803\n",
      "Iteraions 856: train_loss: 0.1440298800077964 train_accuracy: 0.9438833333333333 test_loss: 0.35679004220042326 test_accuracy: 0.8828\n",
      "Iteraions 857: train_loss: 0.14200553554709283 train_accuracy: 0.9457 test_loss: 0.355150634701701 test_accuracy: 0.8847\n",
      "Iteraions 858: train_loss: 0.14284212055662027 train_accuracy: 0.9441 test_loss: 0.35254173595431176 test_accuracy: 0.8863\n",
      "Iteraions 859: train_loss: 0.14165384978610765 train_accuracy: 0.94505 test_loss: 0.35497042724449657 test_accuracy: 0.884\n",
      "Iteraions 860: train_loss: 0.14326763882572238 train_accuracy: 0.94555 test_loss: 0.355816673548185 test_accuracy: 0.8834\n",
      "Iteraions 861: train_loss: 0.14504532960567437 train_accuracy: 0.94325 test_loss: 0.36328505172335845 test_accuracy: 0.8815\n",
      "Iteraions 862: train_loss: 0.14703584038085946 train_accuracy: 0.9433 test_loss: 0.3585490034822079 test_accuracy: 0.8814\n",
      "Iteraions 863: train_loss: 0.14714761645050267 train_accuracy: 0.9418666666666666 test_loss: 0.35978117476361615 test_accuracy: 0.8816\n",
      "Iteraions 864: train_loss: 0.1439698024483825 train_accuracy: 0.9443333333333334 test_loss: 0.35239034018329674 test_accuracy: 0.8838\n",
      "Iteraions 865: train_loss: 0.14006701932434173 train_accuracy: 0.9454333333333333 test_loss: 0.3587699338017847 test_accuracy: 0.884\n",
      "Iteraions 866: train_loss: 0.14066829475615153 train_accuracy: 0.94525 test_loss: 0.35879859993077323 test_accuracy: 0.8853\n",
      "Iteraions 867: train_loss: 0.14255154399748007 train_accuracy: 0.9446333333333333 test_loss: 0.35787117163428245 test_accuracy: 0.8845\n",
      "Iteraions 868: train_loss: 0.14265112866069926 train_accuracy: 0.9440833333333334 test_loss: 0.3536831208351799 test_accuracy: 0.8822\n",
      "Iteraions 869: train_loss: 0.1407467646140815 train_accuracy: 0.9467333333333333 test_loss: 0.3616875896763267 test_accuracy: 0.882\n",
      "Iteraions 870: train_loss: 0.13919749878530693 train_accuracy: 0.9452 test_loss: 0.3606681427942651 test_accuracy: 0.8833\n",
      "Iteraions 871: train_loss: 0.13936316470569704 train_accuracy: 0.9462666666666667 test_loss: 0.3564517083350032 test_accuracy: 0.8843\n",
      "Iteraions 872: train_loss: 0.14126004055477043 train_accuracy: 0.9464333333333333 test_loss: 0.35897207376697954 test_accuracy: 0.882\n",
      "Iteraions 873: train_loss: 0.14284576772652793 train_accuracy: 0.94485 test_loss: 0.35974882426571864 test_accuracy: 0.883\n",
      "Iteraions 874: train_loss: 0.14125491515580083 train_accuracy: 0.9463166666666667 test_loss: 0.3636449717420783 test_accuracy: 0.8821\n",
      "Iteraions 875: train_loss: 0.13904351167991663 train_accuracy: 0.94615 test_loss: 0.3555976720578098 test_accuracy: 0.8857\n",
      "Iteraions 876: train_loss: 0.13823679043616602 train_accuracy: 0.9468833333333333 test_loss: 0.36141041304009125 test_accuracy: 0.8828\n",
      "Iteraions 877: train_loss: 0.13894090909882995 train_accuracy: 0.9468166666666666 test_loss: 0.3623871096842953 test_accuracy: 0.8811\n",
      "Iteraions 878: train_loss: 0.14144659418375838 train_accuracy: 0.9446833333333333 test_loss: 0.3617819837112336 test_accuracy: 0.8825\n",
      "Iteraions 879: train_loss: 0.14181266723966587 train_accuracy: 0.9450666666666667 test_loss: 0.35749409939801696 test_accuracy: 0.8823\n",
      "Iteraions 880: train_loss: 0.13994654337003365 train_accuracy: 0.9457166666666666 test_loss: 0.36206314361699904 test_accuracy: 0.8828\n",
      "Iteraions 881: train_loss: 0.13856298412913579 train_accuracy: 0.9475166666666667 test_loss: 0.3566847531918081 test_accuracy: 0.8825\n",
      "Iteraions 882: train_loss: 0.13811972166243505 train_accuracy: 0.9470333333333333 test_loss: 0.35540992533113175 test_accuracy: 0.8837\n",
      "Iteraions 883: train_loss: 0.13885002699531804 train_accuracy: 0.9461 test_loss: 0.3588188917968961 test_accuracy: 0.8832\n",
      "Iteraions 884: train_loss: 0.1380014784484182 train_accuracy: 0.9469666666666666 test_loss: 0.35487145551336635 test_accuracy: 0.8832\n",
      "Iteraions 885: train_loss: 0.1388141979304284 train_accuracy: 0.9467166666666667 test_loss: 0.3615392194991587 test_accuracy: 0.8853\n",
      "Iteraions 886: train_loss: 0.13752152090277153 train_accuracy: 0.9467 test_loss: 0.3535836340709071 test_accuracy: 0.8849\n",
      "Iteraions 887: train_loss: 0.13726243308518432 train_accuracy: 0.9474666666666667 test_loss: 0.3562460059867123 test_accuracy: 0.8848\n",
      "Iteraions 888: train_loss: 0.1373949477683633 train_accuracy: 0.9472333333333334 test_loss: 0.3576116163098495 test_accuracy: 0.8805\n",
      "Iteraions 889: train_loss: 0.1391035541680778 train_accuracy: 0.9463 test_loss: 0.3640957447761467 test_accuracy: 0.8832\n",
      "Iteraions 890: train_loss: 0.13574416751454071 train_accuracy: 0.9465333333333333 test_loss: 0.36281017865928405 test_accuracy: 0.8822\n",
      "Iteraions 891: train_loss: 0.13575510887321124 train_accuracy: 0.9474333333333333 test_loss: 0.35275776804153586 test_accuracy: 0.8888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 892: train_loss: 0.1382338331458962 train_accuracy: 0.9463833333333334 test_loss: 0.359461146202345 test_accuracy: 0.8865\n",
      "Iteraions 893: train_loss: 0.1359029987039744 train_accuracy: 0.9472833333333334 test_loss: 0.35540516324430393 test_accuracy: 0.8855\n",
      "Iteraions 894: train_loss: 0.13730469529104394 train_accuracy: 0.9476166666666667 test_loss: 0.35885234232292484 test_accuracy: 0.8829\n",
      "Iteraions 895: train_loss: 0.13682405468646497 train_accuracy: 0.9471666666666667 test_loss: 0.3551887825304387 test_accuracy: 0.8846\n",
      "Iteraions 896: train_loss: 0.13806748424786472 train_accuracy: 0.9466666666666667 test_loss: 0.35578369248113295 test_accuracy: 0.8849\n",
      "Iteraions 897: train_loss: 0.13623701790179377 train_accuracy: 0.94815 test_loss: 0.3663189872900471 test_accuracy: 0.8858\n",
      "Iteraions 898: train_loss: 0.13381542415943112 train_accuracy: 0.9488 test_loss: 0.36275796527063375 test_accuracy: 0.882\n",
      "Iteraions 899: train_loss: 0.13526072635720923 train_accuracy: 0.9485 test_loss: 0.3585878398841858 test_accuracy: 0.8833\n",
      "Iteraions 900: train_loss: 0.13520658318263387 train_accuracy: 0.9470833333333334 test_loss: 0.3568310292975026 test_accuracy: 0.8826\n",
      "Iteraions 901: train_loss: 0.13371882986659436 train_accuracy: 0.9488 test_loss: 0.3644429680399532 test_accuracy: 0.8818\n",
      "Iteraions 902: train_loss: 0.13412087749352125 train_accuracy: 0.9480833333333333 test_loss: 0.35724576654442186 test_accuracy: 0.8854\n",
      "Iteraions 903: train_loss: 0.1332604248716214 train_accuracy: 0.9487833333333333 test_loss: 0.35597158079509383 test_accuracy: 0.8857\n",
      "Iteraions 904: train_loss: 0.13445906553351578 train_accuracy: 0.9481 test_loss: 0.3660417874285343 test_accuracy: 0.8811\n",
      "Iteraions 905: train_loss: 0.13300800699190887 train_accuracy: 0.9490666666666666 test_loss: 0.36375653279070225 test_accuracy: 0.8847\n",
      "Iteraions 906: train_loss: 0.134750720691601 train_accuracy: 0.9478 test_loss: 0.36100726335838706 test_accuracy: 0.8825\n",
      "Iteraions 907: train_loss: 0.1339925822910237 train_accuracy: 0.9489 test_loss: 0.3604487959928707 test_accuracy: 0.8842\n",
      "Iteraions 908: train_loss: 0.1340147504899447 train_accuracy: 0.9487666666666666 test_loss: 0.3613211931725873 test_accuracy: 0.883\n",
      "Iteraions 909: train_loss: 0.1341489885702845 train_accuracy: 0.9490833333333333 test_loss: 0.3633785986024154 test_accuracy: 0.8865\n",
      "Iteraions 910: train_loss: 0.132479293254141 train_accuracy: 0.9493333333333334 test_loss: 0.36294440005220346 test_accuracy: 0.885\n",
      "Iteraions 911: train_loss: 0.1326306652070345 train_accuracy: 0.9481666666666667 test_loss: 0.36097548701195054 test_accuracy: 0.8829\n",
      "Iteraions 912: train_loss: 0.1331332303747265 train_accuracy: 0.9489166666666666 test_loss: 0.36576224607668373 test_accuracy: 0.8841\n",
      "Iteraions 913: train_loss: 0.1329566396879773 train_accuracy: 0.9486 test_loss: 0.3622106414937918 test_accuracy: 0.8843\n",
      "Iteraions 914: train_loss: 0.1333292349528615 train_accuracy: 0.9477833333333333 test_loss: 0.3574765730232347 test_accuracy: 0.8866\n",
      "Iteraions 915: train_loss: 0.13424593416872263 train_accuracy: 0.94975 test_loss: 0.35683214549541237 test_accuracy: 0.8854\n",
      "Iteraions 916: train_loss: 0.13299440306006777 train_accuracy: 0.9489833333333333 test_loss: 0.3594815690137642 test_accuracy: 0.8858\n",
      "Iteraions 917: train_loss: 0.13327151067071558 train_accuracy: 0.949 test_loss: 0.36728164062607666 test_accuracy: 0.8838\n",
      "Iteraions 918: train_loss: 0.1319631953982002 train_accuracy: 0.9489666666666666 test_loss: 0.3568094763017921 test_accuracy: 0.8855\n",
      "Iteraions 919: train_loss: 0.1328389988022588 train_accuracy: 0.9486 test_loss: 0.36272106885413885 test_accuracy: 0.8845\n",
      "Iteraions 920: train_loss: 0.13043653153469573 train_accuracy: 0.9507666666666666 test_loss: 0.3698410398505072 test_accuracy: 0.8823\n",
      "Iteraions 921: train_loss: 0.13302911353190858 train_accuracy: 0.9483 test_loss: 0.36526526610506205 test_accuracy: 0.8865\n",
      "Iteraions 922: train_loss: 0.133220360200718 train_accuracy: 0.9495 test_loss: 0.36260666604759867 test_accuracy: 0.8839\n",
      "Iteraions 923: train_loss: 0.13124787990442424 train_accuracy: 0.9492166666666667 test_loss: 0.3621865800497114 test_accuracy: 0.8887\n",
      "Iteraions 924: train_loss: 0.1328006651808613 train_accuracy: 0.9492833333333334 test_loss: 0.35876880578810727 test_accuracy: 0.8853\n",
      "Iteraions 925: train_loss: 0.13239674546248204 train_accuracy: 0.9493 test_loss: 0.3688574049817777 test_accuracy: 0.8856\n",
      "Iteraions 926: train_loss: 0.13088801050045623 train_accuracy: 0.9502666666666667 test_loss: 0.3719017992262863 test_accuracy: 0.8831\n",
      "Iteraions 927: train_loss: 0.1320893786310577 train_accuracy: 0.94885 test_loss: 0.3613988874203799 test_accuracy: 0.8818\n",
      "Iteraions 928: train_loss: 0.1324435617298643 train_accuracy: 0.9486 test_loss: 0.3673043202621287 test_accuracy: 0.8837\n",
      "Iteraions 929: train_loss: 0.13162091361015404 train_accuracy: 0.949 test_loss: 0.36110713656986393 test_accuracy: 0.8867\n",
      "Iteraions 930: train_loss: 0.13041937722649866 train_accuracy: 0.9496 test_loss: 0.3616538004814145 test_accuracy: 0.8834\n",
      "Iteraions 931: train_loss: 0.1308072371348347 train_accuracy: 0.9490333333333333 test_loss: 0.35973911121878893 test_accuracy: 0.883\n",
      "Iteraions 932: train_loss: 0.1298351115349757 train_accuracy: 0.9508 test_loss: 0.3692212688487356 test_accuracy: 0.882\n",
      "Iteraions 933: train_loss: 0.13078983184603568 train_accuracy: 0.9488 test_loss: 0.36788336450039516 test_accuracy: 0.8796\n",
      "Iteraions 934: train_loss: 0.1322270386375569 train_accuracy: 0.9497166666666667 test_loss: 0.3634658616222779 test_accuracy: 0.8856\n",
      "Iteraions 935: train_loss: 0.1316606991570275 train_accuracy: 0.9485 test_loss: 0.36474196838001344 test_accuracy: 0.8836\n",
      "Iteraions 936: train_loss: 0.13345523999679978 train_accuracy: 0.9484333333333334 test_loss: 0.3681283772985006 test_accuracy: 0.8823\n",
      "Iteraions 937: train_loss: 0.13174455204429664 train_accuracy: 0.9491 test_loss: 0.3692740148223068 test_accuracy: 0.8841\n",
      "Iteraions 938: train_loss: 0.12811527159346067 train_accuracy: 0.9512833333333334 test_loss: 0.36441895463075336 test_accuracy: 0.8842\n",
      "Iteraions 939: train_loss: 0.1281224350615302 train_accuracy: 0.95135 test_loss: 0.3622068333848985 test_accuracy: 0.8842\n",
      "Iteraions 940: train_loss: 0.12877229618732164 train_accuracy: 0.9509333333333333 test_loss: 0.36605550176231555 test_accuracy: 0.8825\n",
      "Iteraions 941: train_loss: 0.12967700803213358 train_accuracy: 0.9495666666666667 test_loss: 0.36563777246061874 test_accuracy: 0.8821\n",
      "Iteraions 942: train_loss: 0.12969094157225863 train_accuracy: 0.9507833333333333 test_loss: 0.36593352717749056 test_accuracy: 0.8824\n",
      "Iteraions 943: train_loss: 0.12960684999702266 train_accuracy: 0.9501833333333334 test_loss: 0.3679734776162759 test_accuracy: 0.8871\n",
      "Iteraions 944: train_loss: 0.12836135486895964 train_accuracy: 0.9502333333333334 test_loss: 0.36662053390351357 test_accuracy: 0.8838\n",
      "Iteraions 945: train_loss: 0.12913374280630135 train_accuracy: 0.9506 test_loss: 0.36517542966759375 test_accuracy: 0.8841\n",
      "Iteraions 946: train_loss: 0.12956922025156375 train_accuracy: 0.9504 test_loss: 0.37052616233062535 test_accuracy: 0.8845\n",
      "Iteraions 947: train_loss: 0.13072108713506259 train_accuracy: 0.9497166666666667 test_loss: 0.36618946141786407 test_accuracy: 0.8868\n",
      "Iteraions 948: train_loss: 0.12880365080054446 train_accuracy: 0.9511166666666667 test_loss: 0.371563951578548 test_accuracy: 0.8815\n",
      "Iteraions 949: train_loss: 0.12857262983185244 train_accuracy: 0.9512166666666667 test_loss: 0.3633934939839776 test_accuracy: 0.8863\n",
      "Iteraions 950: train_loss: 0.12830396503301686 train_accuracy: 0.9510833333333333 test_loss: 0.36375103939613207 test_accuracy: 0.8846\n",
      "Iteraions 951: train_loss: 0.12861874211524907 train_accuracy: 0.9506333333333333 test_loss: 0.3667691070757591 test_accuracy: 0.8855\n",
      "Iteraions 952: train_loss: 0.1264323877721947 train_accuracy: 0.9511833333333334 test_loss: 0.36944206901443116 test_accuracy: 0.8841\n",
      "Iteraions 953: train_loss: 0.12840263168359628 train_accuracy: 0.9502 test_loss: 0.3689694650131296 test_accuracy: 0.8817\n",
      "Iteraions 954: train_loss: 0.1290663073640677 train_accuracy: 0.9506666666666667 test_loss: 0.3700399228059574 test_accuracy: 0.8837\n",
      "Iteraions 955: train_loss: 0.12734467057089854 train_accuracy: 0.9511 test_loss: 0.36878716824616153 test_accuracy: 0.883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 956: train_loss: 0.12658161312191601 train_accuracy: 0.9520333333333333 test_loss: 0.3655386834086924 test_accuracy: 0.8853\n",
      "Iteraions 957: train_loss: 0.12557112934691858 train_accuracy: 0.9518833333333333 test_loss: 0.368411014029455 test_accuracy: 0.8843\n",
      "Iteraions 958: train_loss: 0.1255984889215751 train_accuracy: 0.9516333333333333 test_loss: 0.36301090162497623 test_accuracy: 0.8843\n",
      "Iteraions 959: train_loss: 0.1275990401315321 train_accuracy: 0.9508333333333333 test_loss: 0.3657712631794723 test_accuracy: 0.8855\n",
      "Iteraions 960: train_loss: 0.12902247509384035 train_accuracy: 0.9503833333333334 test_loss: 0.3767968487284717 test_accuracy: 0.8849\n",
      "Iteraions 961: train_loss: 0.1272025863515249 train_accuracy: 0.951 test_loss: 0.36869359229809673 test_accuracy: 0.8841\n",
      "Iteraions 962: train_loss: 0.1263522091421212 train_accuracy: 0.9508833333333333 test_loss: 0.376166957903967 test_accuracy: 0.884\n",
      "Iteraions 963: train_loss: 0.12552491198854956 train_accuracy: 0.95195 test_loss: 0.36804311543805895 test_accuracy: 0.8857\n",
      "Iteraions 964: train_loss: 0.12600538045329254 train_accuracy: 0.9522833333333334 test_loss: 0.3720107251830893 test_accuracy: 0.8857\n",
      "Iteraions 965: train_loss: 0.12630892388890566 train_accuracy: 0.9519 test_loss: 0.3710555513822719 test_accuracy: 0.8831\n",
      "Iteraions 966: train_loss: 0.12494995816102304 train_accuracy: 0.9524666666666667 test_loss: 0.3731386710020186 test_accuracy: 0.8843\n",
      "Iteraions 967: train_loss: 0.12497552234159512 train_accuracy: 0.9514833333333333 test_loss: 0.36761649956623943 test_accuracy: 0.8816\n",
      "Iteraions 968: train_loss: 0.1257082288318987 train_accuracy: 0.9518833333333333 test_loss: 0.3725729659506595 test_accuracy: 0.8828\n",
      "Iteraions 969: train_loss: 0.12435202049952489 train_accuracy: 0.9527333333333333 test_loss: 0.36691648855049575 test_accuracy: 0.8858\n",
      "Iteraions 970: train_loss: 0.12607449017256292 train_accuracy: 0.9518666666666666 test_loss: 0.37231269196205424 test_accuracy: 0.8841\n",
      "Iteraions 971: train_loss: 0.12656628828311722 train_accuracy: 0.95185 test_loss: 0.37224432204353364 test_accuracy: 0.8829\n",
      "Iteraions 972: train_loss: 0.12474516134775798 train_accuracy: 0.9516833333333333 test_loss: 0.3672475430983497 test_accuracy: 0.8837\n",
      "Iteraions 973: train_loss: 0.12481249630555755 train_accuracy: 0.9531666666666667 test_loss: 0.37367511128096703 test_accuracy: 0.8843\n",
      "Iteraions 974: train_loss: 0.12269121542610191 train_accuracy: 0.9536166666666667 test_loss: 0.3660157769814344 test_accuracy: 0.8839\n",
      "Iteraions 975: train_loss: 0.12258549720605302 train_accuracy: 0.9539166666666666 test_loss: 0.36585551548922784 test_accuracy: 0.8873\n",
      "Iteraions 976: train_loss: 0.12443294686241907 train_accuracy: 0.9526833333333333 test_loss: 0.3718130139856687 test_accuracy: 0.882\n",
      "Iteraions 977: train_loss: 0.12574624914542126 train_accuracy: 0.9517166666666667 test_loss: 0.36767152550664334 test_accuracy: 0.8832\n",
      "Iteraions 978: train_loss: 0.12704725689801236 train_accuracy: 0.95135 test_loss: 0.380499703865136 test_accuracy: 0.8832\n",
      "Iteraions 979: train_loss: 0.1304025178840173 train_accuracy: 0.9507333333333333 test_loss: 0.3734702911018939 test_accuracy: 0.8828\n",
      "Iteraions 980: train_loss: 0.13317683962606178 train_accuracy: 0.94705 test_loss: 0.3859747064198442 test_accuracy: 0.8784\n",
      "Iteraions 981: train_loss: 0.1350572905728615 train_accuracy: 0.9476 test_loss: 0.3845389041521677 test_accuracy: 0.8777\n",
      "Iteraions 982: train_loss: 0.1279450902998586 train_accuracy: 0.9493666666666667 test_loss: 0.3697335181643192 test_accuracy: 0.8845\n",
      "Iteraions 983: train_loss: 0.12317196091454131 train_accuracy: 0.9528333333333333 test_loss: 0.3668643218331672 test_accuracy: 0.8844\n",
      "Iteraions 984: train_loss: 0.12499191274311955 train_accuracy: 0.95205 test_loss: 0.37149964487132153 test_accuracy: 0.8836\n",
      "Iteraions 985: train_loss: 0.12657210232716185 train_accuracy: 0.9509666666666666 test_loss: 0.37599639636611526 test_accuracy: 0.8811\n",
      "Iteraions 986: train_loss: 0.1271104357551805 train_accuracy: 0.9506666666666667 test_loss: 0.37436342830685815 test_accuracy: 0.883\n",
      "Iteraions 987: train_loss: 0.1246387489850444 train_accuracy: 0.9525333333333333 test_loss: 0.3639030614481716 test_accuracy: 0.8879\n",
      "Iteraions 988: train_loss: 0.12117310246212691 train_accuracy: 0.9536 test_loss: 0.37617121815463145 test_accuracy: 0.8833\n",
      "Iteraions 989: train_loss: 0.12278131625672185 train_accuracy: 0.95365 test_loss: 0.3687068806352623 test_accuracy: 0.8849\n",
      "Iteraions 990: train_loss: 0.12447205537305549 train_accuracy: 0.9513666666666667 test_loss: 0.3746484883765027 test_accuracy: 0.884\n",
      "Iteraions 991: train_loss: 0.12479643378764385 train_accuracy: 0.9519333333333333 test_loss: 0.38053873281248257 test_accuracy: 0.8816\n",
      "Iteraions 992: train_loss: 0.12240811935857274 train_accuracy: 0.9536333333333333 test_loss: 0.37508883385531433 test_accuracy: 0.8867\n",
      "Iteraions 993: train_loss: 0.12126791372669553 train_accuracy: 0.95385 test_loss: 0.3681428993071989 test_accuracy: 0.8862\n",
      "Iteraions 994: train_loss: 0.12208685854876108 train_accuracy: 0.9532333333333334 test_loss: 0.37166483199981043 test_accuracy: 0.8816\n",
      "Iteraions 995: train_loss: 0.12226868472571308 train_accuracy: 0.9526166666666667 test_loss: 0.37599563850186574 test_accuracy: 0.8813\n",
      "Iteraions 996: train_loss: 0.12091189847001715 train_accuracy: 0.9545 test_loss: 0.373175397182837 test_accuracy: 0.8854\n",
      "Iteraions 997: train_loss: 0.11976758749696485 train_accuracy: 0.9545166666666667 test_loss: 0.36893920652403256 test_accuracy: 0.8866\n",
      "Iteraions 998: train_loss: 0.12119115485320353 train_accuracy: 0.9544 test_loss: 0.3735630624913727 test_accuracy: 0.8868\n",
      "Iteraions 999: train_loss: 0.12050375188199003 train_accuracy: 0.95505 test_loss: 0.3794019950315992 test_accuracy: 0.8851\n"
     ]
    }
   ],
   "source": [
    "# Call train function and run it for specified number of iterations (max_iterations = 1000)\n",
    "train(tr_x, W1, b1, W2, b2, W3, b3, tr_y, te_x, te_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is for dropout prob = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 0: train_loss: 2.3025479345832536 train_accuracy: 0.1 test_loss: 2.3025533486581824 test_accuracy: 0.1\n",
      "Iteraions 1: train_loss: 2.2990355981418795 train_accuracy: 0.1 test_loss: 2.2990318874095617 test_accuracy: 0.1\n",
      "Iteraions 2: train_loss: 2.2921404472669895 train_accuracy: 0.1 test_loss: 2.2921949887385393 test_accuracy: 0.1\n",
      "Iteraions 3: train_loss: 2.280398370407528 train_accuracy: 0.1 test_loss: 2.280555637039989 test_accuracy: 0.1\n",
      "Iteraions 4: train_loss: 2.2622382340790503 train_accuracy: 0.1 test_loss: 2.262335215403194 test_accuracy: 0.1\n",
      "Iteraions 5: train_loss: 2.235602102778123 train_accuracy: 0.1 test_loss: 2.2358204330664964 test_accuracy: 0.1\n",
      "Iteraions 6: train_loss: 2.1992591627272176 train_accuracy: 0.1 test_loss: 2.199482477211453 test_accuracy: 0.1\n",
      "Iteraions 7: train_loss: 2.152050352478464 train_accuracy: 0.1 test_loss: 2.1530189492869787 test_accuracy: 0.1\n",
      "Iteraions 8: train_loss: 2.094074161901287 train_accuracy: 0.1 test_loss: 2.095250354691444 test_accuracy: 0.1\n",
      "Iteraions 9: train_loss: 2.0255620448213585 train_accuracy: 0.1 test_loss: 2.027410308031679 test_accuracy: 0.1\n",
      "Iteraions 10: train_loss: 1.9479085872363806 train_accuracy: 0.1 test_loss: 1.950363877338446 test_accuracy: 0.1\n",
      "Iteraions 11: train_loss: 1.863764119031216 train_accuracy: 0.1 test_loss: 1.866035004204866 test_accuracy: 0.1\n",
      "Iteraions 12: train_loss: 1.7772105020287572 train_accuracy: 0.10276666666666667 test_loss: 1.7802507129369656 test_accuracy: 0.1024\n",
      "Iteraions 13: train_loss: 1.6949184593265179 train_accuracy: 0.12571666666666667 test_loss: 1.6982282686605803 test_accuracy: 0.1266\n",
      "Iteraions 14: train_loss: 1.6183841152259075 train_accuracy: 0.1516 test_loss: 1.621893194539736 test_accuracy: 0.151\n",
      "Iteraions 15: train_loss: 1.5463169597954005 train_accuracy: 0.16118333333333335 test_loss: 1.5498090524663002 test_accuracy: 0.1597\n",
      "Iteraions 16: train_loss: 1.4773213896648438 train_accuracy: 0.16508333333333333 test_loss: 1.4813212448935285 test_accuracy: 0.1631\n",
      "Iteraions 17: train_loss: 1.413358285763476 train_accuracy: 0.15441666666666667 test_loss: 1.4169059550657732 test_accuracy: 0.1525\n",
      "Iteraions 18: train_loss: 1.3580875894244546 train_accuracy: 0.14743333333333333 test_loss: 1.3633935442789211 test_accuracy: 0.1459\n",
      "Iteraions 19: train_loss: 1.3095637791996788 train_accuracy: 0.15066666666666667 test_loss: 1.316073184266248 test_accuracy: 0.1511\n",
      "Iteraions 20: train_loss: 1.2619958333266914 train_accuracy: 0.16506666666666667 test_loss: 1.2721052341881627 test_accuracy: 0.1635\n",
      "Iteraions 21: train_loss: 1.2171751597847063 train_accuracy: 0.19885 test_loss: 1.225998960938671 test_accuracy: 0.1963\n",
      "Iteraions 22: train_loss: 1.1812482595311944 train_accuracy: 0.24206666666666668 test_loss: 1.1908238587650957 test_accuracy: 0.2406\n",
      "Iteraions 23: train_loss: 1.152048386960815 train_accuracy: 0.2768 test_loss: 1.1619620073281762 test_accuracy: 0.2762\n",
      "Iteraions 24: train_loss: 1.1194822912264608 train_accuracy: 0.29775 test_loss: 1.1352679544051623 test_accuracy: 0.295\n",
      "Iteraions 25: train_loss: 1.0897399877621041 train_accuracy: 0.32911666666666667 test_loss: 1.10708665285404 test_accuracy: 0.325\n",
      "Iteraions 26: train_loss: 1.0666525966744163 train_accuracy: 0.3698166666666667 test_loss: 1.0804656034604705 test_accuracy: 0.3648\n",
      "Iteraions 27: train_loss: 1.0455875550820457 train_accuracy: 0.39203333333333334 test_loss: 1.0589568030388705 test_accuracy: 0.3934\n",
      "Iteraions 28: train_loss: 1.0226696681434975 train_accuracy: 0.40851666666666664 test_loss: 1.0401279749796326 test_accuracy: 0.4077\n",
      "Iteraions 29: train_loss: 1.0004719509528306 train_accuracy: 0.42973333333333336 test_loss: 1.0170300807994206 test_accuracy: 0.4274\n",
      "Iteraions 30: train_loss: 0.9844134024230009 train_accuracy: 0.4525666666666667 test_loss: 1.0037878210275848 test_accuracy: 0.4522\n",
      "Iteraions 31: train_loss: 0.9667221122360439 train_accuracy: 0.4682 test_loss: 0.9846392664748979 test_accuracy: 0.4623\n",
      "Iteraions 32: train_loss: 0.9496364243439867 train_accuracy: 0.4836 test_loss: 0.9722214405436814 test_accuracy: 0.4773\n",
      "Iteraions 33: train_loss: 0.9357548212988822 train_accuracy: 0.4982 test_loss: 0.9580646362901172 test_accuracy: 0.494\n",
      "Iteraions 34: train_loss: 0.9223777164575188 train_accuracy: 0.5174333333333333 test_loss: 0.9495726197922751 test_accuracy: 0.5106\n",
      "Iteraions 35: train_loss: 0.9087517028102622 train_accuracy: 0.52155 test_loss: 0.9341690109243588 test_accuracy: 0.5154\n",
      "Iteraions 36: train_loss: 0.8998772506016983 train_accuracy: 0.5263333333333333 test_loss: 0.9189872021691273 test_accuracy: 0.5233\n",
      "Iteraions 37: train_loss: 0.8890567929057398 train_accuracy: 0.5469833333333334 test_loss: 0.9113410906318801 test_accuracy: 0.5387\n",
      "Iteraions 38: train_loss: 0.8814808461843262 train_accuracy: 0.5414166666666667 test_loss: 0.9016604938342816 test_accuracy: 0.5337\n",
      "Iteraions 39: train_loss: 0.8692440997505912 train_accuracy: 0.5457333333333333 test_loss: 0.8959093279066863 test_accuracy: 0.5392\n",
      "Iteraions 40: train_loss: 0.8616526211277153 train_accuracy: 0.55915 test_loss: 0.884269901598121 test_accuracy: 0.5525\n",
      "Iteraions 41: train_loss: 0.851460032367504 train_accuracy: 0.5686333333333333 test_loss: 0.8773387005370998 test_accuracy: 0.5571\n",
      "Iteraions 42: train_loss: 0.8452497030141041 train_accuracy: 0.5670333333333333 test_loss: 0.8689642184423437 test_accuracy: 0.5594\n",
      "Iteraions 43: train_loss: 0.836642037889637 train_accuracy: 0.5694 test_loss: 0.8554241593439934 test_accuracy: 0.5642\n",
      "Iteraions 44: train_loss: 0.8285310604164223 train_accuracy: 0.5821333333333333 test_loss: 0.8541212532706908 test_accuracy: 0.5707\n",
      "Iteraions 45: train_loss: 0.819794033923232 train_accuracy: 0.5816333333333333 test_loss: 0.8422000077337889 test_accuracy: 0.5715\n",
      "Iteraions 46: train_loss: 0.8111149162456208 train_accuracy: 0.57795 test_loss: 0.8334523807930473 test_accuracy: 0.569\n",
      "Iteraions 47: train_loss: 0.8010529107759035 train_accuracy: 0.5896666666666667 test_loss: 0.8256266995518028 test_accuracy: 0.5848\n",
      "Iteraions 48: train_loss: 0.792201218317483 train_accuracy: 0.5979333333333333 test_loss: 0.815017423713252 test_accuracy: 0.5912\n",
      "Iteraions 49: train_loss: 0.7831625110852178 train_accuracy: 0.5931166666666666 test_loss: 0.8046096195809791 test_accuracy: 0.584\n",
      "Iteraions 50: train_loss: 0.7734743245531108 train_accuracy: 0.6006 test_loss: 0.7946922743158865 test_accuracy: 0.594\n",
      "Iteraions 51: train_loss: 0.7683613526423052 train_accuracy: 0.6088666666666667 test_loss: 0.7906702570684422 test_accuracy: 0.5975\n",
      "Iteraions 52: train_loss: 0.7591665138899106 train_accuracy: 0.6090666666666666 test_loss: 0.7789285046272594 test_accuracy: 0.605\n",
      "Iteraions 53: train_loss: 0.7494584067737715 train_accuracy: 0.6149166666666667 test_loss: 0.7738874795645628 test_accuracy: 0.6045\n",
      "Iteraions 54: train_loss: 0.7431230745860439 train_accuracy: 0.6235666666666667 test_loss: 0.7662716595713659 test_accuracy: 0.6169\n",
      "Iteraions 55: train_loss: 0.7364275795932389 train_accuracy: 0.62775 test_loss: 0.7603269782667523 test_accuracy: 0.6197\n",
      "Iteraions 56: train_loss: 0.7285357110992462 train_accuracy: 0.62895 test_loss: 0.7542259217376888 test_accuracy: 0.6171\n",
      "Iteraions 57: train_loss: 0.7207879152782511 train_accuracy: 0.6379333333333334 test_loss: 0.7481437590720069 test_accuracy: 0.6269\n",
      "Iteraions 58: train_loss: 0.7145868063094778 train_accuracy: 0.6466166666666666 test_loss: 0.7391418074998215 test_accuracy: 0.6392\n",
      "Iteraions 59: train_loss: 0.7109004285914894 train_accuracy: 0.6477833333333334 test_loss: 0.7325697500888302 test_accuracy: 0.6379\n",
      "Iteraions 60: train_loss: 0.7051368907461001 train_accuracy: 0.6498833333333334 test_loss: 0.7266465378127381 test_accuracy: 0.6467\n",
      "Iteraions 61: train_loss: 0.6978580589210682 train_accuracy: 0.6584666666666666 test_loss: 0.7219513330709931 test_accuracy: 0.6511\n",
      "Iteraions 62: train_loss: 0.6914701590396513 train_accuracy: 0.6626666666666666 test_loss: 0.7131752873538673 test_accuracy: 0.6579\n",
      "Iteraions 63: train_loss: 0.6854544326671921 train_accuracy: 0.6635166666666666 test_loss: 0.7083448667278041 test_accuracy: 0.6546\n",
      "Iteraions 64: train_loss: 0.6786236417357396 train_accuracy: 0.6705666666666666 test_loss: 0.6991836976060041 test_accuracy: 0.6663\n",
      "Iteraions 65: train_loss: 0.6726371854104555 train_accuracy: 0.6774166666666667 test_loss: 0.6997047198061497 test_accuracy: 0.6709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 66: train_loss: 0.6664223706997495 train_accuracy: 0.6773 test_loss: 0.6885754465152915 test_accuracy: 0.6684\n",
      "Iteraions 67: train_loss: 0.6615146691397199 train_accuracy: 0.68195 test_loss: 0.6860796741091068 test_accuracy: 0.6778\n",
      "Iteraions 68: train_loss: 0.654991137976448 train_accuracy: 0.6877833333333333 test_loss: 0.680800543419971 test_accuracy: 0.6791\n",
      "Iteraions 69: train_loss: 0.6502216403988176 train_accuracy: 0.6896333333333333 test_loss: 0.6752247762769217 test_accuracy: 0.6819\n",
      "Iteraions 70: train_loss: 0.6450116804962659 train_accuracy: 0.6933 test_loss: 0.6698194830465363 test_accuracy: 0.6828\n",
      "Iteraions 71: train_loss: 0.6396890123648324 train_accuracy: 0.6981833333333334 test_loss: 0.6679046616779767 test_accuracy: 0.685\n",
      "Iteraions 72: train_loss: 0.6347569632690355 train_accuracy: 0.7010833333333333 test_loss: 0.6605307727132343 test_accuracy: 0.69\n",
      "Iteraions 73: train_loss: 0.6291941524489819 train_accuracy: 0.7011833333333334 test_loss: 0.6543461664592042 test_accuracy: 0.693\n",
      "Iteraions 74: train_loss: 0.6236217598184347 train_accuracy: 0.7069 test_loss: 0.6495241043588201 test_accuracy: 0.6961\n",
      "Iteraions 75: train_loss: 0.6182261847315934 train_accuracy: 0.7074833333333334 test_loss: 0.6444966129287869 test_accuracy: 0.701\n",
      "Iteraions 76: train_loss: 0.6147790130636478 train_accuracy: 0.7119166666666666 test_loss: 0.6406183762594438 test_accuracy: 0.7007\n",
      "Iteraions 77: train_loss: 0.6097238291282588 train_accuracy: 0.71465 test_loss: 0.6339654299977506 test_accuracy: 0.7016\n",
      "Iteraions 78: train_loss: 0.6046016754841447 train_accuracy: 0.7150666666666666 test_loss: 0.6310030635495477 test_accuracy: 0.7051\n",
      "Iteraions 79: train_loss: 0.5998501444002031 train_accuracy: 0.7184166666666667 test_loss: 0.630298399799998 test_accuracy: 0.7062\n",
      "Iteraions 80: train_loss: 0.5944789045725235 train_accuracy: 0.7218333333333333 test_loss: 0.6237905398461268 test_accuracy: 0.7105\n",
      "Iteraions 81: train_loss: 0.5914853527949855 train_accuracy: 0.7231833333333333 test_loss: 0.6179402242837002 test_accuracy: 0.7116\n",
      "Iteraions 82: train_loss: 0.5852097598599346 train_accuracy: 0.727 test_loss: 0.6091279141339567 test_accuracy: 0.7179\n",
      "Iteraions 83: train_loss: 0.5813808960275959 train_accuracy: 0.7289333333333333 test_loss: 0.6133501893127695 test_accuracy: 0.7161\n",
      "Iteraions 84: train_loss: 0.5777128642596973 train_accuracy: 0.7314333333333334 test_loss: 0.605981777079178 test_accuracy: 0.7204\n",
      "Iteraions 85: train_loss: 0.5726275758789474 train_accuracy: 0.7341666666666666 test_loss: 0.6016376032494829 test_accuracy: 0.7216\n",
      "Iteraions 86: train_loss: 0.5681809107526761 train_accuracy: 0.7345166666666667 test_loss: 0.5958964597277054 test_accuracy: 0.7215\n",
      "Iteraions 87: train_loss: 0.5651899047008602 train_accuracy: 0.7392666666666666 test_loss: 0.5938936729769914 test_accuracy: 0.7245\n",
      "Iteraions 88: train_loss: 0.561099965357103 train_accuracy: 0.7415833333333334 test_loss: 0.5914898084229178 test_accuracy: 0.7292\n",
      "Iteraions 89: train_loss: 0.5557295622010944 train_accuracy: 0.7434833333333334 test_loss: 0.5837010084529962 test_accuracy: 0.7308\n",
      "Iteraions 90: train_loss: 0.5522795248726975 train_accuracy: 0.7469833333333333 test_loss: 0.5864793329053666 test_accuracy: 0.7321\n",
      "Iteraions 91: train_loss: 0.54708778613184 train_accuracy: 0.7487833333333334 test_loss: 0.5804309001019483 test_accuracy: 0.7335\n",
      "Iteraions 92: train_loss: 0.5450561325493676 train_accuracy: 0.7522833333333333 test_loss: 0.5737368317627355 test_accuracy: 0.739\n",
      "Iteraions 93: train_loss: 0.5399555828468356 train_accuracy: 0.7553333333333333 test_loss: 0.5704161536474744 test_accuracy: 0.7398\n",
      "Iteraions 94: train_loss: 0.5349736312924822 train_accuracy: 0.7574 test_loss: 0.5661842658386318 test_accuracy: 0.7426\n",
      "Iteraions 95: train_loss: 0.532943697074679 train_accuracy: 0.7597333333333334 test_loss: 0.5648118407714072 test_accuracy: 0.7468\n",
      "Iteraions 96: train_loss: 0.5300937152628764 train_accuracy: 0.76115 test_loss: 0.558999499981538 test_accuracy: 0.7465\n",
      "Iteraions 97: train_loss: 0.5272773384447269 train_accuracy: 0.7633166666666666 test_loss: 0.5582700218742304 test_accuracy: 0.7494\n",
      "Iteraions 98: train_loss: 0.5224405145088952 train_accuracy: 0.7654833333333333 test_loss: 0.5517557610509343 test_accuracy: 0.7537\n",
      "Iteraions 99: train_loss: 0.5185130999806559 train_accuracy: 0.76835 test_loss: 0.5526471900893095 test_accuracy: 0.7545\n",
      "Iteraions 100: train_loss: 0.5162924014342688 train_accuracy: 0.7713833333333333 test_loss: 0.5488767442697831 test_accuracy: 0.7565\n",
      "Iteraions 101: train_loss: 0.5131458049402563 train_accuracy: 0.7722333333333333 test_loss: 0.5441898760410042 test_accuracy: 0.759\n",
      "Iteraions 102: train_loss: 0.5111654193651005 train_accuracy: 0.7739333333333334 test_loss: 0.5419341730473147 test_accuracy: 0.7635\n",
      "Iteraions 103: train_loss: 0.5074343115409269 train_accuracy: 0.7769333333333334 test_loss: 0.537633373402558 test_accuracy: 0.7602\n",
      "Iteraions 104: train_loss: 0.5045280715290769 train_accuracy: 0.7792333333333333 test_loss: 0.5335899075132725 test_accuracy: 0.7664\n",
      "Iteraions 105: train_loss: 0.5021046368493168 train_accuracy: 0.78095 test_loss: 0.5349167938154377 test_accuracy: 0.7661\n",
      "Iteraions 106: train_loss: 0.4981222608851104 train_accuracy: 0.7823833333333333 test_loss: 0.5292372568874841 test_accuracy: 0.7708\n",
      "Iteraions 107: train_loss: 0.4966113082576279 train_accuracy: 0.7830333333333334 test_loss: 0.5290131026311905 test_accuracy: 0.768\n",
      "Iteraions 108: train_loss: 0.4927242277927716 train_accuracy: 0.7876833333333333 test_loss: 0.5225037107245822 test_accuracy: 0.7732\n",
      "Iteraions 109: train_loss: 0.4908605073949695 train_accuracy: 0.7858 test_loss: 0.523929231380706 test_accuracy: 0.7765\n",
      "Iteraions 110: train_loss: 0.4876723363522842 train_accuracy: 0.7886833333333333 test_loss: 0.5223929745615837 test_accuracy: 0.7758\n",
      "Iteraions 111: train_loss: 0.4848011594440835 train_accuracy: 0.7898166666666666 test_loss: 0.5216125973823854 test_accuracy: 0.7743\n",
      "Iteraions 112: train_loss: 0.482423190023808 train_accuracy: 0.79195 test_loss: 0.5182625643641657 test_accuracy: 0.7782\n",
      "Iteraions 113: train_loss: 0.4810956917998456 train_accuracy: 0.7928666666666667 test_loss: 0.5147460603581557 test_accuracy: 0.7796\n",
      "Iteraions 114: train_loss: 0.47787164431841517 train_accuracy: 0.7943333333333333 test_loss: 0.5093588487540792 test_accuracy: 0.7812\n",
      "Iteraions 115: train_loss: 0.47539932109869476 train_accuracy: 0.7958333333333333 test_loss: 0.5127875844354676 test_accuracy: 0.7834\n",
      "Iteraions 116: train_loss: 0.47395329232354705 train_accuracy: 0.7972 test_loss: 0.5052894224830498 test_accuracy: 0.7858\n",
      "Iteraions 117: train_loss: 0.4712197831028853 train_accuracy: 0.7986333333333333 test_loss: 0.50408139788408 test_accuracy: 0.7869\n",
      "Iteraions 118: train_loss: 0.4680677867444283 train_accuracy: 0.799 test_loss: 0.5046844457324465 test_accuracy: 0.7872\n",
      "Iteraions 119: train_loss: 0.4664383634504794 train_accuracy: 0.7999166666666667 test_loss: 0.4982251267042537 test_accuracy: 0.7865\n",
      "Iteraions 120: train_loss: 0.46507259315716076 train_accuracy: 0.8014 test_loss: 0.4992295889958963 test_accuracy: 0.7866\n",
      "Iteraions 121: train_loss: 0.46339712535087074 train_accuracy: 0.80325 test_loss: 0.4958306369542368 test_accuracy: 0.7906\n",
      "Iteraions 122: train_loss: 0.4596774198608563 train_accuracy: 0.8029166666666666 test_loss: 0.4946048246488384 test_accuracy: 0.7921\n",
      "Iteraions 123: train_loss: 0.457860118758118 train_accuracy: 0.8041333333333334 test_loss: 0.49158909970077985 test_accuracy: 0.7921\n",
      "Iteraions 124: train_loss: 0.45526419790767747 train_accuracy: 0.8063333333333333 test_loss: 0.4890763080386938 test_accuracy: 0.7955\n",
      "Iteraions 125: train_loss: 0.45326915321534034 train_accuracy: 0.8064666666666667 test_loss: 0.4873921025963089 test_accuracy: 0.7925\n",
      "Iteraions 126: train_loss: 0.4526200391090039 train_accuracy: 0.8076833333333333 test_loss: 0.48937869570038056 test_accuracy: 0.793\n",
      "Iteraions 127: train_loss: 0.44974116009085935 train_accuracy: 0.8096333333333333 test_loss: 0.4844429200103997 test_accuracy: 0.7963\n",
      "Iteraions 128: train_loss: 0.4483421086127746 train_accuracy: 0.8102833333333334 test_loss: 0.4827976919378885 test_accuracy: 0.7987\n",
      "Iteraions 129: train_loss: 0.44643733786198364 train_accuracy: 0.8121833333333334 test_loss: 0.4833716500204837 test_accuracy: 0.7955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 130: train_loss: 0.4450189159448485 train_accuracy: 0.8102166666666667 test_loss: 0.4771158752301301 test_accuracy: 0.7967\n",
      "Iteraions 131: train_loss: 0.44151355710881884 train_accuracy: 0.8129 test_loss: 0.47733112806995404 test_accuracy: 0.7999\n",
      "Iteraions 132: train_loss: 0.4416485088645347 train_accuracy: 0.813 test_loss: 0.4762564162384639 test_accuracy: 0.7985\n",
      "Iteraions 133: train_loss: 0.4394533158896354 train_accuracy: 0.8157166666666666 test_loss: 0.47535352920023705 test_accuracy: 0.8008\n",
      "Iteraions 134: train_loss: 0.4375957977395415 train_accuracy: 0.8153 test_loss: 0.47200494309722396 test_accuracy: 0.8058\n",
      "Iteraions 135: train_loss: 0.4359749017183226 train_accuracy: 0.8158 test_loss: 0.4713164859067054 test_accuracy: 0.8016\n",
      "Iteraions 136: train_loss: 0.4363823980555602 train_accuracy: 0.8174 test_loss: 0.4731254986872631 test_accuracy: 0.8021\n",
      "Iteraions 137: train_loss: 0.43311465378902037 train_accuracy: 0.8165666666666667 test_loss: 0.47004197778754353 test_accuracy: 0.8022\n",
      "Iteraions 138: train_loss: 0.42992771710421246 train_accuracy: 0.8205333333333333 test_loss: 0.46805945294473095 test_accuracy: 0.8029\n",
      "Iteraions 139: train_loss: 0.4299323062644832 train_accuracy: 0.8194833333333333 test_loss: 0.4679808225812413 test_accuracy: 0.8026\n",
      "Iteraions 140: train_loss: 0.42748010205728276 train_accuracy: 0.81985 test_loss: 0.46200117382863554 test_accuracy: 0.806\n",
      "Iteraions 141: train_loss: 0.4263616810818948 train_accuracy: 0.8212166666666667 test_loss: 0.4661265901480502 test_accuracy: 0.8075\n",
      "Iteraions 142: train_loss: 0.42574387484900156 train_accuracy: 0.8200666666666667 test_loss: 0.46574511393008206 test_accuracy: 0.8069\n",
      "Iteraions 143: train_loss: 0.4229516311277437 train_accuracy: 0.8244 test_loss: 0.4632196034693192 test_accuracy: 0.8068\n",
      "Iteraions 144: train_loss: 0.4217638131785714 train_accuracy: 0.82425 test_loss: 0.4576372035193563 test_accuracy: 0.8088\n",
      "Iteraions 145: train_loss: 0.4191983934585731 train_accuracy: 0.8242 test_loss: 0.4594417181769192 test_accuracy: 0.8107\n",
      "Iteraions 146: train_loss: 0.4193023935535718 train_accuracy: 0.8256 test_loss: 0.45539114154626587 test_accuracy: 0.8114\n",
      "Iteraions 147: train_loss: 0.4197550071290446 train_accuracy: 0.8239 test_loss: 0.4529107490041667 test_accuracy: 0.8111\n",
      "Iteraions 148: train_loss: 0.4161726026481088 train_accuracy: 0.8254833333333333 test_loss: 0.45300291208846794 test_accuracy: 0.8141\n",
      "Iteraions 149: train_loss: 0.4143375514151298 train_accuracy: 0.8268166666666666 test_loss: 0.45346864546452964 test_accuracy: 0.8138\n",
      "Iteraions 150: train_loss: 0.4115830207050522 train_accuracy: 0.82635 test_loss: 0.45180046680535524 test_accuracy: 0.8117\n",
      "Iteraions 151: train_loss: 0.41196213542893806 train_accuracy: 0.8279333333333333 test_loss: 0.4512101957610122 test_accuracy: 0.8113\n",
      "Iteraions 152: train_loss: 0.40973236147978176 train_accuracy: 0.82945 test_loss: 0.4502304935422892 test_accuracy: 0.8139\n",
      "Iteraions 153: train_loss: 0.4096643265239415 train_accuracy: 0.8285666666666667 test_loss: 0.44715817431743415 test_accuracy: 0.816\n",
      "Iteraions 154: train_loss: 0.40848043315507 train_accuracy: 0.8299 test_loss: 0.4461413176731839 test_accuracy: 0.8139\n",
      "Iteraions 155: train_loss: 0.4071368373177499 train_accuracy: 0.8301166666666666 test_loss: 0.4448352601296523 test_accuracy: 0.8139\n",
      "Iteraions 156: train_loss: 0.4036460794758434 train_accuracy: 0.8308 test_loss: 0.4458314600815933 test_accuracy: 0.8149\n",
      "Iteraions 157: train_loss: 0.4037273971496971 train_accuracy: 0.83255 test_loss: 0.4422697593374167 test_accuracy: 0.8177\n",
      "Iteraions 158: train_loss: 0.4022508677770901 train_accuracy: 0.8317166666666667 test_loss: 0.44374283083639005 test_accuracy: 0.8148\n",
      "Iteraions 159: train_loss: 0.40309902935869457 train_accuracy: 0.8324 test_loss: 0.4423162178016226 test_accuracy: 0.818\n",
      "Iteraions 160: train_loss: 0.4002137379713634 train_accuracy: 0.8327833333333333 test_loss: 0.4401059639121386 test_accuracy: 0.8151\n",
      "Iteraions 161: train_loss: 0.3980842965423332 train_accuracy: 0.8350333333333333 test_loss: 0.4398424312032962 test_accuracy: 0.8181\n",
      "Iteraions 162: train_loss: 0.39770667465440857 train_accuracy: 0.8354333333333334 test_loss: 0.4375423392220756 test_accuracy: 0.8204\n",
      "Iteraions 163: train_loss: 0.3968481952167179 train_accuracy: 0.8360166666666666 test_loss: 0.43695541382827807 test_accuracy: 0.8196\n",
      "Iteraions 164: train_loss: 0.39624120102612675 train_accuracy: 0.8356666666666667 test_loss: 0.4350955930676353 test_accuracy: 0.8204\n",
      "Iteraions 165: train_loss: 0.39359064324284104 train_accuracy: 0.8371 test_loss: 0.4371352610699798 test_accuracy: 0.8186\n",
      "Iteraions 166: train_loss: 0.3933817380776783 train_accuracy: 0.8365833333333333 test_loss: 0.43169048085885653 test_accuracy: 0.8206\n",
      "Iteraions 167: train_loss: 0.39275627667577223 train_accuracy: 0.8363333333333334 test_loss: 0.43628090514812445 test_accuracy: 0.8209\n",
      "Iteraions 168: train_loss: 0.39104800726773864 train_accuracy: 0.83895 test_loss: 0.43530889897229047 test_accuracy: 0.8214\n",
      "Iteraions 169: train_loss: 0.3905272070384949 train_accuracy: 0.8387166666666667 test_loss: 0.42809887504861155 test_accuracy: 0.824\n",
      "Iteraions 170: train_loss: 0.3883067134850343 train_accuracy: 0.8397666666666667 test_loss: 0.42855807210810515 test_accuracy: 0.8231\n",
      "Iteraions 171: train_loss: 0.38648189927084675 train_accuracy: 0.8405333333333334 test_loss: 0.430320985917973 test_accuracy: 0.823\n",
      "Iteraions 172: train_loss: 0.38627871519500634 train_accuracy: 0.8394666666666667 test_loss: 0.4300200828857919 test_accuracy: 0.8258\n",
      "Iteraions 173: train_loss: 0.3849541980445444 train_accuracy: 0.84095 test_loss: 0.4291133842732002 test_accuracy: 0.825\n",
      "Iteraions 174: train_loss: 0.3833291215369374 train_accuracy: 0.8415833333333333 test_loss: 0.4236095521339904 test_accuracy: 0.8245\n",
      "Iteraions 175: train_loss: 0.3837402857315483 train_accuracy: 0.8413833333333334 test_loss: 0.4242344442805228 test_accuracy: 0.8274\n",
      "Iteraions 176: train_loss: 0.3828101167404424 train_accuracy: 0.8427166666666667 test_loss: 0.4292411188783498 test_accuracy: 0.8238\n",
      "Iteraions 177: train_loss: 0.38190858244347825 train_accuracy: 0.8419 test_loss: 0.42650954464922525 test_accuracy: 0.8258\n",
      "Iteraions 178: train_loss: 0.3794748460364444 train_accuracy: 0.8427833333333333 test_loss: 0.4241951520581244 test_accuracy: 0.8248\n",
      "Iteraions 179: train_loss: 0.378195687036338 train_accuracy: 0.8440166666666666 test_loss: 0.4215460132609114 test_accuracy: 0.8274\n",
      "Iteraions 180: train_loss: 0.37847372440153026 train_accuracy: 0.8452166666666666 test_loss: 0.42206512199100427 test_accuracy: 0.8263\n",
      "Iteraions 181: train_loss: 0.3771413300037691 train_accuracy: 0.8445666666666667 test_loss: 0.42429914743208863 test_accuracy: 0.8253\n",
      "Iteraions 182: train_loss: 0.3764848834239712 train_accuracy: 0.8441333333333333 test_loss: 0.422377353248451 test_accuracy: 0.8256\n",
      "Iteraions 183: train_loss: 0.37443948013009115 train_accuracy: 0.8459166666666667 test_loss: 0.4188313411753128 test_accuracy: 0.8275\n",
      "Iteraions 184: train_loss: 0.3728590097321292 train_accuracy: 0.8469 test_loss: 0.4152521994565157 test_accuracy: 0.8301\n",
      "Iteraions 185: train_loss: 0.373374378595187 train_accuracy: 0.846 test_loss: 0.4185164625435398 test_accuracy: 0.8293\n",
      "Iteraions 186: train_loss: 0.3714187078401006 train_accuracy: 0.84555 test_loss: 0.4202917645141779 test_accuracy: 0.8276\n",
      "Iteraions 187: train_loss: 0.3705040428744455 train_accuracy: 0.8475666666666667 test_loss: 0.41487918280115127 test_accuracy: 0.8307\n",
      "Iteraions 188: train_loss: 0.36848961034366196 train_accuracy: 0.8481166666666666 test_loss: 0.41044193805095236 test_accuracy: 0.8316\n",
      "Iteraions 189: train_loss: 0.368582691428908 train_accuracy: 0.8490333333333333 test_loss: 0.4157343531750421 test_accuracy: 0.8285\n",
      "Iteraions 190: train_loss: 0.3690007073011007 train_accuracy: 0.8480166666666666 test_loss: 0.4114323359677277 test_accuracy: 0.8331\n",
      "Iteraions 191: train_loss: 0.36914714038376817 train_accuracy: 0.8481 test_loss: 0.4154026664045196 test_accuracy: 0.8307\n",
      "Iteraions 192: train_loss: 0.36734537827715447 train_accuracy: 0.8480833333333333 test_loss: 0.41102481404389457 test_accuracy: 0.8337\n",
      "Iteraions 193: train_loss: 0.36470052828086214 train_accuracy: 0.8489 test_loss: 0.41008804623021733 test_accuracy: 0.8335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 194: train_loss: 0.3659370800092179 train_accuracy: 0.8493333333333334 test_loss: 0.4112635071737064 test_accuracy: 0.8307\n",
      "Iteraions 195: train_loss: 0.3647032745453975 train_accuracy: 0.8505666666666667 test_loss: 0.409523861417645 test_accuracy: 0.8327\n",
      "Iteraions 196: train_loss: 0.3612954965384542 train_accuracy: 0.85115 test_loss: 0.4088856688562483 test_accuracy: 0.8293\n",
      "Iteraions 197: train_loss: 0.3623779607721632 train_accuracy: 0.8504 test_loss: 0.4049688798241493 test_accuracy: 0.8316\n",
      "Iteraions 198: train_loss: 0.3620258659075233 train_accuracy: 0.8504 test_loss: 0.4064514872905096 test_accuracy: 0.8346\n",
      "Iteraions 199: train_loss: 0.3607571719569957 train_accuracy: 0.8516333333333334 test_loss: 0.40721159256053907 test_accuracy: 0.8335\n",
      "Iteraions 200: train_loss: 0.35977572949255665 train_accuracy: 0.8531 test_loss: 0.404519428385062 test_accuracy: 0.8345\n",
      "Iteraions 201: train_loss: 0.3595523007271974 train_accuracy: 0.8534333333333334 test_loss: 0.4066766535981981 test_accuracy: 0.8331\n",
      "Iteraions 202: train_loss: 0.3578544736534962 train_accuracy: 0.8542166666666666 test_loss: 0.4047839750584972 test_accuracy: 0.8357\n",
      "Iteraions 203: train_loss: 0.357902172442582 train_accuracy: 0.8525166666666667 test_loss: 0.408119381175158 test_accuracy: 0.8332\n",
      "Iteraions 204: train_loss: 0.3559307805535197 train_accuracy: 0.8549 test_loss: 0.3999676827818515 test_accuracy: 0.834\n",
      "Iteraions 205: train_loss: 0.35451531405408554 train_accuracy: 0.8538333333333333 test_loss: 0.4033127479035759 test_accuracy: 0.836\n",
      "Iteraions 206: train_loss: 0.3554342822616698 train_accuracy: 0.8537166666666667 test_loss: 0.4033828238019779 test_accuracy: 0.8365\n",
      "Iteraions 207: train_loss: 0.35436505255825057 train_accuracy: 0.85445 test_loss: 0.39976563965176026 test_accuracy: 0.8359\n",
      "Iteraions 208: train_loss: 0.3542347387572363 train_accuracy: 0.8560666666666666 test_loss: 0.39960021853528627 test_accuracy: 0.8348\n",
      "Iteraions 209: train_loss: 0.35228306286005767 train_accuracy: 0.85605 test_loss: 0.4007473356451875 test_accuracy: 0.8359\n",
      "Iteraions 210: train_loss: 0.3510712242426773 train_accuracy: 0.8561166666666666 test_loss: 0.3976530460914385 test_accuracy: 0.8383\n",
      "Iteraions 211: train_loss: 0.35122631721164255 train_accuracy: 0.8555833333333334 test_loss: 0.39957009205923294 test_accuracy: 0.838\n",
      "Iteraions 212: train_loss: 0.3483628383532886 train_accuracy: 0.8574666666666667 test_loss: 0.39523741963324055 test_accuracy: 0.8385\n",
      "Iteraions 213: train_loss: 0.34795303669464783 train_accuracy: 0.85745 test_loss: 0.3973939028818024 test_accuracy: 0.8394\n",
      "Iteraions 214: train_loss: 0.34903491890336663 train_accuracy: 0.8581666666666666 test_loss: 0.3981912144213246 test_accuracy: 0.8386\n",
      "Iteraions 215: train_loss: 0.3473691349856731 train_accuracy: 0.85735 test_loss: 0.39564103386251953 test_accuracy: 0.84\n",
      "Iteraions 216: train_loss: 0.3463458780368242 train_accuracy: 0.8586166666666667 test_loss: 0.396574019332218 test_accuracy: 0.8389\n",
      "Iteraions 217: train_loss: 0.3447941918896956 train_accuracy: 0.8586 test_loss: 0.39305589816988257 test_accuracy: 0.8393\n",
      "Iteraions 218: train_loss: 0.3433891483488039 train_accuracy: 0.8591 test_loss: 0.3959344571980935 test_accuracy: 0.8399\n",
      "Iteraions 219: train_loss: 0.3442811735078371 train_accuracy: 0.8590833333333333 test_loss: 0.3954628745537609 test_accuracy: 0.8388\n",
      "Iteraions 220: train_loss: 0.3433003093179319 train_accuracy: 0.85935 test_loss: 0.3949294335275957 test_accuracy: 0.8407\n",
      "Iteraions 221: train_loss: 0.34375016394733343 train_accuracy: 0.8601166666666666 test_loss: 0.39306630432603384 test_accuracy: 0.8409\n",
      "Iteraions 222: train_loss: 0.3439264683105139 train_accuracy: 0.8587333333333333 test_loss: 0.39502488100208205 test_accuracy: 0.8422\n",
      "Iteraions 223: train_loss: 0.34331584554097266 train_accuracy: 0.8596333333333334 test_loss: 0.3964567282678354 test_accuracy: 0.8414\n",
      "Iteraions 224: train_loss: 0.34017384477014734 train_accuracy: 0.8591833333333333 test_loss: 0.3927945244524038 test_accuracy: 0.8416\n",
      "Iteraions 225: train_loss: 0.34009947869948326 train_accuracy: 0.8610333333333333 test_loss: 0.3949298540603101 test_accuracy: 0.8406\n",
      "Iteraions 226: train_loss: 0.34010924361540984 train_accuracy: 0.8620666666666666 test_loss: 0.39161699295001245 test_accuracy: 0.8428\n",
      "Iteraions 227: train_loss: 0.33941747441258524 train_accuracy: 0.8616833333333334 test_loss: 0.389445400965928 test_accuracy: 0.8422\n",
      "Iteraions 228: train_loss: 0.33813915889135915 train_accuracy: 0.8617666666666667 test_loss: 0.3900840315904841 test_accuracy: 0.842\n",
      "Iteraions 229: train_loss: 0.33627483427693455 train_accuracy: 0.8621666666666666 test_loss: 0.39169062765978485 test_accuracy: 0.8391\n",
      "Iteraions 230: train_loss: 0.33648215405701126 train_accuracy: 0.86325 test_loss: 0.38538417867878805 test_accuracy: 0.8474\n",
      "Iteraions 231: train_loss: 0.3355553021290624 train_accuracy: 0.8625333333333334 test_loss: 0.3934402852499732 test_accuracy: 0.8435\n",
      "Iteraions 232: train_loss: 0.334332769729686 train_accuracy: 0.8628666666666667 test_loss: 0.38739226572492014 test_accuracy: 0.8447\n",
      "Iteraions 233: train_loss: 0.33298282039487154 train_accuracy: 0.864 test_loss: 0.38708076224609483 test_accuracy: 0.8433\n",
      "Iteraions 234: train_loss: 0.3342688374057673 train_accuracy: 0.86295 test_loss: 0.3913357120139943 test_accuracy: 0.8432\n",
      "Iteraions 235: train_loss: 0.3325626230296297 train_accuracy: 0.8652 test_loss: 0.3866200474446717 test_accuracy: 0.8464\n",
      "Iteraions 236: train_loss: 0.33149985267245197 train_accuracy: 0.8644166666666667 test_loss: 0.3885859157917717 test_accuracy: 0.8404\n",
      "Iteraions 237: train_loss: 0.3306173696799378 train_accuracy: 0.8655 test_loss: 0.3864761642530566 test_accuracy: 0.8449\n",
      "Iteraions 238: train_loss: 0.33228438688638234 train_accuracy: 0.8661 test_loss: 0.38514524092259644 test_accuracy: 0.8431\n",
      "Iteraions 239: train_loss: 0.3296199567474909 train_accuracy: 0.8649 test_loss: 0.3852151622076466 test_accuracy: 0.8425\n",
      "Iteraions 240: train_loss: 0.32797366808690837 train_accuracy: 0.8666 test_loss: 0.38010262236936737 test_accuracy: 0.8456\n",
      "Iteraions 241: train_loss: 0.3291565179080142 train_accuracy: 0.8660166666666667 test_loss: 0.3863099285762402 test_accuracy: 0.8453\n",
      "Iteraions 242: train_loss: 0.32792880062496493 train_accuracy: 0.8660666666666667 test_loss: 0.3857500032714439 test_accuracy: 0.8443\n",
      "Iteraions 243: train_loss: 0.3266541393108157 train_accuracy: 0.8663333333333333 test_loss: 0.38389676347346857 test_accuracy: 0.8451\n",
      "Iteraions 244: train_loss: 0.3254243811940718 train_accuracy: 0.8681333333333333 test_loss: 0.3833680900500746 test_accuracy: 0.8453\n",
      "Iteraions 245: train_loss: 0.3259823964173389 train_accuracy: 0.8673666666666666 test_loss: 0.38495114267989383 test_accuracy: 0.8442\n",
      "Iteraions 246: train_loss: 0.3248877332843942 train_accuracy: 0.868 test_loss: 0.37994067653275504 test_accuracy: 0.8459\n",
      "Iteraions 247: train_loss: 0.32393404173689017 train_accuracy: 0.8670666666666667 test_loss: 0.3806172491850336 test_accuracy: 0.8482\n",
      "Iteraions 248: train_loss: 0.3246629181332394 train_accuracy: 0.8680333333333333 test_loss: 0.38188156981218685 test_accuracy: 0.8471\n",
      "Iteraions 249: train_loss: 0.32290461524846664 train_accuracy: 0.8682666666666666 test_loss: 0.3804997547351081 test_accuracy: 0.8454\n",
      "Iteraions 250: train_loss: 0.32156510703501184 train_accuracy: 0.8689833333333333 test_loss: 0.377755373513583 test_accuracy: 0.8476\n",
      "Iteraions 251: train_loss: 0.32200753390115705 train_accuracy: 0.8684166666666666 test_loss: 0.3779891495654636 test_accuracy: 0.8495\n",
      "Iteraions 252: train_loss: 0.31994038002348946 train_accuracy: 0.8705166666666667 test_loss: 0.3795677370222889 test_accuracy: 0.8476\n",
      "Iteraions 253: train_loss: 0.3197754986751672 train_accuracy: 0.8693666666666666 test_loss: 0.3810327119044974 test_accuracy: 0.848\n",
      "Iteraions 254: train_loss: 0.3196187066943529 train_accuracy: 0.8701333333333333 test_loss: 0.3787213678255229 test_accuracy: 0.8483\n",
      "Iteraions 255: train_loss: 0.3184082004366179 train_accuracy: 0.8700833333333333 test_loss: 0.3824071734281508 test_accuracy: 0.847\n",
      "Iteraions 256: train_loss: 0.3189348007398604 train_accuracy: 0.8707666666666667 test_loss: 0.3769725795309227 test_accuracy: 0.8506\n",
      "Iteraions 257: train_loss: 0.3177124534465489 train_accuracy: 0.8712666666666666 test_loss: 0.3788139774267537 test_accuracy: 0.8483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 258: train_loss: 0.317105952555197 train_accuracy: 0.8708 test_loss: 0.37575330594432743 test_accuracy: 0.8503\n",
      "Iteraions 259: train_loss: 0.31751850294868816 train_accuracy: 0.8710333333333333 test_loss: 0.37611453715934656 test_accuracy: 0.8472\n",
      "Iteraions 260: train_loss: 0.3155317101440147 train_accuracy: 0.8710166666666667 test_loss: 0.37630057750037776 test_accuracy: 0.8506\n",
      "Iteraions 261: train_loss: 0.3149475649438585 train_accuracy: 0.8722166666666666 test_loss: 0.37675360783591677 test_accuracy: 0.8486\n",
      "Iteraions 262: train_loss: 0.3147731672365158 train_accuracy: 0.8728333333333333 test_loss: 0.37286850427946844 test_accuracy: 0.8516\n",
      "Iteraions 263: train_loss: 0.3137097715563848 train_accuracy: 0.8741166666666667 test_loss: 0.37308154364527363 test_accuracy: 0.8493\n",
      "Iteraions 264: train_loss: 0.31339139591881165 train_accuracy: 0.8733666666666666 test_loss: 0.3708685619893549 test_accuracy: 0.8495\n",
      "Iteraions 265: train_loss: 0.3120372529846427 train_accuracy: 0.8735 test_loss: 0.3767379150184848 test_accuracy: 0.8478\n",
      "Iteraions 266: train_loss: 0.31402873589586316 train_accuracy: 0.8730833333333333 test_loss: 0.36968951898850116 test_accuracy: 0.8498\n",
      "Iteraions 267: train_loss: 0.3107314348675788 train_accuracy: 0.8732166666666666 test_loss: 0.3780262264046439 test_accuracy: 0.8508\n",
      "Iteraions 268: train_loss: 0.31030329210580626 train_accuracy: 0.8735 test_loss: 0.3711836443827536 test_accuracy: 0.8505\n",
      "Iteraions 269: train_loss: 0.3104932416600175 train_accuracy: 0.8741166666666667 test_loss: 0.37064210200270453 test_accuracy: 0.8537\n",
      "Iteraions 270: train_loss: 0.30959665867130987 train_accuracy: 0.8746 test_loss: 0.37186630338311505 test_accuracy: 0.8535\n",
      "Iteraions 271: train_loss: 0.30993182458498375 train_accuracy: 0.8737166666666667 test_loss: 0.37299761791178027 test_accuracy: 0.8504\n",
      "Iteraions 272: train_loss: 0.3082340283977102 train_accuracy: 0.875 test_loss: 0.37505346070802087 test_accuracy: 0.8497\n",
      "Iteraions 273: train_loss: 0.3082331372188207 train_accuracy: 0.8764 test_loss: 0.37464077777595645 test_accuracy: 0.8515\n",
      "Iteraions 274: train_loss: 0.3070133113602367 train_accuracy: 0.8753 test_loss: 0.3682266435958065 test_accuracy: 0.8497\n",
      "Iteraions 275: train_loss: 0.3062245441655344 train_accuracy: 0.8763333333333333 test_loss: 0.3709404399432348 test_accuracy: 0.8539\n",
      "Iteraions 276: train_loss: 0.3065647061296242 train_accuracy: 0.8749833333333333 test_loss: 0.3737976837720816 test_accuracy: 0.851\n",
      "Iteraions 277: train_loss: 0.30508757452396534 train_accuracy: 0.87545 test_loss: 0.3700112939226116 test_accuracy: 0.8523\n",
      "Iteraions 278: train_loss: 0.30554661956747 train_accuracy: 0.8751333333333333 test_loss: 0.36839061313813765 test_accuracy: 0.851\n",
      "Iteraions 279: train_loss: 0.3049036579126913 train_accuracy: 0.8762666666666666 test_loss: 0.3670805007978555 test_accuracy: 0.8549\n",
      "Iteraions 280: train_loss: 0.3023748004963405 train_accuracy: 0.8769 test_loss: 0.3655574161733121 test_accuracy: 0.8555\n",
      "Iteraions 281: train_loss: 0.3044399819174952 train_accuracy: 0.8769 test_loss: 0.3683639978192836 test_accuracy: 0.8531\n",
      "Iteraions 282: train_loss: 0.30274456321296866 train_accuracy: 0.8770666666666667 test_loss: 0.36937314563930207 test_accuracy: 0.8528\n",
      "Iteraions 283: train_loss: 0.30246993197679595 train_accuracy: 0.8777333333333334 test_loss: 0.3689791632645163 test_accuracy: 0.8545\n",
      "Iteraions 284: train_loss: 0.3013552211711979 train_accuracy: 0.8785166666666666 test_loss: 0.3710131076189677 test_accuracy: 0.8549\n",
      "Iteraions 285: train_loss: 0.3001638990760851 train_accuracy: 0.8781666666666667 test_loss: 0.3656013334267962 test_accuracy: 0.8519\n",
      "Iteraions 286: train_loss: 0.29929496523297144 train_accuracy: 0.8795166666666666 test_loss: 0.36686412324171613 test_accuracy: 0.8573\n",
      "Iteraions 287: train_loss: 0.29995158819786627 train_accuracy: 0.8779833333333333 test_loss: 0.3676115747333039 test_accuracy: 0.8533\n",
      "Iteraions 288: train_loss: 0.29994874108205927 train_accuracy: 0.8782333333333333 test_loss: 0.36675680400850225 test_accuracy: 0.8529\n",
      "Iteraions 289: train_loss: 0.29980681258315794 train_accuracy: 0.8784 test_loss: 0.36709250775204066 test_accuracy: 0.8533\n",
      "Iteraions 290: train_loss: 0.298075606368918 train_accuracy: 0.8784333333333333 test_loss: 0.3686246379763833 test_accuracy: 0.853\n",
      "Iteraions 291: train_loss: 0.29722326287944 train_accuracy: 0.8805 test_loss: 0.3596870624513298 test_accuracy: 0.8555\n",
      "Iteraions 292: train_loss: 0.29645021381587905 train_accuracy: 0.87925 test_loss: 0.36310679346863806 test_accuracy: 0.8551\n",
      "Iteraions 293: train_loss: 0.29733059888065755 train_accuracy: 0.8792833333333333 test_loss: 0.3624516662921075 test_accuracy: 0.8587\n",
      "Iteraions 294: train_loss: 0.29573102391964046 train_accuracy: 0.8802333333333333 test_loss: 0.3624943098777827 test_accuracy: 0.8546\n",
      "Iteraions 295: train_loss: 0.2965770855940295 train_accuracy: 0.87995 test_loss: 0.36340836264698123 test_accuracy: 0.8552\n",
      "Iteraions 296: train_loss: 0.2945841460888979 train_accuracy: 0.88005 test_loss: 0.36127482749558987 test_accuracy: 0.8542\n",
      "Iteraions 297: train_loss: 0.2959770585383267 train_accuracy: 0.88015 test_loss: 0.3629683399464619 test_accuracy: 0.8562\n",
      "Iteraions 298: train_loss: 0.2950481579355557 train_accuracy: 0.8807166666666667 test_loss: 0.3719034836494416 test_accuracy: 0.8544\n",
      "Iteraions 299: train_loss: 0.29448923208045724 train_accuracy: 0.8802333333333333 test_loss: 0.3613539900870993 test_accuracy: 0.8555\n",
      "Iteraions 300: train_loss: 0.29162264065336857 train_accuracy: 0.8819 test_loss: 0.3621711560526639 test_accuracy: 0.8571\n",
      "Iteraions 301: train_loss: 0.29215524856022446 train_accuracy: 0.8815666666666667 test_loss: 0.3567027367663044 test_accuracy: 0.8596\n",
      "Iteraions 302: train_loss: 0.2929942216690432 train_accuracy: 0.8804833333333333 test_loss: 0.363929834432074 test_accuracy: 0.8566\n",
      "Iteraions 303: train_loss: 0.29224059998265767 train_accuracy: 0.8821166666666667 test_loss: 0.3632349428473172 test_accuracy: 0.8561\n",
      "Iteraions 304: train_loss: 0.29201326809269856 train_accuracy: 0.8821333333333333 test_loss: 0.3592663891023085 test_accuracy: 0.8572\n",
      "Iteraions 305: train_loss: 0.2902326523514603 train_accuracy: 0.88305 test_loss: 0.3561368441567242 test_accuracy: 0.8566\n",
      "Iteraions 306: train_loss: 0.2901632024149977 train_accuracy: 0.88245 test_loss: 0.36303406055856235 test_accuracy: 0.8556\n",
      "Iteraions 307: train_loss: 0.29145062767298663 train_accuracy: 0.8813666666666666 test_loss: 0.35961509244797246 test_accuracy: 0.8555\n",
      "Iteraions 308: train_loss: 0.2887440509944172 train_accuracy: 0.8840666666666667 test_loss: 0.35996470984133705 test_accuracy: 0.8589\n",
      "Iteraions 309: train_loss: 0.28916462022408873 train_accuracy: 0.8827833333333334 test_loss: 0.35982738825263366 test_accuracy: 0.8566\n",
      "Iteraions 310: train_loss: 0.2881012369233846 train_accuracy: 0.88305 test_loss: 0.3633486385896889 test_accuracy: 0.8557\n",
      "Iteraions 311: train_loss: 0.287858710997525 train_accuracy: 0.8835333333333333 test_loss: 0.3569478561072707 test_accuracy: 0.8583\n",
      "Iteraions 312: train_loss: 0.28612055714239243 train_accuracy: 0.8840666666666667 test_loss: 0.36055368873763266 test_accuracy: 0.8582\n",
      "Iteraions 313: train_loss: 0.287047053610833 train_accuracy: 0.8827166666666667 test_loss: 0.35631841567683425 test_accuracy: 0.8584\n",
      "Iteraions 314: train_loss: 0.285168315835342 train_accuracy: 0.8842166666666667 test_loss: 0.35749543129663813 test_accuracy: 0.8598\n",
      "Iteraions 315: train_loss: 0.28640344515412275 train_accuracy: 0.8836666666666667 test_loss: 0.3617381393707243 test_accuracy: 0.8579\n",
      "Iteraions 316: train_loss: 0.2849063685760525 train_accuracy: 0.8855166666666666 test_loss: 0.3575794667580014 test_accuracy: 0.8576\n",
      "Iteraions 317: train_loss: 0.2844566640518675 train_accuracy: 0.8839833333333333 test_loss: 0.35874346615790015 test_accuracy: 0.8554\n",
      "Iteraions 318: train_loss: 0.28307692633286513 train_accuracy: 0.8855666666666666 test_loss: 0.35808460446718665 test_accuracy: 0.8561\n",
      "Iteraions 319: train_loss: 0.2826978143593639 train_accuracy: 0.8845666666666666 test_loss: 0.3578752554354797 test_accuracy: 0.8573\n",
      "Iteraions 320: train_loss: 0.2837846393306896 train_accuracy: 0.8845166666666666 test_loss: 0.3583943981819083 test_accuracy: 0.8553\n",
      "Iteraions 321: train_loss: 0.28332567104370626 train_accuracy: 0.8850166666666667 test_loss: 0.35882020891806093 test_accuracy: 0.8608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 322: train_loss: 0.2817240652395602 train_accuracy: 0.8865333333333333 test_loss: 0.35404550048169275 test_accuracy: 0.8598\n",
      "Iteraions 323: train_loss: 0.27978975153223695 train_accuracy: 0.88525 test_loss: 0.3580604944579429 test_accuracy: 0.8583\n",
      "Iteraions 324: train_loss: 0.2821763197984658 train_accuracy: 0.8856166666666667 test_loss: 0.3563924664548027 test_accuracy: 0.8578\n",
      "Iteraions 325: train_loss: 0.2807668051587232 train_accuracy: 0.8858666666666667 test_loss: 0.3602975064527972 test_accuracy: 0.8591\n",
      "Iteraions 326: train_loss: 0.2798691902684104 train_accuracy: 0.8867666666666667 test_loss: 0.35224881336610736 test_accuracy: 0.8611\n",
      "Iteraions 327: train_loss: 0.280805835654469 train_accuracy: 0.8866833333333334 test_loss: 0.35731674109887956 test_accuracy: 0.859\n",
      "Iteraions 328: train_loss: 0.27997681925249673 train_accuracy: 0.8870333333333333 test_loss: 0.3570005803836301 test_accuracy: 0.8612\n",
      "Iteraions 329: train_loss: 0.27935832791762927 train_accuracy: 0.88765 test_loss: 0.35680111074872883 test_accuracy: 0.8584\n",
      "Iteraions 330: train_loss: 0.2788820551205962 train_accuracy: 0.8868 test_loss: 0.35921788339232363 test_accuracy: 0.8602\n",
      "Iteraions 331: train_loss: 0.2790242114730836 train_accuracy: 0.8863666666666666 test_loss: 0.3550688442499544 test_accuracy: 0.8602\n",
      "Iteraions 332: train_loss: 0.27737824367051467 train_accuracy: 0.8888666666666667 test_loss: 0.3569656000712766 test_accuracy: 0.857\n",
      "Iteraions 333: train_loss: 0.27565883618723075 train_accuracy: 0.8880666666666667 test_loss: 0.3505318077523565 test_accuracy: 0.8624\n",
      "Iteraions 334: train_loss: 0.2772109156675535 train_accuracy: 0.8880166666666667 test_loss: 0.3550743544640131 test_accuracy: 0.8602\n",
      "Iteraions 335: train_loss: 0.2747333041229984 train_accuracy: 0.8897333333333334 test_loss: 0.3524271047637119 test_accuracy: 0.859\n",
      "Iteraions 336: train_loss: 0.2750045612318949 train_accuracy: 0.8904 test_loss: 0.35471334671041227 test_accuracy: 0.864\n",
      "Iteraions 337: train_loss: 0.2749707561182591 train_accuracy: 0.8888166666666667 test_loss: 0.3520541427087477 test_accuracy: 0.8609\n",
      "Iteraions 338: train_loss: 0.2735736174073209 train_accuracy: 0.8874833333333333 test_loss: 0.3544114821439188 test_accuracy: 0.8646\n",
      "Iteraions 339: train_loss: 0.2740762985910001 train_accuracy: 0.8886333333333334 test_loss: 0.3515836053355562 test_accuracy: 0.8617\n",
      "Iteraions 340: train_loss: 0.2742511988037789 train_accuracy: 0.88935 test_loss: 0.35407608086597053 test_accuracy: 0.8615\n",
      "Iteraions 341: train_loss: 0.27510401173000004 train_accuracy: 0.8891833333333333 test_loss: 0.3574463640262725 test_accuracy: 0.861\n",
      "Iteraions 342: train_loss: 0.27299234955441654 train_accuracy: 0.8882 test_loss: 0.35105336730427256 test_accuracy: 0.8625\n",
      "Iteraions 343: train_loss: 0.273058846394185 train_accuracy: 0.8891833333333333 test_loss: 0.34998589164849375 test_accuracy: 0.8628\n",
      "Iteraions 344: train_loss: 0.27068806558125974 train_accuracy: 0.8908833333333334 test_loss: 0.3531327816950341 test_accuracy: 0.8611\n",
      "Iteraions 345: train_loss: 0.27298776145883025 train_accuracy: 0.88975 test_loss: 0.35519972452656906 test_accuracy: 0.8606\n",
      "Iteraions 346: train_loss: 0.2748447347627675 train_accuracy: 0.8893666666666666 test_loss: 0.35119444402927347 test_accuracy: 0.863\n",
      "Iteraions 347: train_loss: 0.2724689751576235 train_accuracy: 0.8884833333333333 test_loss: 0.35219938031341436 test_accuracy: 0.8623\n",
      "Iteraions 348: train_loss: 0.2704512090608405 train_accuracy: 0.89 test_loss: 0.3532992090814264 test_accuracy: 0.8633\n",
      "Iteraions 349: train_loss: 0.2705504318018992 train_accuracy: 0.8895833333333333 test_loss: 0.3520365278695517 test_accuracy: 0.8598\n",
      "Iteraions 350: train_loss: 0.27025197567222087 train_accuracy: 0.8909 test_loss: 0.35013968375575466 test_accuracy: 0.8616\n",
      "Iteraions 351: train_loss: 0.2688276140190004 train_accuracy: 0.8904833333333333 test_loss: 0.3460144269548113 test_accuracy: 0.8641\n",
      "Iteraions 352: train_loss: 0.26868307304667977 train_accuracy: 0.8913166666666666 test_loss: 0.3503485886693085 test_accuracy: 0.863\n",
      "Iteraions 353: train_loss: 0.2685872970200278 train_accuracy: 0.8913 test_loss: 0.3532660485155443 test_accuracy: 0.8608\n",
      "Iteraions 354: train_loss: 0.26783297880552104 train_accuracy: 0.8925666666666666 test_loss: 0.34989046114846906 test_accuracy: 0.8617\n",
      "Iteraions 355: train_loss: 0.267508766681532 train_accuracy: 0.8912166666666667 test_loss: 0.3510183323979831 test_accuracy: 0.8645\n",
      "Iteraions 356: train_loss: 0.2680109192406826 train_accuracy: 0.8917666666666667 test_loss: 0.3506198869561975 test_accuracy: 0.8621\n",
      "Iteraions 357: train_loss: 0.2638274451244714 train_accuracy: 0.8935666666666666 test_loss: 0.3503684962075263 test_accuracy: 0.8635\n",
      "Iteraions 358: train_loss: 0.26587109845474194 train_accuracy: 0.89195 test_loss: 0.34766952955128505 test_accuracy: 0.8651\n",
      "Iteraions 359: train_loss: 0.26726660493441695 train_accuracy: 0.8913333333333333 test_loss: 0.3462299544045549 test_accuracy: 0.8646\n",
      "Iteraions 360: train_loss: 0.26546018183841247 train_accuracy: 0.8914 test_loss: 0.34839609144901523 test_accuracy: 0.8653\n",
      "Iteraions 361: train_loss: 0.2663075788264496 train_accuracy: 0.8939333333333334 test_loss: 0.3522614726989694 test_accuracy: 0.8622\n",
      "Iteraions 362: train_loss: 0.2648419502962995 train_accuracy: 0.89355 test_loss: 0.34316007974810675 test_accuracy: 0.8658\n",
      "Iteraions 363: train_loss: 0.2641329795487128 train_accuracy: 0.89185 test_loss: 0.35102085572164626 test_accuracy: 0.8644\n",
      "Iteraions 364: train_loss: 0.2624273808978079 train_accuracy: 0.8938 test_loss: 0.34734365425315133 test_accuracy: 0.8649\n",
      "Iteraions 365: train_loss: 0.26177323687710924 train_accuracy: 0.8941 test_loss: 0.35155530574618754 test_accuracy: 0.8628\n",
      "Iteraions 366: train_loss: 0.26263929513008527 train_accuracy: 0.8938333333333334 test_loss: 0.3451224297065493 test_accuracy: 0.8671\n",
      "Iteraions 367: train_loss: 0.26319103867365273 train_accuracy: 0.8938333333333334 test_loss: 0.34861898699846194 test_accuracy: 0.863\n",
      "Iteraions 368: train_loss: 0.2636997521099894 train_accuracy: 0.89355 test_loss: 0.3457562756313021 test_accuracy: 0.8658\n",
      "Iteraions 369: train_loss: 0.2629016904572789 train_accuracy: 0.8936666666666667 test_loss: 0.3453772125204436 test_accuracy: 0.865\n",
      "Iteraions 370: train_loss: 0.26186493150682316 train_accuracy: 0.8933833333333333 test_loss: 0.3421616632837513 test_accuracy: 0.8669\n",
      "Iteraions 371: train_loss: 0.25987938926855403 train_accuracy: 0.8952333333333333 test_loss: 0.3473415552407237 test_accuracy: 0.8636\n",
      "Iteraions 372: train_loss: 0.2602855921874338 train_accuracy: 0.8952333333333333 test_loss: 0.3416325672886231 test_accuracy: 0.8684\n",
      "Iteraions 373: train_loss: 0.2604651131982984 train_accuracy: 0.8950833333333333 test_loss: 0.34321988356386013 test_accuracy: 0.8655\n",
      "Iteraions 374: train_loss: 0.2584669519577172 train_accuracy: 0.89615 test_loss: 0.34622809400721455 test_accuracy: 0.8665\n",
      "Iteraions 375: train_loss: 0.2594366932065199 train_accuracy: 0.8955833333333333 test_loss: 0.34266527461190427 test_accuracy: 0.8658\n",
      "Iteraions 376: train_loss: 0.25945863274862174 train_accuracy: 0.89545 test_loss: 0.3459711271182011 test_accuracy: 0.8648\n",
      "Iteraions 377: train_loss: 0.25970637331921365 train_accuracy: 0.8951666666666667 test_loss: 0.34341074360123314 test_accuracy: 0.8649\n",
      "Iteraions 378: train_loss: 0.2566422850746008 train_accuracy: 0.8961333333333333 test_loss: 0.3492322121088657 test_accuracy: 0.864\n",
      "Iteraions 379: train_loss: 0.25631128603861597 train_accuracy: 0.89635 test_loss: 0.3497531255946023 test_accuracy: 0.8649\n",
      "Iteraions 380: train_loss: 0.2570987238502146 train_accuracy: 0.89575 test_loss: 0.3440342796936772 test_accuracy: 0.8673\n",
      "Iteraions 381: train_loss: 0.2579678070825042 train_accuracy: 0.8961333333333333 test_loss: 0.3464549219432712 test_accuracy: 0.867\n",
      "Iteraions 382: train_loss: 0.2565463539015737 train_accuracy: 0.8957166666666667 test_loss: 0.3456084479640728 test_accuracy: 0.867\n",
      "Iteraions 383: train_loss: 0.2553159415094072 train_accuracy: 0.8969333333333334 test_loss: 0.340805096999182 test_accuracy: 0.8672\n",
      "Iteraions 384: train_loss: 0.25524900550473983 train_accuracy: 0.8971166666666667 test_loss: 0.3427531805692881 test_accuracy: 0.8709\n",
      "Iteraions 385: train_loss: 0.2543425315654262 train_accuracy: 0.8972833333333333 test_loss: 0.34372226974136355 test_accuracy: 0.8682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 386: train_loss: 0.254791184419815 train_accuracy: 0.8976 test_loss: 0.3463449676691359 test_accuracy: 0.8659\n",
      "Iteraions 387: train_loss: 0.25320945353319374 train_accuracy: 0.8974 test_loss: 0.3424458185487935 test_accuracy: 0.8702\n",
      "Iteraions 388: train_loss: 0.2538760505843189 train_accuracy: 0.8984833333333333 test_loss: 0.34377029618445676 test_accuracy: 0.8657\n",
      "Iteraions 389: train_loss: 0.25370844526905734 train_accuracy: 0.8981 test_loss: 0.3472968428196773 test_accuracy: 0.8642\n",
      "Iteraions 390: train_loss: 0.2546120334370833 train_accuracy: 0.89675 test_loss: 0.3429817587539731 test_accuracy: 0.8691\n",
      "Iteraions 391: train_loss: 0.2513618402945614 train_accuracy: 0.89855 test_loss: 0.34981326661309886 test_accuracy: 0.8669\n",
      "Iteraions 392: train_loss: 0.2524672170400029 train_accuracy: 0.8976 test_loss: 0.3453596986090053 test_accuracy: 0.8674\n",
      "Iteraions 393: train_loss: 0.25238847498805267 train_accuracy: 0.8981333333333333 test_loss: 0.3456327643087457 test_accuracy: 0.863\n",
      "Iteraions 394: train_loss: 0.25073416196848064 train_accuracy: 0.8991333333333333 test_loss: 0.34185650178518107 test_accuracy: 0.8671\n",
      "Iteraions 395: train_loss: 0.2532419566205979 train_accuracy: 0.898 test_loss: 0.3447367602701677 test_accuracy: 0.8685\n",
      "Iteraions 396: train_loss: 0.2514054092096866 train_accuracy: 0.8987166666666667 test_loss: 0.3462978755759746 test_accuracy: 0.8668\n",
      "Iteraions 397: train_loss: 0.2508341993752581 train_accuracy: 0.89825 test_loss: 0.341798439905054 test_accuracy: 0.8681\n",
      "Iteraions 398: train_loss: 0.25094739205261735 train_accuracy: 0.8984166666666666 test_loss: 0.3470925668029781 test_accuracy: 0.87\n",
      "Iteraions 399: train_loss: 0.24887924050806484 train_accuracy: 0.89935 test_loss: 0.34482921828847946 test_accuracy: 0.8666\n",
      "Iteraions 400: train_loss: 0.24907760575794272 train_accuracy: 0.8990833333333333 test_loss: 0.345053660895103 test_accuracy: 0.8672\n",
      "Iteraions 401: train_loss: 0.2493095977352346 train_accuracy: 0.8988833333333334 test_loss: 0.34394932248505466 test_accuracy: 0.8671\n",
      "Iteraions 402: train_loss: 0.25092040509530006 train_accuracy: 0.89885 test_loss: 0.34114474353425933 test_accuracy: 0.8669\n",
      "Iteraions 403: train_loss: 0.24948312367128073 train_accuracy: 0.8981666666666667 test_loss: 0.3457098820553174 test_accuracy: 0.8677\n",
      "Iteraions 404: train_loss: 0.24972063842056982 train_accuracy: 0.9004833333333333 test_loss: 0.34452015097037075 test_accuracy: 0.8698\n",
      "Iteraions 405: train_loss: 0.24843040202002636 train_accuracy: 0.8997 test_loss: 0.34444376737862953 test_accuracy: 0.8696\n",
      "Iteraions 406: train_loss: 0.24816120400535677 train_accuracy: 0.8999 test_loss: 0.34585765173255795 test_accuracy: 0.8682\n",
      "Iteraions 407: train_loss: 0.24550432199241312 train_accuracy: 0.9014 test_loss: 0.340232489944222 test_accuracy: 0.8685\n",
      "Iteraions 408: train_loss: 0.2463674487086043 train_accuracy: 0.8998833333333334 test_loss: 0.3446556995891797 test_accuracy: 0.8695\n",
      "Iteraions 409: train_loss: 0.2478178523257171 train_accuracy: 0.9004833333333333 test_loss: 0.3470873961654807 test_accuracy: 0.8676\n",
      "Iteraions 410: train_loss: 0.24691472990202318 train_accuracy: 0.8992666666666667 test_loss: 0.34482996016132506 test_accuracy: 0.8669\n",
      "Iteraions 411: train_loss: 0.24659520705549767 train_accuracy: 0.9000166666666667 test_loss: 0.341353356034441 test_accuracy: 0.8664\n",
      "Iteraions 412: train_loss: 0.24304370930390545 train_accuracy: 0.9021166666666667 test_loss: 0.3420314758614702 test_accuracy: 0.868\n",
      "Iteraions 413: train_loss: 0.245869101889591 train_accuracy: 0.8997166666666667 test_loss: 0.3403943744140512 test_accuracy: 0.8674\n",
      "Iteraions 414: train_loss: 0.2456332419123845 train_accuracy: 0.9009 test_loss: 0.3396616196656525 test_accuracy: 0.8696\n",
      "Iteraions 415: train_loss: 0.24420929703887123 train_accuracy: 0.9016833333333333 test_loss: 0.34210941794093985 test_accuracy: 0.8696\n",
      "Iteraions 416: train_loss: 0.2436589872155521 train_accuracy: 0.90135 test_loss: 0.33996792095959666 test_accuracy: 0.8685\n",
      "Iteraions 417: train_loss: 0.24250629389247175 train_accuracy: 0.9013333333333333 test_loss: 0.34411985934684997 test_accuracy: 0.8732\n",
      "Iteraions 418: train_loss: 0.2437377621857913 train_accuracy: 0.9020666666666667 test_loss: 0.34022556204794796 test_accuracy: 0.87\n",
      "Iteraions 419: train_loss: 0.24189522108436298 train_accuracy: 0.9018666666666667 test_loss: 0.344417088953211 test_accuracy: 0.8677\n",
      "Iteraions 420: train_loss: 0.24462487032191263 train_accuracy: 0.9009666666666667 test_loss: 0.3407128547509108 test_accuracy: 0.8714\n",
      "Iteraions 421: train_loss: 0.24476324522258266 train_accuracy: 0.9015666666666666 test_loss: 0.3453988103728927 test_accuracy: 0.8687\n",
      "Iteraions 422: train_loss: 0.24269606902504845 train_accuracy: 0.9019666666666667 test_loss: 0.339388751496285 test_accuracy: 0.8698\n",
      "Iteraions 423: train_loss: 0.24078217162777701 train_accuracy: 0.9033 test_loss: 0.34500349003254643 test_accuracy: 0.8677\n",
      "Iteraions 424: train_loss: 0.24258824579390004 train_accuracy: 0.90185 test_loss: 0.3404374319965191 test_accuracy: 0.8699\n",
      "Iteraions 425: train_loss: 0.24213641637953978 train_accuracy: 0.9034666666666666 test_loss: 0.34241324674811613 test_accuracy: 0.8686\n",
      "Iteraions 426: train_loss: 0.24185393318665857 train_accuracy: 0.9024833333333333 test_loss: 0.34296655994272823 test_accuracy: 0.8681\n",
      "Iteraions 427: train_loss: 0.24021267707949845 train_accuracy: 0.9022833333333333 test_loss: 0.3416951095123749 test_accuracy: 0.8663\n",
      "Iteraions 428: train_loss: 0.2387236403481013 train_accuracy: 0.9037 test_loss: 0.3421873630334059 test_accuracy: 0.8703\n",
      "Iteraions 429: train_loss: 0.23932705469456386 train_accuracy: 0.9039666666666667 test_loss: 0.3448589829746501 test_accuracy: 0.8704\n",
      "Iteraions 430: train_loss: 0.2395612842608014 train_accuracy: 0.9036 test_loss: 0.34326881567779766 test_accuracy: 0.87\n",
      "Iteraions 431: train_loss: 0.23949797263922046 train_accuracy: 0.9035 test_loss: 0.3364787384262159 test_accuracy: 0.8712\n",
      "Iteraions 432: train_loss: 0.23871222359811559 train_accuracy: 0.9038333333333334 test_loss: 0.34068561406482556 test_accuracy: 0.8698\n",
      "Iteraions 433: train_loss: 0.23814257930302468 train_accuracy: 0.9056666666666666 test_loss: 0.33920285637534014 test_accuracy: 0.8679\n",
      "Iteraions 434: train_loss: 0.23818878685051847 train_accuracy: 0.9031333333333333 test_loss: 0.3398012573867316 test_accuracy: 0.8723\n",
      "Iteraions 435: train_loss: 0.23835184341162852 train_accuracy: 0.9039833333333334 test_loss: 0.33700050990524477 test_accuracy: 0.8691\n",
      "Iteraions 436: train_loss: 0.23817220708471645 train_accuracy: 0.9035666666666666 test_loss: 0.3447267936285413 test_accuracy: 0.8694\n",
      "Iteraions 437: train_loss: 0.23750964947934444 train_accuracy: 0.9031833333333333 test_loss: 0.34538379405879416 test_accuracy: 0.8684\n",
      "Iteraions 438: train_loss: 0.23556827487678259 train_accuracy: 0.9052 test_loss: 0.3382036303117239 test_accuracy: 0.8718\n",
      "Iteraions 439: train_loss: 0.23668493044982036 train_accuracy: 0.90465 test_loss: 0.34256160973495425 test_accuracy: 0.8715\n",
      "Iteraions 440: train_loss: 0.23596052217544478 train_accuracy: 0.9046333333333333 test_loss: 0.34108485392961 test_accuracy: 0.8718\n",
      "Iteraions 441: train_loss: 0.23438891221538052 train_accuracy: 0.9048666666666667 test_loss: 0.3408392016230356 test_accuracy: 0.8662\n",
      "Iteraions 442: train_loss: 0.23410261065447308 train_accuracy: 0.9058666666666667 test_loss: 0.3377103953066647 test_accuracy: 0.8724\n",
      "Iteraions 443: train_loss: 0.23405765393587813 train_accuracy: 0.9058333333333334 test_loss: 0.3407605800410659 test_accuracy: 0.871\n",
      "Iteraions 444: train_loss: 0.23369993789960902 train_accuracy: 0.9051833333333333 test_loss: 0.34097132212340475 test_accuracy: 0.8696\n",
      "Iteraions 445: train_loss: 0.23273054315871852 train_accuracy: 0.9062166666666667 test_loss: 0.3416024445926228 test_accuracy: 0.8713\n",
      "Iteraions 446: train_loss: 0.2324076570322412 train_accuracy: 0.90555 test_loss: 0.339579073543181 test_accuracy: 0.871\n",
      "Iteraions 447: train_loss: 0.23158967714797885 train_accuracy: 0.9066833333333333 test_loss: 0.33952679586493356 test_accuracy: 0.8701\n",
      "Iteraions 448: train_loss: 0.23269745754124138 train_accuracy: 0.90745 test_loss: 0.3413288488978259 test_accuracy: 0.8716\n",
      "Iteraions 449: train_loss: 0.23182311130313282 train_accuracy: 0.9066 test_loss: 0.3380795848060297 test_accuracy: 0.8732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 450: train_loss: 0.23337585906207606 train_accuracy: 0.90635 test_loss: 0.34181774739863574 test_accuracy: 0.8717\n",
      "Iteraions 451: train_loss: 0.23134764395143773 train_accuracy: 0.9072666666666667 test_loss: 0.3393107253021405 test_accuracy: 0.87\n",
      "Iteraions 452: train_loss: 0.2296006577155771 train_accuracy: 0.9074 test_loss: 0.3370841063156702 test_accuracy: 0.8689\n",
      "Iteraions 453: train_loss: 0.2308295750448276 train_accuracy: 0.9073 test_loss: 0.3391958395345679 test_accuracy: 0.8706\n",
      "Iteraions 454: train_loss: 0.2335390233083401 train_accuracy: 0.9068 test_loss: 0.34009366918957173 test_accuracy: 0.8716\n",
      "Iteraions 455: train_loss: 0.23078741528572705 train_accuracy: 0.90815 test_loss: 0.34227531981502163 test_accuracy: 0.8684\n",
      "Iteraions 456: train_loss: 0.23058585010281832 train_accuracy: 0.9066833333333333 test_loss: 0.3411217446413812 test_accuracy: 0.8731\n",
      "Iteraions 457: train_loss: 0.22985978256938744 train_accuracy: 0.9084666666666666 test_loss: 0.3416383801019185 test_accuracy: 0.872\n",
      "Iteraions 458: train_loss: 0.22919290571425893 train_accuracy: 0.9078666666666667 test_loss: 0.3403720726084823 test_accuracy: 0.8711\n",
      "Iteraions 459: train_loss: 0.2305852219613768 train_accuracy: 0.9077333333333333 test_loss: 0.34100490678929807 test_accuracy: 0.8697\n",
      "Iteraions 460: train_loss: 0.22801505716312245 train_accuracy: 0.9078666666666667 test_loss: 0.34235512870564616 test_accuracy: 0.8693\n",
      "Iteraions 461: train_loss: 0.23053219723174628 train_accuracy: 0.9068 test_loss: 0.34218341377270445 test_accuracy: 0.8734\n",
      "Iteraions 462: train_loss: 0.22948500166133162 train_accuracy: 0.90775 test_loss: 0.34498956153225485 test_accuracy: 0.871\n",
      "Iteraions 463: train_loss: 0.22772525168857252 train_accuracy: 0.9082 test_loss: 0.33842874359192493 test_accuracy: 0.8706\n",
      "Iteraions 464: train_loss: 0.22962111520330075 train_accuracy: 0.9083166666666667 test_loss: 0.3413718440819232 test_accuracy: 0.8715\n",
      "Iteraions 465: train_loss: 0.2289060244107268 train_accuracy: 0.90725 test_loss: 0.3379956879389614 test_accuracy: 0.8718\n",
      "Iteraions 466: train_loss: 0.22859484601892563 train_accuracy: 0.908 test_loss: 0.3401961301380681 test_accuracy: 0.8716\n",
      "Iteraions 467: train_loss: 0.22788311858420954 train_accuracy: 0.9092666666666667 test_loss: 0.3378796960058924 test_accuracy: 0.8718\n",
      "Iteraions 468: train_loss: 0.22640175165275445 train_accuracy: 0.9091833333333333 test_loss: 0.33636562726738367 test_accuracy: 0.8696\n",
      "Iteraions 469: train_loss: 0.22813507857304685 train_accuracy: 0.9085833333333333 test_loss: 0.34166531602726735 test_accuracy: 0.8716\n",
      "Iteraions 470: train_loss: 0.2285200060497538 train_accuracy: 0.9083833333333333 test_loss: 0.33767393945116125 test_accuracy: 0.8732\n",
      "Iteraions 471: train_loss: 0.2282593855014212 train_accuracy: 0.9089166666666667 test_loss: 0.3385025023512364 test_accuracy: 0.8715\n",
      "Iteraions 472: train_loss: 0.22469881448183282 train_accuracy: 0.9094666666666666 test_loss: 0.34291343443492517 test_accuracy: 0.8736\n",
      "Iteraions 473: train_loss: 0.22374982950028285 train_accuracy: 0.9108166666666667 test_loss: 0.3424712180831112 test_accuracy: 0.8734\n",
      "Iteraions 474: train_loss: 0.22551433567019197 train_accuracy: 0.9099833333333334 test_loss: 0.3380217145563555 test_accuracy: 0.8709\n",
      "Iteraions 475: train_loss: 0.22568936528710473 train_accuracy: 0.9092 test_loss: 0.346278948950114 test_accuracy: 0.8721\n",
      "Iteraions 476: train_loss: 0.2232775557849402 train_accuracy: 0.9114666666666666 test_loss: 0.3394144144500917 test_accuracy: 0.8736\n",
      "Iteraions 477: train_loss: 0.22388116376608105 train_accuracy: 0.9102 test_loss: 0.3390854444725845 test_accuracy: 0.8726\n",
      "Iteraions 478: train_loss: 0.22223913436579823 train_accuracy: 0.9121333333333334 test_loss: 0.3335061073199773 test_accuracy: 0.8739\n",
      "Iteraions 479: train_loss: 0.2244466514844012 train_accuracy: 0.9102833333333333 test_loss: 0.3354677077635696 test_accuracy: 0.8746\n",
      "Iteraions 480: train_loss: 0.2239902401669599 train_accuracy: 0.91025 test_loss: 0.33955866538689977 test_accuracy: 0.8725\n",
      "Iteraions 481: train_loss: 0.22206270783208443 train_accuracy: 0.9111333333333334 test_loss: 0.3386659643127935 test_accuracy: 0.871\n",
      "Iteraions 482: train_loss: 0.22260850149248523 train_accuracy: 0.91115 test_loss: 0.33830962144722576 test_accuracy: 0.8751\n",
      "Iteraions 483: train_loss: 0.2229683591106443 train_accuracy: 0.9113666666666667 test_loss: 0.3390215840643227 test_accuracy: 0.8737\n",
      "Iteraions 484: train_loss: 0.22201995591619186 train_accuracy: 0.91145 test_loss: 0.33847909493120976 test_accuracy: 0.8751\n",
      "Iteraions 485: train_loss: 0.22013820552268493 train_accuracy: 0.9113666666666667 test_loss: 0.34256336364091067 test_accuracy: 0.8729\n",
      "Iteraions 486: train_loss: 0.2209287421940415 train_accuracy: 0.9109333333333334 test_loss: 0.34104715216264586 test_accuracy: 0.8705\n",
      "Iteraions 487: train_loss: 0.2211420204525704 train_accuracy: 0.91095 test_loss: 0.34154009126605395 test_accuracy: 0.8708\n",
      "Iteraions 488: train_loss: 0.219728210471094 train_accuracy: 0.9123166666666667 test_loss: 0.3356212521001357 test_accuracy: 0.8715\n",
      "Iteraions 489: train_loss: 0.21911126707584735 train_accuracy: 0.9119333333333334 test_loss: 0.33585091425373703 test_accuracy: 0.8733\n",
      "Iteraions 490: train_loss: 0.21937168054794615 train_accuracy: 0.9127166666666666 test_loss: 0.33727385968380125 test_accuracy: 0.8741\n",
      "Iteraions 491: train_loss: 0.21946129486603627 train_accuracy: 0.9103833333333333 test_loss: 0.33890237343537627 test_accuracy: 0.8734\n",
      "Iteraions 492: train_loss: 0.2181535348148306 train_accuracy: 0.9123666666666667 test_loss: 0.33690313999749705 test_accuracy: 0.8723\n",
      "Iteraions 493: train_loss: 0.2182817240374387 train_accuracy: 0.9128166666666667 test_loss: 0.3421739067736291 test_accuracy: 0.8733\n",
      "Iteraions 494: train_loss: 0.21835545683540858 train_accuracy: 0.91115 test_loss: 0.3373526935902827 test_accuracy: 0.8718\n",
      "Iteraions 495: train_loss: 0.21895676125780392 train_accuracy: 0.91215 test_loss: 0.33948359346209384 test_accuracy: 0.8779\n",
      "Iteraions 496: train_loss: 0.21745882034589287 train_accuracy: 0.9121666666666667 test_loss: 0.33576952957896056 test_accuracy: 0.8744\n",
      "Iteraions 497: train_loss: 0.21716938705696193 train_accuracy: 0.9128666666666667 test_loss: 0.33830985858879903 test_accuracy: 0.8753\n",
      "Iteraions 498: train_loss: 0.21791444927590392 train_accuracy: 0.9135833333333333 test_loss: 0.33754202210794976 test_accuracy: 0.874\n",
      "Iteraions 499: train_loss: 0.21616976558631862 train_accuracy: 0.9121833333333333 test_loss: 0.34581713383229473 test_accuracy: 0.8722\n",
      "Iteraions 500: train_loss: 0.21659965321417637 train_accuracy: 0.9128333333333334 test_loss: 0.33823190068064046 test_accuracy: 0.8746\n",
      "Iteraions 501: train_loss: 0.21686317562580265 train_accuracy: 0.9124 test_loss: 0.3347007400336962 test_accuracy: 0.8758\n",
      "Iteraions 502: train_loss: 0.21747337671881165 train_accuracy: 0.9127 test_loss: 0.3456832114900819 test_accuracy: 0.8704\n",
      "Iteraions 503: train_loss: 0.21671438439700688 train_accuracy: 0.9127833333333333 test_loss: 0.338535438179267 test_accuracy: 0.8762\n",
      "Iteraions 504: train_loss: 0.2155041528607038 train_accuracy: 0.9138666666666667 test_loss: 0.33979544696475833 test_accuracy: 0.8745\n",
      "Iteraions 505: train_loss: 0.21615646383055398 train_accuracy: 0.9136833333333333 test_loss: 0.3441846155237489 test_accuracy: 0.8712\n",
      "Iteraions 506: train_loss: 0.21529442422412817 train_accuracy: 0.91425 test_loss: 0.3393566043353011 test_accuracy: 0.8763\n",
      "Iteraions 507: train_loss: 0.21433936197085718 train_accuracy: 0.9142 test_loss: 0.3373504953268415 test_accuracy: 0.8764\n",
      "Iteraions 508: train_loss: 0.21495681303151482 train_accuracy: 0.9144166666666667 test_loss: 0.34037753019736217 test_accuracy: 0.8738\n",
      "Iteraions 509: train_loss: 0.21384484893992908 train_accuracy: 0.9147833333333333 test_loss: 0.3459450374072037 test_accuracy: 0.8739\n",
      "Iteraions 510: train_loss: 0.21262052538315626 train_accuracy: 0.9145833333333333 test_loss: 0.33707848437898047 test_accuracy: 0.8757\n",
      "Iteraions 511: train_loss: 0.21316355385151375 train_accuracy: 0.9153666666666667 test_loss: 0.33867473800327397 test_accuracy: 0.8739\n",
      "Iteraions 512: train_loss: 0.21261077052716282 train_accuracy: 0.91535 test_loss: 0.33803336583342747 test_accuracy: 0.8744\n",
      "Iteraions 513: train_loss: 0.21203069456459211 train_accuracy: 0.9156166666666666 test_loss: 0.33185667620658743 test_accuracy: 0.8764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 514: train_loss: 0.21082615138657815 train_accuracy: 0.9149666666666667 test_loss: 0.3400281695028149 test_accuracy: 0.8734\n",
      "Iteraions 515: train_loss: 0.2115458347655848 train_accuracy: 0.91505 test_loss: 0.3425315836400333 test_accuracy: 0.8732\n",
      "Iteraions 516: train_loss: 0.21047811419606344 train_accuracy: 0.9156666666666666 test_loss: 0.34083780954162535 test_accuracy: 0.8718\n",
      "Iteraions 517: train_loss: 0.2122873255667519 train_accuracy: 0.91545 test_loss: 0.3373471614493948 test_accuracy: 0.8756\n",
      "Iteraions 518: train_loss: 0.21159605778734908 train_accuracy: 0.9160833333333334 test_loss: 0.33902834990893754 test_accuracy: 0.8726\n",
      "Iteraions 519: train_loss: 0.21117904331049173 train_accuracy: 0.9147666666666666 test_loss: 0.33858912632475563 test_accuracy: 0.8763\n",
      "Iteraions 520: train_loss: 0.21215381141118514 train_accuracy: 0.9161166666666667 test_loss: 0.3365081800341552 test_accuracy: 0.8739\n",
      "Iteraions 521: train_loss: 0.2117912613995483 train_accuracy: 0.9147 test_loss: 0.3364848995524787 test_accuracy: 0.8765\n",
      "Iteraions 522: train_loss: 0.21156504391502476 train_accuracy: 0.9150833333333334 test_loss: 0.3379281943189318 test_accuracy: 0.8761\n",
      "Iteraions 523: train_loss: 0.21002117363733033 train_accuracy: 0.9152 test_loss: 0.3414804505170858 test_accuracy: 0.8733\n",
      "Iteraions 524: train_loss: 0.2090899589891822 train_accuracy: 0.9153833333333333 test_loss: 0.3434783293284025 test_accuracy: 0.8745\n",
      "Iteraions 525: train_loss: 0.20890004314208746 train_accuracy: 0.9176833333333333 test_loss: 0.34086727132084244 test_accuracy: 0.8746\n",
      "Iteraions 526: train_loss: 0.2093080804956954 train_accuracy: 0.9164166666666667 test_loss: 0.3405718397054025 test_accuracy: 0.8753\n",
      "Iteraions 527: train_loss: 0.20875445043061105 train_accuracy: 0.91575 test_loss: 0.3391800900002698 test_accuracy: 0.8752\n",
      "Iteraions 528: train_loss: 0.20967841481008484 train_accuracy: 0.9162666666666667 test_loss: 0.34155242023889926 test_accuracy: 0.8742\n",
      "Iteraions 529: train_loss: 0.21034939779887787 train_accuracy: 0.9156333333333333 test_loss: 0.3411556030110989 test_accuracy: 0.8742\n",
      "Iteraions 530: train_loss: 0.20955753904229343 train_accuracy: 0.9157166666666666 test_loss: 0.33813794932104985 test_accuracy: 0.8746\n",
      "Iteraions 531: train_loss: 0.2084520614060642 train_accuracy: 0.91625 test_loss: 0.34032086062194344 test_accuracy: 0.8729\n",
      "Iteraions 532: train_loss: 0.20805386452766925 train_accuracy: 0.9171 test_loss: 0.3395840694782708 test_accuracy: 0.8751\n",
      "Iteraions 533: train_loss: 0.20507815116253514 train_accuracy: 0.9187333333333333 test_loss: 0.3402826879687016 test_accuracy: 0.8759\n",
      "Iteraions 534: train_loss: 0.20727262201524269 train_accuracy: 0.9174666666666667 test_loss: 0.3394381342016311 test_accuracy: 0.8738\n",
      "Iteraions 535: train_loss: 0.207085668028278 train_accuracy: 0.9169333333333334 test_loss: 0.33979868623638665 test_accuracy: 0.8742\n",
      "Iteraions 536: train_loss: 0.20714408793755618 train_accuracy: 0.9166833333333333 test_loss: 0.3429528650639319 test_accuracy: 0.8739\n",
      "Iteraions 537: train_loss: 0.20642131574915415 train_accuracy: 0.9178333333333333 test_loss: 0.33879481662975935 test_accuracy: 0.8766\n",
      "Iteraions 538: train_loss: 0.2046684638908228 train_accuracy: 0.9181166666666667 test_loss: 0.34166397692061506 test_accuracy: 0.8762\n",
      "Iteraions 539: train_loss: 0.20623729786044823 train_accuracy: 0.9179666666666667 test_loss: 0.33657248276819635 test_accuracy: 0.8761\n",
      "Iteraions 540: train_loss: 0.20436292175470408 train_accuracy: 0.9173333333333333 test_loss: 0.33866866769960163 test_accuracy: 0.8778\n",
      "Iteraions 541: train_loss: 0.2043778998481484 train_accuracy: 0.9180333333333334 test_loss: 0.3378842697671539 test_accuracy: 0.8748\n",
      "Iteraions 542: train_loss: 0.20490769766205172 train_accuracy: 0.9173833333333333 test_loss: 0.33667479452887944 test_accuracy: 0.8763\n",
      "Iteraions 543: train_loss: 0.2054657295970005 train_accuracy: 0.9166 test_loss: 0.34217964186736866 test_accuracy: 0.8741\n",
      "Iteraions 544: train_loss: 0.2050850419967388 train_accuracy: 0.9177166666666666 test_loss: 0.34404225411328926 test_accuracy: 0.8749\n",
      "Iteraions 545: train_loss: 0.20352974990576592 train_accuracy: 0.9181 test_loss: 0.34179867897344557 test_accuracy: 0.874\n",
      "Iteraions 546: train_loss: 0.20278535654020569 train_accuracy: 0.9182833333333333 test_loss: 0.3389648264725573 test_accuracy: 0.8766\n",
      "Iteraions 547: train_loss: 0.20229038012453643 train_accuracy: 0.9193166666666667 test_loss: 0.3405606871377485 test_accuracy: 0.8749\n",
      "Iteraions 548: train_loss: 0.20286255357041075 train_accuracy: 0.9190666666666667 test_loss: 0.34528200135223913 test_accuracy: 0.8751\n",
      "Iteraions 549: train_loss: 0.2028238170373054 train_accuracy: 0.9187166666666666 test_loss: 0.34247651511033667 test_accuracy: 0.8731\n",
      "Iteraions 550: train_loss: 0.20371837813338128 train_accuracy: 0.9178166666666666 test_loss: 0.3409268978332227 test_accuracy: 0.8761\n",
      "Iteraions 551: train_loss: 0.20446049236435304 train_accuracy: 0.9177833333333333 test_loss: 0.3449658662652524 test_accuracy: 0.8745\n",
      "Iteraions 552: train_loss: 0.20803820169080625 train_accuracy: 0.9165333333333333 test_loss: 0.34239596790983823 test_accuracy: 0.8724\n",
      "Iteraions 553: train_loss: 0.20712331346407953 train_accuracy: 0.9177666666666666 test_loss: 0.3478023968528219 test_accuracy: 0.8673\n",
      "Iteraions 554: train_loss: 0.20508196584792976 train_accuracy: 0.91775 test_loss: 0.3434719912034764 test_accuracy: 0.8739\n",
      "Iteraions 555: train_loss: 0.20140083810030887 train_accuracy: 0.91905 test_loss: 0.34071603843852216 test_accuracy: 0.8765\n",
      "Iteraions 556: train_loss: 0.2005236756404502 train_accuracy: 0.9188333333333333 test_loss: 0.34248855249602034 test_accuracy: 0.8753\n",
      "Iteraions 557: train_loss: 0.20216746679437614 train_accuracy: 0.9195333333333333 test_loss: 0.3393905292661974 test_accuracy: 0.8765\n",
      "Iteraions 558: train_loss: 0.2024778226610652 train_accuracy: 0.91905 test_loss: 0.34905152946498713 test_accuracy: 0.8744\n",
      "Iteraions 559: train_loss: 0.20170588036769477 train_accuracy: 0.9190666666666667 test_loss: 0.33890127061842834 test_accuracy: 0.8775\n",
      "Iteraions 560: train_loss: 0.19932336792518537 train_accuracy: 0.9206 test_loss: 0.3404981055947278 test_accuracy: 0.874\n",
      "Iteraions 561: train_loss: 0.19963677549950803 train_accuracy: 0.9202166666666667 test_loss: 0.34453296167577274 test_accuracy: 0.8745\n",
      "Iteraions 562: train_loss: 0.20098121703622893 train_accuracy: 0.9201833333333334 test_loss: 0.3389473397764256 test_accuracy: 0.8778\n",
      "Iteraions 563: train_loss: 0.1996408097612796 train_accuracy: 0.9194833333333333 test_loss: 0.3386484090263559 test_accuracy: 0.8775\n",
      "Iteraions 564: train_loss: 0.1982338569408656 train_accuracy: 0.92185 test_loss: 0.3380752562907478 test_accuracy: 0.8759\n",
      "Iteraions 565: train_loss: 0.19890899999058825 train_accuracy: 0.9202333333333333 test_loss: 0.3314948884545933 test_accuracy: 0.8781\n",
      "Iteraions 566: train_loss: 0.19879665292406964 train_accuracy: 0.92115 test_loss: 0.3410917769234884 test_accuracy: 0.8732\n",
      "Iteraions 567: train_loss: 0.1978409216540979 train_accuracy: 0.9213166666666667 test_loss: 0.3359726550586266 test_accuracy: 0.8765\n",
      "Iteraions 568: train_loss: 0.19726215012881573 train_accuracy: 0.9213833333333333 test_loss: 0.34286962919957503 test_accuracy: 0.8768\n",
      "Iteraions 569: train_loss: 0.198553097835331 train_accuracy: 0.92085 test_loss: 0.3431285913638371 test_accuracy: 0.8749\n",
      "Iteraions 570: train_loss: 0.1956490935624482 train_accuracy: 0.9217166666666666 test_loss: 0.34423606091174586 test_accuracy: 0.8751\n",
      "Iteraions 571: train_loss: 0.19734710602018968 train_accuracy: 0.9217833333333333 test_loss: 0.34229081861551025 test_accuracy: 0.8785\n",
      "Iteraions 572: train_loss: 0.19796224542585453 train_accuracy: 0.9215 test_loss: 0.33928083623740196 test_accuracy: 0.8758\n",
      "Iteraions 573: train_loss: 0.19941247004136742 train_accuracy: 0.92115 test_loss: 0.3410162549034385 test_accuracy: 0.8752\n",
      "Iteraions 574: train_loss: 0.19676463252923573 train_accuracy: 0.9222 test_loss: 0.3425121652267426 test_accuracy: 0.8778\n",
      "Iteraions 575: train_loss: 0.19446011241131111 train_accuracy: 0.9224 test_loss: 0.33517945849410397 test_accuracy: 0.8764\n",
      "Iteraions 576: train_loss: 0.19663616819022076 train_accuracy: 0.9212833333333333 test_loss: 0.3435640818496274 test_accuracy: 0.873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 577: train_loss: 0.19592594262271926 train_accuracy: 0.9222 test_loss: 0.33988970706503113 test_accuracy: 0.876\n",
      "Iteraions 578: train_loss: 0.1938819878315513 train_accuracy: 0.9224 test_loss: 0.347754391849714 test_accuracy: 0.8736\n",
      "Iteraions 579: train_loss: 0.1955073124269432 train_accuracy: 0.9227333333333333 test_loss: 0.3446177402473261 test_accuracy: 0.878\n",
      "Iteraions 580: train_loss: 0.19479016472113175 train_accuracy: 0.92265 test_loss: 0.34324766368653026 test_accuracy: 0.8737\n",
      "Iteraions 581: train_loss: 0.1936959709558805 train_accuracy: 0.9237666666666666 test_loss: 0.3411517977331199 test_accuracy: 0.8802\n",
      "Iteraions 582: train_loss: 0.19454052518686482 train_accuracy: 0.9226 test_loss: 0.3395386349844529 test_accuracy: 0.8727\n",
      "Iteraions 583: train_loss: 0.19122103633960197 train_accuracy: 0.9224333333333333 test_loss: 0.3428458789202068 test_accuracy: 0.8771\n",
      "Iteraions 584: train_loss: 0.19408930596227184 train_accuracy: 0.9228 test_loss: 0.3401725039753425 test_accuracy: 0.8767\n",
      "Iteraions 585: train_loss: 0.1932310696253741 train_accuracy: 0.9229166666666667 test_loss: 0.34367702653674503 test_accuracy: 0.8747\n",
      "Iteraions 586: train_loss: 0.19413865789117526 train_accuracy: 0.9228666666666666 test_loss: 0.34008113635271836 test_accuracy: 0.877\n",
      "Iteraions 587: train_loss: 0.19430767720969358 train_accuracy: 0.9220833333333334 test_loss: 0.346984305001595 test_accuracy: 0.8756\n",
      "Iteraions 588: train_loss: 0.19257561968635448 train_accuracy: 0.9229666666666667 test_loss: 0.3447540918917792 test_accuracy: 0.8761\n",
      "Iteraions 589: train_loss: 0.19175846076837216 train_accuracy: 0.9235666666666666 test_loss: 0.3465187232410313 test_accuracy: 0.8755\n",
      "Iteraions 590: train_loss: 0.19038344055615852 train_accuracy: 0.9237 test_loss: 0.34085768598293226 test_accuracy: 0.8782\n",
      "Iteraions 591: train_loss: 0.19146506071316877 train_accuracy: 0.9238 test_loss: 0.3382524806914571 test_accuracy: 0.8771\n",
      "Iteraions 592: train_loss: 0.19205172602757611 train_accuracy: 0.9234333333333333 test_loss: 0.34283623950763775 test_accuracy: 0.8755\n",
      "Iteraions 593: train_loss: 0.19238745637654883 train_accuracy: 0.9233666666666667 test_loss: 0.3455497729170758 test_accuracy: 0.876\n",
      "Iteraions 594: train_loss: 0.19286565120569243 train_accuracy: 0.9228 test_loss: 0.3384655224688434 test_accuracy: 0.8772\n",
      "Iteraions 595: train_loss: 0.1924454749676818 train_accuracy: 0.9233666666666667 test_loss: 0.33910291862459596 test_accuracy: 0.8781\n",
      "Iteraions 596: train_loss: 0.19149672784063176 train_accuracy: 0.9236666666666666 test_loss: 0.3419901162220453 test_accuracy: 0.8762\n",
      "Iteraions 597: train_loss: 0.19010588885888963 train_accuracy: 0.9251 test_loss: 0.3394499459943107 test_accuracy: 0.8756\n",
      "Iteraions 598: train_loss: 0.19007236681179548 train_accuracy: 0.9247 test_loss: 0.34676706789420586 test_accuracy: 0.8761\n",
      "Iteraions 599: train_loss: 0.19051944636094656 train_accuracy: 0.9238833333333333 test_loss: 0.3444707562746689 test_accuracy: 0.8753\n",
      "Iteraions 600: train_loss: 0.19129283526915764 train_accuracy: 0.9245166666666667 test_loss: 0.3473985275391638 test_accuracy: 0.876\n",
      "Iteraions 601: train_loss: 0.19071314615716328 train_accuracy: 0.9234166666666667 test_loss: 0.34614314066098156 test_accuracy: 0.8764\n",
      "Iteraions 602: train_loss: 0.19368852607703996 train_accuracy: 0.9236 test_loss: 0.34081291843727807 test_accuracy: 0.8739\n",
      "Iteraions 603: train_loss: 0.19079095493509704 train_accuracy: 0.9238666666666666 test_loss: 0.34455309759082836 test_accuracy: 0.8784\n",
      "Iteraions 604: train_loss: 0.18993619408984597 train_accuracy: 0.9250166666666667 test_loss: 0.3445649850383291 test_accuracy: 0.8775\n",
      "Iteraions 605: train_loss: 0.18726351439215336 train_accuracy: 0.9257833333333333 test_loss: 0.34865928079377784 test_accuracy: 0.8761\n",
      "Iteraions 606: train_loss: 0.187490827372053 train_accuracy: 0.9255166666666667 test_loss: 0.3434522745641969 test_accuracy: 0.8773\n",
      "Iteraions 607: train_loss: 0.18878058329167677 train_accuracy: 0.92615 test_loss: 0.3398241471735585 test_accuracy: 0.8805\n",
      "Iteraions 608: train_loss: 0.1880283501326317 train_accuracy: 0.92545 test_loss: 0.3446807721208264 test_accuracy: 0.8767\n",
      "Iteraions 609: train_loss: 0.18691746490949404 train_accuracy: 0.9256 test_loss: 0.3415052047786811 test_accuracy: 0.8773\n",
      "Iteraions 610: train_loss: 0.18537361909256436 train_accuracy: 0.9274333333333333 test_loss: 0.3429170884008242 test_accuracy: 0.8758\n",
      "Iteraions 611: train_loss: 0.18774398084309374 train_accuracy: 0.9250666666666667 test_loss: 0.34005210558500965 test_accuracy: 0.8768\n",
      "Iteraions 612: train_loss: 0.18663439293031805 train_accuracy: 0.9259666666666667 test_loss: 0.34376632505028487 test_accuracy: 0.8785\n",
      "Iteraions 613: train_loss: 0.18792753702508197 train_accuracy: 0.9243166666666667 test_loss: 0.33949209147022175 test_accuracy: 0.8792\n",
      "Iteraions 614: train_loss: 0.18625351208772117 train_accuracy: 0.9258833333333333 test_loss: 0.3472802709564629 test_accuracy: 0.8771\n",
      "Iteraions 615: train_loss: 0.18783962239960234 train_accuracy: 0.9249666666666667 test_loss: 0.3490961309260144 test_accuracy: 0.8767\n",
      "Iteraions 616: train_loss: 0.18524150690752153 train_accuracy: 0.9260333333333334 test_loss: 0.34205766795920134 test_accuracy: 0.8751\n",
      "Iteraions 617: train_loss: 0.18492760210066275 train_accuracy: 0.9270333333333334 test_loss: 0.3429203501871556 test_accuracy: 0.8762\n",
      "Iteraions 618: train_loss: 0.186442100693083 train_accuracy: 0.9255 test_loss: 0.34553591707372416 test_accuracy: 0.8788\n",
      "Iteraions 619: train_loss: 0.18554552131859497 train_accuracy: 0.9264666666666667 test_loss: 0.3434894456679202 test_accuracy: 0.8794\n",
      "Iteraions 620: train_loss: 0.18539553416931417 train_accuracy: 0.9258833333333333 test_loss: 0.3439450338435697 test_accuracy: 0.8805\n",
      "Iteraions 621: train_loss: 0.1848907366372655 train_accuracy: 0.9276333333333333 test_loss: 0.3479759549436216 test_accuracy: 0.8771\n",
      "Iteraions 622: train_loss: 0.18260847135929398 train_accuracy: 0.9275 test_loss: 0.33537217555681453 test_accuracy: 0.8763\n",
      "Iteraions 623: train_loss: 0.1834630685235752 train_accuracy: 0.9271666666666667 test_loss: 0.34035474054684256 test_accuracy: 0.8801\n",
      "Iteraions 624: train_loss: 0.18363309294091135 train_accuracy: 0.9278833333333333 test_loss: 0.34409856545124257 test_accuracy: 0.8781\n",
      "Iteraions 625: train_loss: 0.18388619258033792 train_accuracy: 0.9264333333333333 test_loss: 0.3513875432662575 test_accuracy: 0.878\n",
      "Iteraions 626: train_loss: 0.18348604728902226 train_accuracy: 0.9272333333333334 test_loss: 0.33805035375325687 test_accuracy: 0.8799\n",
      "Iteraions 627: train_loss: 0.18349500795145735 train_accuracy: 0.9263333333333333 test_loss: 0.3435791608959008 test_accuracy: 0.877\n",
      "Iteraions 628: train_loss: 0.18211009680087042 train_accuracy: 0.9283666666666667 test_loss: 0.3450420351347003 test_accuracy: 0.8794\n",
      "Iteraions 629: train_loss: 0.1818444928193808 train_accuracy: 0.9280833333333334 test_loss: 0.34727025105992715 test_accuracy: 0.8778\n",
      "Iteraions 630: train_loss: 0.18215623971154363 train_accuracy: 0.92795 test_loss: 0.3428785466432286 test_accuracy: 0.8771\n",
      "Iteraions 631: train_loss: 0.183848427785602 train_accuracy: 0.927 test_loss: 0.33944305557422333 test_accuracy: 0.8795\n",
      "Iteraions 632: train_loss: 0.18190617808621534 train_accuracy: 0.9265833333333333 test_loss: 0.340860455865086 test_accuracy: 0.8791\n",
      "Iteraions 633: train_loss: 0.18091123131829007 train_accuracy: 0.9283833333333333 test_loss: 0.3469552703259764 test_accuracy: 0.8757\n",
      "Iteraions 634: train_loss: 0.18197620033206233 train_accuracy: 0.9282833333333333 test_loss: 0.33981042021230423 test_accuracy: 0.8789\n",
      "Iteraions 635: train_loss: 0.18139771694610451 train_accuracy: 0.929 test_loss: 0.34427153876606287 test_accuracy: 0.878\n",
      "Iteraions 636: train_loss: 0.18149919978589735 train_accuracy: 0.9279333333333334 test_loss: 0.34302625780337564 test_accuracy: 0.8769\n",
      "Iteraions 637: train_loss: 0.18099572068837508 train_accuracy: 0.9297333333333333 test_loss: 0.3406837453959204 test_accuracy: 0.8799\n",
      "Iteraions 638: train_loss: 0.18099203454761312 train_accuracy: 0.9282166666666667 test_loss: 0.3437583653898272 test_accuracy: 0.8769\n",
      "Iteraions 639: train_loss: 0.18121855764473166 train_accuracy: 0.9273833333333333 test_loss: 0.34406574493973147 test_accuracy: 0.8767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 640: train_loss: 0.179439633682172 train_accuracy: 0.92975 test_loss: 0.34735807432270377 test_accuracy: 0.8753\n",
      "Iteraions 641: train_loss: 0.17895267209354757 train_accuracy: 0.9288333333333333 test_loss: 0.3454511587279699 test_accuracy: 0.8766\n",
      "Iteraions 642: train_loss: 0.18035212098562017 train_accuracy: 0.929 test_loss: 0.3494920818078843 test_accuracy: 0.8777\n",
      "Iteraions 643: train_loss: 0.17893690499691386 train_accuracy: 0.9298333333333333 test_loss: 0.34515956546103627 test_accuracy: 0.8821\n",
      "Iteraions 644: train_loss: 0.17895333862000898 train_accuracy: 0.9291666666666667 test_loss: 0.33945134653534254 test_accuracy: 0.8797\n",
      "Iteraions 645: train_loss: 0.17835603961302204 train_accuracy: 0.9305166666666667 test_loss: 0.34287414370843733 test_accuracy: 0.8788\n",
      "Iteraions 646: train_loss: 0.1799088373325996 train_accuracy: 0.9284166666666667 test_loss: 0.34565333636492634 test_accuracy: 0.878\n",
      "Iteraions 647: train_loss: 0.1789541120782503 train_accuracy: 0.9283833333333333 test_loss: 0.3488885150621517 test_accuracy: 0.8762\n",
      "Iteraions 648: train_loss: 0.17851727511074583 train_accuracy: 0.929 test_loss: 0.3482914484274397 test_accuracy: 0.88\n",
      "Iteraions 649: train_loss: 0.17777091059276717 train_accuracy: 0.9294833333333333 test_loss: 0.34854931023377017 test_accuracy: 0.8761\n",
      "Iteraions 650: train_loss: 0.17626584090944394 train_accuracy: 0.9312333333333334 test_loss: 0.344755804473092 test_accuracy: 0.8775\n",
      "Iteraions 651: train_loss: 0.17764866027896656 train_accuracy: 0.9289 test_loss: 0.3454602671833491 test_accuracy: 0.8784\n",
      "Iteraions 652: train_loss: 0.1769010963777289 train_accuracy: 0.92955 test_loss: 0.3469660801099107 test_accuracy: 0.877\n",
      "Iteraions 653: train_loss: 0.1784423790055121 train_accuracy: 0.92975 test_loss: 0.34187573152259076 test_accuracy: 0.8777\n",
      "Iteraions 654: train_loss: 0.17699353847284266 train_accuracy: 0.9295333333333333 test_loss: 0.34857147311974934 test_accuracy: 0.8754\n",
      "Iteraions 655: train_loss: 0.17679723956304777 train_accuracy: 0.9298166666666666 test_loss: 0.3441443662005162 test_accuracy: 0.8791\n",
      "Iteraions 656: train_loss: 0.17815289558689976 train_accuracy: 0.93015 test_loss: 0.34819090791165486 test_accuracy: 0.875\n",
      "Iteraions 657: train_loss: 0.17974770553887365 train_accuracy: 0.9292833333333334 test_loss: 0.34350484197485565 test_accuracy: 0.8802\n",
      "Iteraions 658: train_loss: 0.18090890326078035 train_accuracy: 0.92815 test_loss: 0.35669805815662525 test_accuracy: 0.8719\n",
      "Iteraions 659: train_loss: 0.18176939079264587 train_accuracy: 0.9273 test_loss: 0.3517968261630809 test_accuracy: 0.8768\n",
      "Iteraions 660: train_loss: 0.18213844076087954 train_accuracy: 0.9269333333333334 test_loss: 0.3498667698760685 test_accuracy: 0.876\n",
      "Iteraions 661: train_loss: 0.17748200524216529 train_accuracy: 0.9301333333333334 test_loss: 0.34359579319244765 test_accuracy: 0.8778\n",
      "Iteraions 662: train_loss: 0.1749651470090897 train_accuracy: 0.9307166666666666 test_loss: 0.34449056485499113 test_accuracy: 0.8799\n",
      "Iteraions 663: train_loss: 0.17709540792545506 train_accuracy: 0.92865 test_loss: 0.35418306539729644 test_accuracy: 0.8803\n",
      "Iteraions 664: train_loss: 0.17917590866778768 train_accuracy: 0.9285 test_loss: 0.3509400537018207 test_accuracy: 0.8803\n",
      "Iteraions 665: train_loss: 0.17805758998293217 train_accuracy: 0.9293 test_loss: 0.3570529657439646 test_accuracy: 0.8757\n",
      "Iteraions 666: train_loss: 0.17321374734757253 train_accuracy: 0.9315333333333333 test_loss: 0.34858295782931803 test_accuracy: 0.8809\n",
      "Iteraions 667: train_loss: 0.17339806517232095 train_accuracy: 0.9306833333333333 test_loss: 0.34209979735906626 test_accuracy: 0.8785\n",
      "Iteraions 668: train_loss: 0.17464378029121497 train_accuracy: 0.9301 test_loss: 0.35131014775548886 test_accuracy: 0.8761\n",
      "Iteraions 669: train_loss: 0.17824527924874486 train_accuracy: 0.9296333333333333 test_loss: 0.3519511027815436 test_accuracy: 0.8776\n",
      "Iteraions 670: train_loss: 0.17570229606670212 train_accuracy: 0.9305333333333333 test_loss: 0.3527150293886999 test_accuracy: 0.8746\n",
      "Iteraions 671: train_loss: 0.1719937972182952 train_accuracy: 0.9324166666666667 test_loss: 0.3461585961688341 test_accuracy: 0.878\n",
      "Iteraions 672: train_loss: 0.17716548313927388 train_accuracy: 0.93035 test_loss: 0.35205931806918705 test_accuracy: 0.8795\n",
      "Iteraions 673: train_loss: 0.17616828725660671 train_accuracy: 0.9292 test_loss: 0.351469133100415 test_accuracy: 0.876\n",
      "Iteraions 674: train_loss: 0.1749275861335144 train_accuracy: 0.9311166666666667 test_loss: 0.3484796405128458 test_accuracy: 0.8798\n",
      "Iteraions 675: train_loss: 0.1745524509675115 train_accuracy: 0.9312166666666667 test_loss: 0.3461694769783116 test_accuracy: 0.8802\n",
      "Iteraions 676: train_loss: 0.1733762412312516 train_accuracy: 0.9320833333333334 test_loss: 0.34395392928832413 test_accuracy: 0.8783\n",
      "Iteraions 677: train_loss: 0.1746986635294094 train_accuracy: 0.9306 test_loss: 0.3454241126359294 test_accuracy: 0.8799\n",
      "Iteraions 678: train_loss: 0.17252386049573737 train_accuracy: 0.9325666666666667 test_loss: 0.3530556381348571 test_accuracy: 0.877\n",
      "Iteraions 679: train_loss: 0.17025421175216274 train_accuracy: 0.9329166666666666 test_loss: 0.34336637584550517 test_accuracy: 0.8798\n",
      "Iteraions 680: train_loss: 0.1721392886863554 train_accuracy: 0.9312833333333334 test_loss: 0.3448241295583922 test_accuracy: 0.8787\n",
      "Iteraions 681: train_loss: 0.17249343679702045 train_accuracy: 0.9316166666666666 test_loss: 0.3488331144519129 test_accuracy: 0.8758\n",
      "Iteraions 682: train_loss: 0.17334870587432408 train_accuracy: 0.93195 test_loss: 0.3437023233864982 test_accuracy: 0.8832\n",
      "Iteraions 683: train_loss: 0.1709005792177966 train_accuracy: 0.9329 test_loss: 0.34798765919825353 test_accuracy: 0.8781\n",
      "Iteraions 684: train_loss: 0.1687590762643802 train_accuracy: 0.9327833333333333 test_loss: 0.3502053277486586 test_accuracy: 0.8755\n",
      "Iteraions 685: train_loss: 0.1702533962369357 train_accuracy: 0.9313333333333333 test_loss: 0.34953472222151016 test_accuracy: 0.8768\n",
      "Iteraions 686: train_loss: 0.1714827565193102 train_accuracy: 0.93315 test_loss: 0.3513424629076782 test_accuracy: 0.8779\n",
      "Iteraions 687: train_loss: 0.1693476747825875 train_accuracy: 0.9334166666666667 test_loss: 0.34752939182487397 test_accuracy: 0.8805\n",
      "Iteraions 688: train_loss: 0.16881784981977016 train_accuracy: 0.9338666666666666 test_loss: 0.349622845040294 test_accuracy: 0.8792\n",
      "Iteraions 689: train_loss: 0.1691460460153589 train_accuracy: 0.9331166666666667 test_loss: 0.35313733234101746 test_accuracy: 0.8798\n",
      "Iteraions 690: train_loss: 0.16971839691574678 train_accuracy: 0.9322333333333334 test_loss: 0.3520446684156677 test_accuracy: 0.8795\n",
      "Iteraions 691: train_loss: 0.16759276813919166 train_accuracy: 0.9328833333333333 test_loss: 0.3495485795139079 test_accuracy: 0.8783\n",
      "Iteraions 692: train_loss: 0.16962441415460108 train_accuracy: 0.93315 test_loss: 0.35357684038217413 test_accuracy: 0.8797\n",
      "Iteraions 693: train_loss: 0.1689564720354929 train_accuracy: 0.9336166666666667 test_loss: 0.3516451644257686 test_accuracy: 0.8801\n",
      "Iteraions 694: train_loss: 0.16715159542017416 train_accuracy: 0.9330166666666667 test_loss: 0.35259900938281974 test_accuracy: 0.8806\n",
      "Iteraions 695: train_loss: 0.1678695978189888 train_accuracy: 0.93365 test_loss: 0.343416531544658 test_accuracy: 0.8787\n",
      "Iteraions 696: train_loss: 0.1683235381063403 train_accuracy: 0.9341833333333334 test_loss: 0.3506554786673892 test_accuracy: 0.8818\n",
      "Iteraions 697: train_loss: 0.1691886703264435 train_accuracy: 0.9330333333333334 test_loss: 0.35264821643264277 test_accuracy: 0.8774\n",
      "Iteraions 698: train_loss: 0.16803999357211566 train_accuracy: 0.9331833333333334 test_loss: 0.3519733897802423 test_accuracy: 0.8798\n",
      "Iteraions 699: train_loss: 0.16715382656447683 train_accuracy: 0.9341 test_loss: 0.35374418505999194 test_accuracy: 0.8771\n",
      "Iteraions 700: train_loss: 0.16732117808161365 train_accuracy: 0.9343 test_loss: 0.35056534403983125 test_accuracy: 0.8769\n",
      "Iteraions 701: train_loss: 0.16676896350611792 train_accuracy: 0.9340833333333334 test_loss: 0.34818067286697096 test_accuracy: 0.879\n",
      "Iteraions 702: train_loss: 0.16751868695287736 train_accuracy: 0.9336333333333333 test_loss: 0.34665872935306463 test_accuracy: 0.8813\n",
      "Iteraions 703: train_loss: 0.16632623065463437 train_accuracy: 0.9343166666666667 test_loss: 0.34945203953579373 test_accuracy: 0.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 704: train_loss: 0.1670182641471816 train_accuracy: 0.9349 test_loss: 0.3578750352800142 test_accuracy: 0.8774\n",
      "Iteraions 705: train_loss: 0.1663402231418902 train_accuracy: 0.9347333333333333 test_loss: 0.35064656267751343 test_accuracy: 0.8769\n",
      "Iteraions 706: train_loss: 0.1651671758448214 train_accuracy: 0.9348 test_loss: 0.34146191464949915 test_accuracy: 0.8848\n",
      "Iteraions 707: train_loss: 0.16618144803301244 train_accuracy: 0.9344333333333333 test_loss: 0.3467682147942472 test_accuracy: 0.883\n",
      "Iteraions 708: train_loss: 0.16412203090840602 train_accuracy: 0.9350666666666667 test_loss: 0.3452186638906368 test_accuracy: 0.8801\n",
      "Iteraions 709: train_loss: 0.16616959052392202 train_accuracy: 0.9350666666666667 test_loss: 0.3579610207710083 test_accuracy: 0.8751\n",
      "Iteraions 710: train_loss: 0.16497350378623804 train_accuracy: 0.9340166666666667 test_loss: 0.3502358200624657 test_accuracy: 0.8808\n",
      "Iteraions 711: train_loss: 0.16486009277843247 train_accuracy: 0.9351666666666667 test_loss: 0.3454705818432179 test_accuracy: 0.8811\n",
      "Iteraions 712: train_loss: 0.16414928307226082 train_accuracy: 0.9341 test_loss: 0.35460155257898635 test_accuracy: 0.8779\n",
      "Iteraions 713: train_loss: 0.16415112743598953 train_accuracy: 0.9353166666666667 test_loss: 0.3486030689144468 test_accuracy: 0.8783\n",
      "Iteraions 714: train_loss: 0.1633822820641864 train_accuracy: 0.9355333333333333 test_loss: 0.3503926446958644 test_accuracy: 0.8783\n",
      "Iteraions 715: train_loss: 0.16405214646130353 train_accuracy: 0.9357 test_loss: 0.35210116099708794 test_accuracy: 0.8763\n",
      "Iteraions 716: train_loss: 0.1641501081365419 train_accuracy: 0.9340166666666667 test_loss: 0.348687560395677 test_accuracy: 0.8809\n",
      "Iteraions 717: train_loss: 0.1637711063100644 train_accuracy: 0.9357166666666666 test_loss: 0.34634618549439594 test_accuracy: 0.8814\n",
      "Iteraions 718: train_loss: 0.16249218892708706 train_accuracy: 0.9365333333333333 test_loss: 0.35350556131854144 test_accuracy: 0.8789\n",
      "Iteraions 719: train_loss: 0.1625301828873417 train_accuracy: 0.93605 test_loss: 0.34791393739807497 test_accuracy: 0.8833\n",
      "Iteraions 720: train_loss: 0.16136423913783715 train_accuracy: 0.93645 test_loss: 0.34480447957247806 test_accuracy: 0.8804\n",
      "Iteraions 721: train_loss: 0.1642733992491085 train_accuracy: 0.9355833333333333 test_loss: 0.3483407595440315 test_accuracy: 0.8793\n",
      "Iteraions 722: train_loss: 0.1611155379583742 train_accuracy: 0.9370833333333334 test_loss: 0.3506061225261099 test_accuracy: 0.8799\n",
      "Iteraions 723: train_loss: 0.15998594149785803 train_accuracy: 0.9368666666666666 test_loss: 0.35396158375811576 test_accuracy: 0.8768\n",
      "Iteraions 724: train_loss: 0.16304378160249713 train_accuracy: 0.9359666666666666 test_loss: 0.3459674924070151 test_accuracy: 0.884\n",
      "Iteraions 725: train_loss: 0.16055381350189982 train_accuracy: 0.9368166666666666 test_loss: 0.3535606709032966 test_accuracy: 0.8768\n",
      "Iteraions 726: train_loss: 0.16071972473697818 train_accuracy: 0.9364666666666667 test_loss: 0.34451091650449966 test_accuracy: 0.8802\n",
      "Iteraions 727: train_loss: 0.16227576618319176 train_accuracy: 0.93555 test_loss: 0.3520345345304748 test_accuracy: 0.8766\n",
      "Iteraions 728: train_loss: 0.1609305916043805 train_accuracy: 0.9358333333333333 test_loss: 0.35109490189812514 test_accuracy: 0.8782\n",
      "Iteraions 729: train_loss: 0.1618666533195843 train_accuracy: 0.9365166666666667 test_loss: 0.35226336686589005 test_accuracy: 0.8812\n",
      "Iteraions 730: train_loss: 0.16064132956186616 train_accuracy: 0.9369333333333333 test_loss: 0.3513664849035324 test_accuracy: 0.8801\n",
      "Iteraions 731: train_loss: 0.1613130951565809 train_accuracy: 0.9356666666666666 test_loss: 0.3555158921406096 test_accuracy: 0.882\n",
      "Iteraions 732: train_loss: 0.16082398380664734 train_accuracy: 0.93755 test_loss: 0.3555290695497042 test_accuracy: 0.8788\n",
      "Iteraions 733: train_loss: 0.1625932354653502 train_accuracy: 0.9353833333333333 test_loss: 0.3553014286235842 test_accuracy: 0.8791\n",
      "Iteraions 734: train_loss: 0.16282954752821382 train_accuracy: 0.9353333333333333 test_loss: 0.35433308782109285 test_accuracy: 0.8785\n",
      "Iteraions 735: train_loss: 0.16305176920256087 train_accuracy: 0.9357333333333333 test_loss: 0.34569193747754745 test_accuracy: 0.8801\n",
      "Iteraions 736: train_loss: 0.16213912230989908 train_accuracy: 0.9357 test_loss: 0.35036926946357 test_accuracy: 0.8784\n",
      "Iteraions 737: train_loss: 0.16220929504282736 train_accuracy: 0.93555 test_loss: 0.35574095188205046 test_accuracy: 0.8794\n",
      "Iteraions 738: train_loss: 0.15833543049827126 train_accuracy: 0.93795 test_loss: 0.3575122596266765 test_accuracy: 0.8798\n",
      "Iteraions 739: train_loss: 0.15817725361354132 train_accuracy: 0.9371166666666667 test_loss: 0.3558688779264546 test_accuracy: 0.8773\n",
      "Iteraions 740: train_loss: 0.16005682097584645 train_accuracy: 0.9369 test_loss: 0.3509067837938026 test_accuracy: 0.8801\n",
      "Iteraions 741: train_loss: 0.16118811558698298 train_accuracy: 0.9379 test_loss: 0.357683642774806 test_accuracy: 0.878\n",
      "Iteraions 742: train_loss: 0.15767887350478946 train_accuracy: 0.9377166666666666 test_loss: 0.3542485471932732 test_accuracy: 0.8792\n",
      "Iteraions 743: train_loss: 0.15835500984984524 train_accuracy: 0.9379166666666666 test_loss: 0.35081318874266654 test_accuracy: 0.8801\n",
      "Iteraions 744: train_loss: 0.15764554119377105 train_accuracy: 0.9384333333333333 test_loss: 0.3518368811177268 test_accuracy: 0.8822\n",
      "Iteraions 745: train_loss: 0.15764192186385256 train_accuracy: 0.9384166666666667 test_loss: 0.3513878710581621 test_accuracy: 0.8826\n",
      "Iteraions 746: train_loss: 0.1579518166767058 train_accuracy: 0.93865 test_loss: 0.3447590676456495 test_accuracy: 0.8818\n",
      "Iteraions 747: train_loss: 0.15639689327831627 train_accuracy: 0.9387833333333333 test_loss: 0.35613862518213446 test_accuracy: 0.8799\n",
      "Iteraions 748: train_loss: 0.15613916203577616 train_accuracy: 0.93845 test_loss: 0.36172300361487403 test_accuracy: 0.8789\n",
      "Iteraions 749: train_loss: 0.15640210342004032 train_accuracy: 0.93775 test_loss: 0.35384792710702606 test_accuracy: 0.8801\n",
      "Iteraions 750: train_loss: 0.15674992692160009 train_accuracy: 0.9386 test_loss: 0.3537680194869817 test_accuracy: 0.8786\n",
      "Iteraions 751: train_loss: 0.15569427172727393 train_accuracy: 0.93885 test_loss: 0.35395675884874783 test_accuracy: 0.8795\n",
      "Iteraions 752: train_loss: 0.15594342630319413 train_accuracy: 0.9393333333333334 test_loss: 0.3591837061963831 test_accuracy: 0.8786\n",
      "Iteraions 753: train_loss: 0.15651205939127683 train_accuracy: 0.93855 test_loss: 0.35552707886450974 test_accuracy: 0.8824\n",
      "Iteraions 754: train_loss: 0.15596785583920125 train_accuracy: 0.9393666666666667 test_loss: 0.3563789780930907 test_accuracy: 0.8803\n",
      "Iteraions 755: train_loss: 0.1557853965075512 train_accuracy: 0.939 test_loss: 0.3529405753065224 test_accuracy: 0.8782\n",
      "Iteraions 756: train_loss: 0.15458058619042198 train_accuracy: 0.9393333333333334 test_loss: 0.3537579402362832 test_accuracy: 0.8798\n",
      "Iteraions 757: train_loss: 0.1557534189338346 train_accuracy: 0.9390333333333334 test_loss: 0.3522606722102427 test_accuracy: 0.8799\n",
      "Iteraions 758: train_loss: 0.15439862251178468 train_accuracy: 0.93905 test_loss: 0.36251384628491906 test_accuracy: 0.8809\n",
      "Iteraions 759: train_loss: 0.1539234796035616 train_accuracy: 0.9397833333333333 test_loss: 0.35356393984522094 test_accuracy: 0.8774\n",
      "Iteraions 760: train_loss: 0.15417910734116072 train_accuracy: 0.9398833333333333 test_loss: 0.3576992922331928 test_accuracy: 0.8774\n",
      "Iteraions 761: train_loss: 0.1531689102974673 train_accuracy: 0.9401166666666667 test_loss: 0.35004328873755075 test_accuracy: 0.8809\n",
      "Iteraions 762: train_loss: 0.1535974689540671 train_accuracy: 0.9386833333333333 test_loss: 0.3603409005317401 test_accuracy: 0.8785\n",
      "Iteraions 763: train_loss: 0.15335282126301275 train_accuracy: 0.9404 test_loss: 0.3565911158595735 test_accuracy: 0.881\n",
      "Iteraions 764: train_loss: 0.15345730134189872 train_accuracy: 0.93975 test_loss: 0.3458244454554243 test_accuracy: 0.8816\n",
      "Iteraions 765: train_loss: 0.15172098808756054 train_accuracy: 0.9400666666666667 test_loss: 0.3623136405289507 test_accuracy: 0.8757\n",
      "Iteraions 766: train_loss: 0.15519312970220647 train_accuracy: 0.9398333333333333 test_loss: 0.35931221959986687 test_accuracy: 0.8782\n",
      "Iteraions 767: train_loss: 0.15463069725056364 train_accuracy: 0.9394666666666667 test_loss: 0.3624811079547568 test_accuracy: 0.8808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 768: train_loss: 0.15530742558215854 train_accuracy: 0.9393666666666667 test_loss: 0.3626921570451605 test_accuracy: 0.8781\n",
      "Iteraions 769: train_loss: 0.15463385873330554 train_accuracy: 0.9394166666666667 test_loss: 0.35882444160913546 test_accuracy: 0.8799\n",
      "Iteraions 770: train_loss: 0.15271008091974703 train_accuracy: 0.9402666666666667 test_loss: 0.36442091555819933 test_accuracy: 0.881\n",
      "Iteraions 771: train_loss: 0.15312234282630227 train_accuracy: 0.9403166666666667 test_loss: 0.3609434444835879 test_accuracy: 0.8816\n",
      "Iteraions 772: train_loss: 0.15225889478548857 train_accuracy: 0.93955 test_loss: 0.35453960790421707 test_accuracy: 0.88\n",
      "Iteraions 773: train_loss: 0.15217947253512606 train_accuracy: 0.9396 test_loss: 0.35947788837735134 test_accuracy: 0.8783\n",
      "Iteraions 774: train_loss: 0.1537979371608447 train_accuracy: 0.9382166666666667 test_loss: 0.35656212223809086 test_accuracy: 0.8819\n",
      "Iteraions 775: train_loss: 0.1538244909243221 train_accuracy: 0.9396 test_loss: 0.36076421665412417 test_accuracy: 0.877\n",
      "Iteraions 776: train_loss: 0.156615772758277 train_accuracy: 0.9376333333333333 test_loss: 0.36383733187345246 test_accuracy: 0.8778\n",
      "Iteraions 777: train_loss: 0.1539381870507019 train_accuracy: 0.9396833333333333 test_loss: 0.36398497219890924 test_accuracy: 0.8778\n",
      "Iteraions 778: train_loss: 0.1531823562125229 train_accuracy: 0.94035 test_loss: 0.3590900426349559 test_accuracy: 0.8804\n",
      "Iteraions 779: train_loss: 0.15027827670198568 train_accuracy: 0.94145 test_loss: 0.35253424565753433 test_accuracy: 0.8829\n",
      "Iteraions 780: train_loss: 0.1516319055457954 train_accuracy: 0.9408666666666666 test_loss: 0.3625944532701386 test_accuracy: 0.8772\n",
      "Iteraions 781: train_loss: 0.1529395496288881 train_accuracy: 0.9395833333333333 test_loss: 0.3539544778642797 test_accuracy: 0.8849\n",
      "Iteraions 782: train_loss: 0.1554270191400108 train_accuracy: 0.9385833333333333 test_loss: 0.36071721567681037 test_accuracy: 0.8783\n",
      "Iteraions 783: train_loss: 0.15231987775456943 train_accuracy: 0.9397166666666666 test_loss: 0.3564069458410638 test_accuracy: 0.878\n",
      "Iteraions 784: train_loss: 0.14947748957487603 train_accuracy: 0.94155 test_loss: 0.35470195276126043 test_accuracy: 0.8804\n",
      "Iteraions 785: train_loss: 0.14885339425245173 train_accuracy: 0.9427 test_loss: 0.3585735226310752 test_accuracy: 0.8781\n",
      "Iteraions 786: train_loss: 0.15128766339761868 train_accuracy: 0.9398333333333333 test_loss: 0.36266566854109683 test_accuracy: 0.8796\n",
      "Iteraions 787: train_loss: 0.15367507796028185 train_accuracy: 0.9398333333333333 test_loss: 0.36701218161711074 test_accuracy: 0.8771\n",
      "Iteraions 788: train_loss: 0.15158974114124932 train_accuracy: 0.9410333333333334 test_loss: 0.37080076082732966 test_accuracy: 0.8794\n",
      "Iteraions 789: train_loss: 0.15085138312798888 train_accuracy: 0.9409 test_loss: 0.3622806297906236 test_accuracy: 0.8795\n",
      "Iteraions 790: train_loss: 0.14905633700573184 train_accuracy: 0.9414666666666667 test_loss: 0.3554231876251377 test_accuracy: 0.8791\n",
      "Iteraions 791: train_loss: 0.14691520614476086 train_accuracy: 0.9424333333333333 test_loss: 0.35210899576590093 test_accuracy: 0.8807\n",
      "Iteraions 792: train_loss: 0.15046905989507608 train_accuracy: 0.9408 test_loss: 0.36420646309410276 test_accuracy: 0.8789\n",
      "Iteraions 793: train_loss: 0.15151474302663065 train_accuracy: 0.9389333333333333 test_loss: 0.3633273367880994 test_accuracy: 0.8784\n",
      "Iteraions 794: train_loss: 0.15050148516764947 train_accuracy: 0.9412666666666667 test_loss: 0.3631043516019501 test_accuracy: 0.879\n",
      "Iteraions 795: train_loss: 0.14770844648424405 train_accuracy: 0.9418166666666666 test_loss: 0.35762055183685687 test_accuracy: 0.8805\n",
      "Iteraions 796: train_loss: 0.15005723014038228 train_accuracy: 0.9407166666666666 test_loss: 0.3639650753422761 test_accuracy: 0.8804\n",
      "Iteraions 797: train_loss: 0.14778400184437396 train_accuracy: 0.9427666666666666 test_loss: 0.35925324494679606 test_accuracy: 0.8805\n",
      "Iteraions 798: train_loss: 0.14946797434265321 train_accuracy: 0.94195 test_loss: 0.36074208018542614 test_accuracy: 0.8814\n",
      "Iteraions 799: train_loss: 0.14775961948471983 train_accuracy: 0.9420666666666667 test_loss: 0.35903753789519166 test_accuracy: 0.8832\n",
      "Iteraions 800: train_loss: 0.1493620636479364 train_accuracy: 0.94155 test_loss: 0.36753988943215976 test_accuracy: 0.8804\n",
      "Iteraions 801: train_loss: 0.14794998708431262 train_accuracy: 0.94235 test_loss: 0.363052796151428 test_accuracy: 0.8804\n",
      "Iteraions 802: train_loss: 0.14795627556736315 train_accuracy: 0.9428333333333333 test_loss: 0.35580398926345763 test_accuracy: 0.8799\n",
      "Iteraions 803: train_loss: 0.14740785167391782 train_accuracy: 0.9422333333333334 test_loss: 0.36672769541818145 test_accuracy: 0.8799\n",
      "Iteraions 804: train_loss: 0.14405919057476446 train_accuracy: 0.9438333333333333 test_loss: 0.35929276661803256 test_accuracy: 0.8805\n",
      "Iteraions 805: train_loss: 0.144707666435147 train_accuracy: 0.9431833333333334 test_loss: 0.3607814542474978 test_accuracy: 0.8808\n",
      "Iteraions 806: train_loss: 0.1464091962732394 train_accuracy: 0.9429166666666666 test_loss: 0.35991473396902673 test_accuracy: 0.8799\n",
      "Iteraions 807: train_loss: 0.14565173724434527 train_accuracy: 0.94405 test_loss: 0.3619054691610859 test_accuracy: 0.8827\n",
      "Iteraions 808: train_loss: 0.14642171261964565 train_accuracy: 0.943 test_loss: 0.36638313321844096 test_accuracy: 0.8806\n",
      "Iteraions 809: train_loss: 0.14775987953647177 train_accuracy: 0.9436166666666667 test_loss: 0.35837343070497396 test_accuracy: 0.8816\n",
      "Iteraions 810: train_loss: 0.14562095351765753 train_accuracy: 0.9433833333333334 test_loss: 0.36374631437051475 test_accuracy: 0.8781\n",
      "Iteraions 811: train_loss: 0.14572745175893292 train_accuracy: 0.9432666666666667 test_loss: 0.3696790404685396 test_accuracy: 0.8766\n",
      "Iteraions 812: train_loss: 0.1451670274971427 train_accuracy: 0.9432833333333334 test_loss: 0.3570951349507551 test_accuracy: 0.8819\n",
      "Iteraions 813: train_loss: 0.14459693839234977 train_accuracy: 0.9433333333333334 test_loss: 0.36361455645742774 test_accuracy: 0.8779\n",
      "Iteraions 814: train_loss: 0.14648025369819967 train_accuracy: 0.9420833333333334 test_loss: 0.36348869882146584 test_accuracy: 0.8832\n",
      "Iteraions 815: train_loss: 0.14546797263455227 train_accuracy: 0.94375 test_loss: 0.36770560837605176 test_accuracy: 0.877\n",
      "Iteraions 816: train_loss: 0.1446724737231031 train_accuracy: 0.9439833333333333 test_loss: 0.36733110995254603 test_accuracy: 0.8773\n",
      "Iteraions 817: train_loss: 0.1435741633172231 train_accuracy: 0.94435 test_loss: 0.36861352326575764 test_accuracy: 0.8829\n",
      "Iteraions 818: train_loss: 0.1440493822174679 train_accuracy: 0.9450666666666667 test_loss: 0.35999455301182515 test_accuracy: 0.8812\n",
      "Iteraions 819: train_loss: 0.14317393841999476 train_accuracy: 0.9447666666666666 test_loss: 0.3569307718640629 test_accuracy: 0.882\n",
      "Iteraions 820: train_loss: 0.14366525168410316 train_accuracy: 0.9441333333333334 test_loss: 0.35998401030727845 test_accuracy: 0.8806\n",
      "Iteraions 821: train_loss: 0.1449475638871298 train_accuracy: 0.9434833333333333 test_loss: 0.365370849803178 test_accuracy: 0.8758\n",
      "Iteraions 822: train_loss: 0.14431776159972293 train_accuracy: 0.9431 test_loss: 0.36638546762793833 test_accuracy: 0.8807\n",
      "Iteraions 823: train_loss: 0.1451835482749774 train_accuracy: 0.94365 test_loss: 0.37143672412659395 test_accuracy: 0.8795\n",
      "Iteraions 824: train_loss: 0.1445084773844581 train_accuracy: 0.9432 test_loss: 0.36279543980905565 test_accuracy: 0.8813\n",
      "Iteraions 825: train_loss: 0.14138792722541288 train_accuracy: 0.9450333333333333 test_loss: 0.3673361475385399 test_accuracy: 0.8794\n",
      "Iteraions 826: train_loss: 0.14361361926905042 train_accuracy: 0.9444333333333333 test_loss: 0.36620948998447145 test_accuracy: 0.8791\n",
      "Iteraions 827: train_loss: 0.14232989080475122 train_accuracy: 0.9445333333333333 test_loss: 0.3675366225529695 test_accuracy: 0.8792\n",
      "Iteraions 828: train_loss: 0.14190416445062554 train_accuracy: 0.94485 test_loss: 0.35913860857117125 test_accuracy: 0.8825\n",
      "Iteraions 829: train_loss: 0.14224890263669362 train_accuracy: 0.94435 test_loss: 0.3591348805568314 test_accuracy: 0.8815\n",
      "Iteraions 830: train_loss: 0.142612163714635 train_accuracy: 0.9451666666666667 test_loss: 0.3584018928353199 test_accuracy: 0.884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 831: train_loss: 0.14165125980712462 train_accuracy: 0.9445666666666667 test_loss: 0.3633644900301137 test_accuracy: 0.8852\n",
      "Iteraions 832: train_loss: 0.14048370509551933 train_accuracy: 0.9444833333333333 test_loss: 0.3675522484088877 test_accuracy: 0.8824\n",
      "Iteraions 833: train_loss: 0.14180069491025055 train_accuracy: 0.9450833333333334 test_loss: 0.36979198785335204 test_accuracy: 0.8782\n",
      "Iteraions 834: train_loss: 0.1421609102771412 train_accuracy: 0.9450333333333333 test_loss: 0.36738259985811145 test_accuracy: 0.8802\n",
      "Iteraions 835: train_loss: 0.1415514159018867 train_accuracy: 0.9441166666666667 test_loss: 0.3713757193475274 test_accuracy: 0.8809\n",
      "Iteraions 836: train_loss: 0.14295980605098604 train_accuracy: 0.9443166666666667 test_loss: 0.3639841891831118 test_accuracy: 0.8828\n",
      "Iteraions 837: train_loss: 0.140436367526985 train_accuracy: 0.9442333333333334 test_loss: 0.3690094769769479 test_accuracy: 0.8817\n",
      "Iteraions 838: train_loss: 0.14267175987250674 train_accuracy: 0.9445 test_loss: 0.36820474681866877 test_accuracy: 0.8812\n",
      "Iteraions 839: train_loss: 0.14086334372574935 train_accuracy: 0.9456 test_loss: 0.3677385061929573 test_accuracy: 0.8804\n",
      "Iteraions 840: train_loss: 0.14001687409750818 train_accuracy: 0.9459166666666666 test_loss: 0.36223919618222183 test_accuracy: 0.8791\n",
      "Iteraions 841: train_loss: 0.14047163885476802 train_accuracy: 0.9456 test_loss: 0.3626050812031182 test_accuracy: 0.8803\n",
      "Iteraions 842: train_loss: 0.13998309811263776 train_accuracy: 0.9454333333333333 test_loss: 0.3649118150164945 test_accuracy: 0.8795\n",
      "Iteraions 843: train_loss: 0.1393636664782846 train_accuracy: 0.9468166666666666 test_loss: 0.3716342304817389 test_accuracy: 0.8796\n",
      "Iteraions 844: train_loss: 0.13913470681458723 train_accuracy: 0.9461 test_loss: 0.3711591802402521 test_accuracy: 0.8815\n",
      "Iteraions 845: train_loss: 0.14064537202632146 train_accuracy: 0.9450166666666666 test_loss: 0.37207898156079167 test_accuracy: 0.8797\n",
      "Iteraions 846: train_loss: 0.13998228005241034 train_accuracy: 0.9453833333333334 test_loss: 0.35972858916520245 test_accuracy: 0.8826\n",
      "Iteraions 847: train_loss: 0.14142572977094092 train_accuracy: 0.9447333333333333 test_loss: 0.3682077901512504 test_accuracy: 0.8826\n",
      "Iteraions 848: train_loss: 0.13937201628318938 train_accuracy: 0.9457666666666666 test_loss: 0.373089292241713 test_accuracy: 0.8784\n",
      "Iteraions 849: train_loss: 0.13914024234506514 train_accuracy: 0.9456833333333333 test_loss: 0.36773704042401956 test_accuracy: 0.8801\n",
      "Iteraions 850: train_loss: 0.1402351540820779 train_accuracy: 0.9446 test_loss: 0.3733667141462734 test_accuracy: 0.8784\n",
      "Iteraions 851: train_loss: 0.13901944121476292 train_accuracy: 0.9464 test_loss: 0.36006516027020724 test_accuracy: 0.8813\n",
      "Iteraions 852: train_loss: 0.13959495965192167 train_accuracy: 0.9453166666666667 test_loss: 0.3777457378990481 test_accuracy: 0.8793\n",
      "Iteraions 853: train_loss: 0.1399073968752334 train_accuracy: 0.9455333333333333 test_loss: 0.3640668279922064 test_accuracy: 0.8838\n",
      "Iteraions 854: train_loss: 0.13839866020636615 train_accuracy: 0.9472166666666667 test_loss: 0.36749128425745314 test_accuracy: 0.8813\n",
      "Iteraions 855: train_loss: 0.13750244711119777 train_accuracy: 0.9464166666666667 test_loss: 0.3635708089243315 test_accuracy: 0.8846\n",
      "Iteraions 856: train_loss: 0.13651384542963715 train_accuracy: 0.9479 test_loss: 0.3662570912058072 test_accuracy: 0.8808\n",
      "Iteraions 857: train_loss: 0.1353974485881346 train_accuracy: 0.9476833333333333 test_loss: 0.36426695309393897 test_accuracy: 0.8818\n",
      "Iteraions 858: train_loss: 0.13825762226622842 train_accuracy: 0.94615 test_loss: 0.3718855500566767 test_accuracy: 0.8824\n",
      "Iteraions 859: train_loss: 0.13855163429805864 train_accuracy: 0.9467666666666666 test_loss: 0.3727207212821683 test_accuracy: 0.8799\n",
      "Iteraions 860: train_loss: 0.13958710458056253 train_accuracy: 0.9454833333333333 test_loss: 0.3676591898230681 test_accuracy: 0.8814\n",
      "Iteraions 861: train_loss: 0.14105285417733107 train_accuracy: 0.9459 test_loss: 0.370412072890983 test_accuracy: 0.8807\n",
      "Iteraions 862: train_loss: 0.13817483729197144 train_accuracy: 0.9463833333333334 test_loss: 0.36190831872874735 test_accuracy: 0.8797\n",
      "Iteraions 863: train_loss: 0.1372619737208805 train_accuracy: 0.9475833333333333 test_loss: 0.3690509851613974 test_accuracy: 0.8795\n",
      "Iteraions 864: train_loss: 0.1350174642956397 train_accuracy: 0.9482666666666667 test_loss: 0.3667777754778332 test_accuracy: 0.8817\n",
      "Iteraions 865: train_loss: 0.13612536649067658 train_accuracy: 0.9473333333333334 test_loss: 0.36489326612073947 test_accuracy: 0.879\n",
      "Iteraions 866: train_loss: 0.13902506204615933 train_accuracy: 0.94675 test_loss: 0.37319366201349674 test_accuracy: 0.8778\n",
      "Iteraions 867: train_loss: 0.1369575177218446 train_accuracy: 0.9477666666666666 test_loss: 0.3710212615876193 test_accuracy: 0.8818\n",
      "Iteraions 868: train_loss: 0.13548571050352373 train_accuracy: 0.9466333333333333 test_loss: 0.37423173820321665 test_accuracy: 0.8822\n",
      "Iteraions 869: train_loss: 0.13402932251121377 train_accuracy: 0.9483833333333334 test_loss: 0.3741636011479523 test_accuracy: 0.878\n",
      "Iteraions 870: train_loss: 0.13571839100664107 train_accuracy: 0.94725 test_loss: 0.373341908610532 test_accuracy: 0.8809\n",
      "Iteraions 871: train_loss: 0.1366324326171728 train_accuracy: 0.9463 test_loss: 0.38305986496526784 test_accuracy: 0.8784\n",
      "Iteraions 872: train_loss: 0.13817731332213268 train_accuracy: 0.9460666666666666 test_loss: 0.3742284341209484 test_accuracy: 0.8806\n",
      "Iteraions 873: train_loss: 0.1376286159850871 train_accuracy: 0.9461666666666667 test_loss: 0.3736588996168882 test_accuracy: 0.8796\n",
      "Iteraions 874: train_loss: 0.13937164981367506 train_accuracy: 0.94565 test_loss: 0.37468822272317465 test_accuracy: 0.8786\n",
      "Iteraions 875: train_loss: 0.1384419990371963 train_accuracy: 0.9456666666666667 test_loss: 0.3772480751918449 test_accuracy: 0.8822\n",
      "Iteraions 876: train_loss: 0.1366925489187825 train_accuracy: 0.9474833333333333 test_loss: 0.37570563204336976 test_accuracy: 0.8811\n",
      "Iteraions 877: train_loss: 0.13654562535418735 train_accuracy: 0.9468 test_loss: 0.37371075010119037 test_accuracy: 0.8814\n",
      "Iteraions 878: train_loss: 0.13443058282007886 train_accuracy: 0.9483833333333334 test_loss: 0.371451095960912 test_accuracy: 0.8817\n",
      "Iteraions 879: train_loss: 0.13483740687062534 train_accuracy: 0.9491666666666667 test_loss: 0.37657065134512097 test_accuracy: 0.879\n",
      "Iteraions 880: train_loss: 0.1368426575467951 train_accuracy: 0.9460166666666666 test_loss: 0.3792211999799169 test_accuracy: 0.8776\n",
      "Iteraions 881: train_loss: 0.1329078977493822 train_accuracy: 0.9482333333333334 test_loss: 0.37354685398057275 test_accuracy: 0.8805\n",
      "Iteraions 882: train_loss: 0.13470234062579783 train_accuracy: 0.94795 test_loss: 0.36741782759945707 test_accuracy: 0.8807\n",
      "Iteraions 883: train_loss: 0.1343412067906357 train_accuracy: 0.9477333333333333 test_loss: 0.3719417545147503 test_accuracy: 0.8807\n",
      "Iteraions 884: train_loss: 0.13482531330208655 train_accuracy: 0.9475333333333333 test_loss: 0.37186102566169094 test_accuracy: 0.8802\n",
      "Iteraions 885: train_loss: 0.13398982765075132 train_accuracy: 0.9489 test_loss: 0.3755880148209398 test_accuracy: 0.8806\n",
      "Iteraions 886: train_loss: 0.1330788528847963 train_accuracy: 0.9476666666666667 test_loss: 0.37084593888575546 test_accuracy: 0.8825\n",
      "Iteraions 887: train_loss: 0.133460000486373 train_accuracy: 0.9483 test_loss: 0.37234464408794604 test_accuracy: 0.8821\n",
      "Iteraions 888: train_loss: 0.13120415047074602 train_accuracy: 0.95005 test_loss: 0.36914523212505823 test_accuracy: 0.8842\n",
      "Iteraions 889: train_loss: 0.13250095391938913 train_accuracy: 0.9489833333333333 test_loss: 0.37195350162563645 test_accuracy: 0.8806\n",
      "Iteraions 890: train_loss: 0.13402476566257682 train_accuracy: 0.9474833333333333 test_loss: 0.3732187722284566 test_accuracy: 0.8805\n",
      "Iteraions 891: train_loss: 0.1304999312569788 train_accuracy: 0.94905 test_loss: 0.3754584714320662 test_accuracy: 0.8826\n",
      "Iteraions 892: train_loss: 0.1309280377660875 train_accuracy: 0.9495166666666667 test_loss: 0.37629749800117507 test_accuracy: 0.8795\n",
      "Iteraions 893: train_loss: 0.13212659084625958 train_accuracy: 0.9484166666666667 test_loss: 0.3761163675629897 test_accuracy: 0.8789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 894: train_loss: 0.1323419403814531 train_accuracy: 0.94905 test_loss: 0.3756460791762395 test_accuracy: 0.8798\n",
      "Iteraions 895: train_loss: 0.13045814676326695 train_accuracy: 0.9498 test_loss: 0.37090022414004126 test_accuracy: 0.883\n",
      "Iteraions 896: train_loss: 0.1312765220349935 train_accuracy: 0.9489666666666666 test_loss: 0.3792936580157231 test_accuracy: 0.8819\n",
      "Iteraions 897: train_loss: 0.1303060377684682 train_accuracy: 0.9495333333333333 test_loss: 0.37396932357260004 test_accuracy: 0.8813\n",
      "Iteraions 898: train_loss: 0.13137334235915948 train_accuracy: 0.9495166666666667 test_loss: 0.376645405207197 test_accuracy: 0.8797\n",
      "Iteraions 899: train_loss: 0.12873807307483498 train_accuracy: 0.9504 test_loss: 0.37631701262024797 test_accuracy: 0.8819\n",
      "Iteraions 900: train_loss: 0.12953336555985787 train_accuracy: 0.9511 test_loss: 0.3761216761416508 test_accuracy: 0.8839\n",
      "Iteraions 901: train_loss: 0.12955920473638352 train_accuracy: 0.9494166666666667 test_loss: 0.3704777720521735 test_accuracy: 0.8832\n",
      "Iteraions 902: train_loss: 0.12973381881502724 train_accuracy: 0.9490333333333333 test_loss: 0.37335894418843873 test_accuracy: 0.8809\n",
      "Iteraions 903: train_loss: 0.12907549337908433 train_accuracy: 0.95045 test_loss: 0.371440694171797 test_accuracy: 0.8811\n",
      "Iteraions 904: train_loss: 0.13067773832157112 train_accuracy: 0.9499333333333333 test_loss: 0.37935924002043436 test_accuracy: 0.88\n",
      "Iteraions 905: train_loss: 0.13032037289581275 train_accuracy: 0.9504166666666667 test_loss: 0.37655911323973984 test_accuracy: 0.8824\n",
      "Iteraions 906: train_loss: 0.1283787714463843 train_accuracy: 0.9500166666666666 test_loss: 0.37898240164886676 test_accuracy: 0.8816\n",
      "Iteraions 907: train_loss: 0.12866040297214879 train_accuracy: 0.9505333333333333 test_loss: 0.37655225304952405 test_accuracy: 0.8845\n",
      "Iteraions 908: train_loss: 0.12901161988971976 train_accuracy: 0.95035 test_loss: 0.37822957950696545 test_accuracy: 0.8796\n",
      "Iteraions 909: train_loss: 0.1301514789755909 train_accuracy: 0.94995 test_loss: 0.37926132135561835 test_accuracy: 0.8811\n",
      "Iteraions 910: train_loss: 0.13033372978083546 train_accuracy: 0.9487666666666666 test_loss: 0.3764088118168896 test_accuracy: 0.8811\n",
      "Iteraions 911: train_loss: 0.13036787627006546 train_accuracy: 0.9496333333333333 test_loss: 0.3684916567602099 test_accuracy: 0.8806\n",
      "Iteraions 912: train_loss: 0.13138159122964574 train_accuracy: 0.9492666666666667 test_loss: 0.3827907361879892 test_accuracy: 0.8799\n",
      "Iteraions 913: train_loss: 0.12815467386521243 train_accuracy: 0.95135 test_loss: 0.3774311231974571 test_accuracy: 0.8792\n",
      "Iteraions 914: train_loss: 0.12855092838880688 train_accuracy: 0.9499166666666666 test_loss: 0.3738147721354499 test_accuracy: 0.8791\n",
      "Iteraions 915: train_loss: 0.1282409530183081 train_accuracy: 0.95065 test_loss: 0.3854109539653929 test_accuracy: 0.8823\n",
      "Iteraions 916: train_loss: 0.12856105820227476 train_accuracy: 0.9516833333333333 test_loss: 0.3751225538300629 test_accuracy: 0.8821\n",
      "Iteraions 917: train_loss: 0.13046080452077993 train_accuracy: 0.9487 test_loss: 0.38164529034306915 test_accuracy: 0.8792\n",
      "Iteraions 918: train_loss: 0.13131135772033967 train_accuracy: 0.9499333333333333 test_loss: 0.38579553317127196 test_accuracy: 0.8799\n",
      "Iteraions 919: train_loss: 0.12976904319533922 train_accuracy: 0.94875 test_loss: 0.3803869355486443 test_accuracy: 0.8781\n",
      "Iteraions 920: train_loss: 0.1272698674683765 train_accuracy: 0.9502166666666667 test_loss: 0.38086269632208103 test_accuracy: 0.8819\n",
      "Iteraions 921: train_loss: 0.12824772881996865 train_accuracy: 0.9511333333333334 test_loss: 0.37601732928701365 test_accuracy: 0.8825\n",
      "Iteraions 922: train_loss: 0.12902771115651557 train_accuracy: 0.9503666666666667 test_loss: 0.37674995289007407 test_accuracy: 0.8814\n",
      "Iteraions 923: train_loss: 0.13068018889731758 train_accuracy: 0.9489666666666666 test_loss: 0.3884285385223822 test_accuracy: 0.877\n",
      "Iteraions 924: train_loss: 0.13133383081500297 train_accuracy: 0.9484833333333333 test_loss: 0.3937423581136792 test_accuracy: 0.8798\n",
      "Iteraions 925: train_loss: 0.12830611388693394 train_accuracy: 0.9509 test_loss: 0.38842239532453954 test_accuracy: 0.8761\n",
      "Iteraions 926: train_loss: 0.1270491163402541 train_accuracy: 0.9505166666666667 test_loss: 0.3769966745372319 test_accuracy: 0.8811\n",
      "Iteraions 927: train_loss: 0.12654212681176066 train_accuracy: 0.9498333333333333 test_loss: 0.36935890666141724 test_accuracy: 0.8821\n",
      "Iteraions 928: train_loss: 0.12719315698550068 train_accuracy: 0.95215 test_loss: 0.3833813486235461 test_accuracy: 0.8815\n",
      "Iteraions 929: train_loss: 0.12808771372188701 train_accuracy: 0.9507333333333333 test_loss: 0.3750758617786636 test_accuracy: 0.8792\n",
      "Iteraions 930: train_loss: 0.12529061057943142 train_accuracy: 0.9522666666666667 test_loss: 0.380719630612491 test_accuracy: 0.8822\n",
      "Iteraions 931: train_loss: 0.12484370704261791 train_accuracy: 0.9520666666666666 test_loss: 0.37557149353480784 test_accuracy: 0.8806\n",
      "Iteraions 932: train_loss: 0.12425992224739388 train_accuracy: 0.9527666666666667 test_loss: 0.38936581186927516 test_accuracy: 0.8807\n",
      "Iteraions 933: train_loss: 0.12481328146416536 train_accuracy: 0.9508833333333333 test_loss: 0.38252539458579726 test_accuracy: 0.8817\n",
      "Iteraions 934: train_loss: 0.12365298215980147 train_accuracy: 0.9530333333333333 test_loss: 0.38630098276777014 test_accuracy: 0.88\n",
      "Iteraions 935: train_loss: 0.12496915863218974 train_accuracy: 0.9513 test_loss: 0.37766211724061394 test_accuracy: 0.8824\n",
      "Iteraions 936: train_loss: 0.12550348840230094 train_accuracy: 0.9522 test_loss: 0.3797734274120548 test_accuracy: 0.8826\n",
      "Iteraions 937: train_loss: 0.12393396690823108 train_accuracy: 0.95185 test_loss: 0.3761330136289019 test_accuracy: 0.8807\n",
      "Iteraions 938: train_loss: 0.12391725974879166 train_accuracy: 0.9519666666666666 test_loss: 0.3781633190150893 test_accuracy: 0.8783\n",
      "Iteraions 939: train_loss: 0.12576114490352253 train_accuracy: 0.9514833333333333 test_loss: 0.379045436416716 test_accuracy: 0.8797\n",
      "Iteraions 940: train_loss: 0.1242134724870841 train_accuracy: 0.9530333333333333 test_loss: 0.37382400123859505 test_accuracy: 0.8843\n",
      "Iteraions 941: train_loss: 0.12314794091846631 train_accuracy: 0.9528666666666666 test_loss: 0.3804470131186911 test_accuracy: 0.8815\n",
      "Iteraions 942: train_loss: 0.1233912373606684 train_accuracy: 0.9530166666666666 test_loss: 0.3782942540015127 test_accuracy: 0.8838\n",
      "Iteraions 943: train_loss: 0.1241825380191237 train_accuracy: 0.9524 test_loss: 0.37788087095050665 test_accuracy: 0.8805\n",
      "Iteraions 944: train_loss: 0.12219485944093612 train_accuracy: 0.95315 test_loss: 0.3853112390605366 test_accuracy: 0.8823\n",
      "Iteraions 945: train_loss: 0.12481238895144928 train_accuracy: 0.9516833333333333 test_loss: 0.38133404637485063 test_accuracy: 0.8843\n",
      "Iteraions 946: train_loss: 0.12282196370270221 train_accuracy: 0.9529666666666666 test_loss: 0.3863912330801693 test_accuracy: 0.8794\n",
      "Iteraions 947: train_loss: 0.12589252653440897 train_accuracy: 0.9513833333333334 test_loss: 0.39001805300948494 test_accuracy: 0.8806\n",
      "Iteraions 948: train_loss: 0.12456836103504096 train_accuracy: 0.9516166666666667 test_loss: 0.3817056539085666 test_accuracy: 0.8787\n",
      "Iteraions 949: train_loss: 0.12354252158682937 train_accuracy: 0.95295 test_loss: 0.3825284094515032 test_accuracy: 0.8812\n",
      "Iteraions 950: train_loss: 0.12388243687950382 train_accuracy: 0.9524 test_loss: 0.37285120366285096 test_accuracy: 0.882\n",
      "Iteraions 951: train_loss: 0.12421797397045442 train_accuracy: 0.9530833333333333 test_loss: 0.3854579605503461 test_accuracy: 0.8782\n",
      "Iteraions 952: train_loss: 0.12501684626037957 train_accuracy: 0.9510833333333333 test_loss: 0.37841820994470926 test_accuracy: 0.8807\n",
      "Iteraions 953: train_loss: 0.12440443640140832 train_accuracy: 0.9526833333333333 test_loss: 0.3891491694328919 test_accuracy: 0.8768\n",
      "Iteraions 954: train_loss: 0.12228956776040471 train_accuracy: 0.95225 test_loss: 0.37564363604674533 test_accuracy: 0.8799\n",
      "Iteraions 955: train_loss: 0.11934454110644174 train_accuracy: 0.9546166666666667 test_loss: 0.38363986207443623 test_accuracy: 0.8815\n",
      "Iteraions 956: train_loss: 0.12453500368921802 train_accuracy: 0.9524833333333333 test_loss: 0.38212223688813446 test_accuracy: 0.8812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 957: train_loss: 0.12201915203237558 train_accuracy: 0.9535333333333333 test_loss: 0.3709366911844403 test_accuracy: 0.8827\n",
      "Iteraions 958: train_loss: 0.1229745909234282 train_accuracy: 0.9530166666666666 test_loss: 0.38563966816276335 test_accuracy: 0.8797\n",
      "Iteraions 959: train_loss: 0.12133601547513893 train_accuracy: 0.9536166666666667 test_loss: 0.38583437840967033 test_accuracy: 0.8792\n",
      "Iteraions 960: train_loss: 0.12192602477842977 train_accuracy: 0.95425 test_loss: 0.3892897930542278 test_accuracy: 0.8792\n",
      "Iteraions 961: train_loss: 0.12226241256722414 train_accuracy: 0.9525333333333333 test_loss: 0.38234950081582847 test_accuracy: 0.8801\n",
      "Iteraions 962: train_loss: 0.1216369906108922 train_accuracy: 0.9522833333333334 test_loss: 0.38709649697799087 test_accuracy: 0.8807\n",
      "Iteraions 963: train_loss: 0.1212310851328456 train_accuracy: 0.9533166666666667 test_loss: 0.3886582634974562 test_accuracy: 0.8806\n",
      "Iteraions 964: train_loss: 0.119574418250086 train_accuracy: 0.9540333333333333 test_loss: 0.3894467097762758 test_accuracy: 0.8825\n",
      "Iteraions 965: train_loss: 0.12037295055288148 train_accuracy: 0.9541166666666666 test_loss: 0.3874861398635279 test_accuracy: 0.8837\n",
      "Iteraions 966: train_loss: 0.11995698184362556 train_accuracy: 0.9551166666666666 test_loss: 0.38237042509867686 test_accuracy: 0.8807\n",
      "Iteraions 967: train_loss: 0.12028606891557203 train_accuracy: 0.95385 test_loss: 0.3945425625202752 test_accuracy: 0.8781\n",
      "Iteraions 968: train_loss: 0.12271129289690622 train_accuracy: 0.9536833333333333 test_loss: 0.3870980999143132 test_accuracy: 0.8805\n",
      "Iteraions 969: train_loss: 0.12356911609279334 train_accuracy: 0.9525333333333333 test_loss: 0.3835929678115999 test_accuracy: 0.8818\n",
      "Iteraions 970: train_loss: 0.12191195793208587 train_accuracy: 0.9535833333333333 test_loss: 0.38827970557205244 test_accuracy: 0.8792\n",
      "Iteraions 971: train_loss: 0.12070322335741697 train_accuracy: 0.9532666666666667 test_loss: 0.3831008205152501 test_accuracy: 0.8828\n",
      "Iteraions 972: train_loss: 0.11898424714045165 train_accuracy: 0.9546333333333333 test_loss: 0.39347057265104585 test_accuracy: 0.8781\n",
      "Iteraions 973: train_loss: 0.11901034011159213 train_accuracy: 0.9540666666666666 test_loss: 0.38729235607103096 test_accuracy: 0.8796\n",
      "Iteraions 974: train_loss: 0.11942943767449675 train_accuracy: 0.9544166666666667 test_loss: 0.3830612756481214 test_accuracy: 0.8816\n",
      "Iteraions 975: train_loss: 0.12267460805771295 train_accuracy: 0.9526833333333333 test_loss: 0.38999473285327635 test_accuracy: 0.8799\n",
      "Iteraions 976: train_loss: 0.12185923304919752 train_accuracy: 0.95335 test_loss: 0.3874441100215753 test_accuracy: 0.8797\n",
      "Iteraions 977: train_loss: 0.120805948277455 train_accuracy: 0.95315 test_loss: 0.38794892915182144 test_accuracy: 0.8824\n",
      "Iteraions 978: train_loss: 0.1191850432525636 train_accuracy: 0.9544166666666667 test_loss: 0.37780736988445257 test_accuracy: 0.8824\n",
      "Iteraions 979: train_loss: 0.11730521665665986 train_accuracy: 0.9557 test_loss: 0.3917527463668765 test_accuracy: 0.8805\n",
      "Iteraions 980: train_loss: 0.11962823008996487 train_accuracy: 0.95305 test_loss: 0.3838892773121251 test_accuracy: 0.8811\n",
      "Iteraions 981: train_loss: 0.11945021112458092 train_accuracy: 0.9544333333333334 test_loss: 0.3883442158064463 test_accuracy: 0.88\n",
      "Iteraions 982: train_loss: 0.11716985820774689 train_accuracy: 0.9547 test_loss: 0.3927847663870016 test_accuracy: 0.8781\n",
      "Iteraions 983: train_loss: 0.11519843205804212 train_accuracy: 0.9557333333333333 test_loss: 0.39533440124691516 test_accuracy: 0.8792\n",
      "Iteraions 984: train_loss: 0.11790327041601037 train_accuracy: 0.9549 test_loss: 0.3877810913250318 test_accuracy: 0.8813\n",
      "Iteraions 985: train_loss: 0.11886299153644819 train_accuracy: 0.95405 test_loss: 0.386457568424462 test_accuracy: 0.8817\n",
      "Iteraions 986: train_loss: 0.11845723254718353 train_accuracy: 0.9552333333333334 test_loss: 0.3889948283539631 test_accuracy: 0.8807\n",
      "Iteraions 987: train_loss: 0.11858410764608814 train_accuracy: 0.9538166666666666 test_loss: 0.37633374313917356 test_accuracy: 0.8844\n",
      "Iteraions 988: train_loss: 0.11795415231306346 train_accuracy: 0.9554 test_loss: 0.38623139499490705 test_accuracy: 0.8807\n",
      "Iteraions 989: train_loss: 0.11798305142708605 train_accuracy: 0.9549666666666666 test_loss: 0.3887124738099934 test_accuracy: 0.8806\n",
      "Iteraions 990: train_loss: 0.11651393997285184 train_accuracy: 0.95635 test_loss: 0.3951983600357691 test_accuracy: 0.8793\n",
      "Iteraions 991: train_loss: 0.11694117862931865 train_accuracy: 0.9553166666666667 test_loss: 0.39452854469065235 test_accuracy: 0.882\n",
      "Iteraions 992: train_loss: 0.1158378024567087 train_accuracy: 0.95515 test_loss: 0.3890705907450174 test_accuracy: 0.8799\n",
      "Iteraions 993: train_loss: 0.11476593799524455 train_accuracy: 0.9568 test_loss: 0.38079331540121364 test_accuracy: 0.8815\n",
      "Iteraions 994: train_loss: 0.11705724579333734 train_accuracy: 0.9544333333333334 test_loss: 0.38309537743754607 test_accuracy: 0.8823\n",
      "Iteraions 995: train_loss: 0.11856378466623611 train_accuracy: 0.9545333333333333 test_loss: 0.3834760682643315 test_accuracy: 0.8822\n",
      "Iteraions 996: train_loss: 0.11910229579354327 train_accuracy: 0.9545666666666667 test_loss: 0.38087407507509513 test_accuracy: 0.8798\n",
      "Iteraions 997: train_loss: 0.11947630919719407 train_accuracy: 0.9551666666666667 test_loss: 0.3913315034355821 test_accuracy: 0.8811\n",
      "Iteraions 998: train_loss: 0.11585188895169614 train_accuracy: 0.95725 test_loss: 0.38849020605685447 test_accuracy: 0.8817\n",
      "Iteraions 999: train_loss: 0.11749266140288374 train_accuracy: 0.9554 test_loss: 0.38892051671396555 test_accuracy: 0.8806\n"
     ]
    }
   ],
   "source": [
    "# Call train function and run it for specified number of iterations (max_iterations = 1000)\n",
    "train(tr_x, W1, b1, W2, b2, W3, b3, tr_y, te_x, te_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is for dropout prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 0: train_loss: 2.3027515960329645 train_accuracy: 0.1 test_loss: 2.302734744852621 test_accuracy: 0.1\n",
      "Iteraions 1: train_loss: 2.2996426227421756 train_accuracy: 0.1 test_loss: 2.299637553295562 test_accuracy: 0.1\n",
      "Iteraions 2: train_loss: 2.293587917945113 train_accuracy: 0.1 test_loss: 2.2936448479588187 test_accuracy: 0.1\n",
      "Iteraions 3: train_loss: 2.282436535011558 train_accuracy: 0.1 test_loss: 2.282340462896922 test_accuracy: 0.1\n",
      "Iteraions 4: train_loss: 2.2641188296293473 train_accuracy: 0.1 test_loss: 2.2641710126162717 test_accuracy: 0.1\n",
      "Iteraions 5: train_loss: 2.2371548419431098 train_accuracy: 0.1 test_loss: 2.23707109998448 test_accuracy: 0.1\n",
      "Iteraions 6: train_loss: 2.1994842635148166 train_accuracy: 0.1 test_loss: 2.199903028565005 test_accuracy: 0.1\n",
      "Iteraions 7: train_loss: 2.1507232722269816 train_accuracy: 0.1 test_loss: 2.1505967050547254 test_accuracy: 0.1\n",
      "Iteraions 8: train_loss: 2.091376066338355 train_accuracy: 0.1 test_loss: 2.092012205610307 test_accuracy: 0.1\n",
      "Iteraions 9: train_loss: 2.0222739373836762 train_accuracy: 0.1 test_loss: 2.0227914254369805 test_accuracy: 0.1\n",
      "Iteraions 10: train_loss: 1.9443438588596047 train_accuracy: 0.1 test_loss: 1.945724039383309 test_accuracy: 0.1\n",
      "Iteraions 11: train_loss: 1.8594105191474717 train_accuracy: 0.1 test_loss: 1.861711670673969 test_accuracy: 0.1\n",
      "Iteraions 12: train_loss: 1.7719881318137594 train_accuracy: 0.10003333333333334 test_loss: 1.7741683808778892 test_accuracy: 0.1\n",
      "Iteraions 13: train_loss: 1.686684113708705 train_accuracy: 0.1011 test_loss: 1.6900706889519312 test_accuracy: 0.1007\n",
      "Iteraions 14: train_loss: 1.6063759227230532 train_accuracy: 0.10698333333333333 test_loss: 1.6095987711763098 test_accuracy: 0.1069\n",
      "Iteraions 15: train_loss: 1.5321048768234447 train_accuracy: 0.12031666666666667 test_loss: 1.5359181826771386 test_accuracy: 0.1183\n",
      "Iteraions 16: train_loss: 1.464211252943402 train_accuracy: 0.14293333333333333 test_loss: 1.468821640287522 test_accuracy: 0.1396\n",
      "Iteraions 17: train_loss: 1.4059056223499793 train_accuracy: 0.1662 test_loss: 1.4101702913219014 test_accuracy: 0.1645\n",
      "Iteraions 18: train_loss: 1.3530334093296426 train_accuracy: 0.1816 test_loss: 1.3578269357999928 test_accuracy: 0.1791\n",
      "Iteraions 19: train_loss: 1.3035211192670915 train_accuracy: 0.19105 test_loss: 1.3117003554468802 test_accuracy: 0.1893\n",
      "Iteraions 20: train_loss: 1.261826427213808 train_accuracy: 0.19626666666666667 test_loss: 1.2730544324058057 test_accuracy: 0.1909\n",
      "Iteraions 21: train_loss: 1.2261954178672176 train_accuracy: 0.20985 test_loss: 1.2363061094609424 test_accuracy: 0.2098\n",
      "Iteraions 22: train_loss: 1.192660259384277 train_accuracy: 0.23501666666666668 test_loss: 1.200666883265033 test_accuracy: 0.2366\n",
      "Iteraions 23: train_loss: 1.1601408718646171 train_accuracy: 0.27175 test_loss: 1.171587534428844 test_accuracy: 0.2706\n",
      "Iteraions 24: train_loss: 1.1348720164073907 train_accuracy: 0.30206666666666665 test_loss: 1.149256546727278 test_accuracy: 0.3009\n",
      "Iteraions 25: train_loss: 1.1114292017226515 train_accuracy: 0.32375 test_loss: 1.1265029090330494 test_accuracy: 0.3211\n",
      "Iteraions 26: train_loss: 1.0856626681765265 train_accuracy: 0.3503833333333333 test_loss: 1.1016421655845081 test_accuracy: 0.3445\n",
      "Iteraions 27: train_loss: 1.0615715819267706 train_accuracy: 0.39198333333333335 test_loss: 1.0774724597938294 test_accuracy: 0.3936\n",
      "Iteraions 28: train_loss: 1.0420033262568982 train_accuracy: 0.4260833333333333 test_loss: 1.0601488411579227 test_accuracy: 0.4224\n",
      "Iteraions 29: train_loss: 1.0200989779035947 train_accuracy: 0.44126666666666664 test_loss: 1.0370785397825595 test_accuracy: 0.4408\n",
      "Iteraions 30: train_loss: 1.000183997430241 train_accuracy: 0.4516833333333333 test_loss: 1.0282492546792423 test_accuracy: 0.4492\n",
      "Iteraions 31: train_loss: 0.9815717757916042 train_accuracy: 0.4623 test_loss: 1.0036895582789371 test_accuracy: 0.4593\n",
      "Iteraions 32: train_loss: 0.9664073929603946 train_accuracy: 0.47376666666666667 test_loss: 0.9852017165739974 test_accuracy: 0.4728\n",
      "Iteraions 33: train_loss: 0.950858169510016 train_accuracy: 0.47835 test_loss: 0.974330716624892 test_accuracy: 0.4765\n",
      "Iteraions 34: train_loss: 0.9343094858616988 train_accuracy: 0.4871 test_loss: 0.957195616627978 test_accuracy: 0.48\n",
      "Iteraions 35: train_loss: 0.9240420482819404 train_accuracy: 0.49398333333333333 test_loss: 0.9432097606688221 test_accuracy: 0.4858\n",
      "Iteraions 36: train_loss: 0.9105295758839383 train_accuracy: 0.5162833333333333 test_loss: 0.9311119121953436 test_accuracy: 0.5102\n",
      "Iteraions 37: train_loss: 0.9001370827623854 train_accuracy: 0.5112666666666666 test_loss: 0.9197788365260303 test_accuracy: 0.5067\n",
      "Iteraions 38: train_loss: 0.8878975856125249 train_accuracy: 0.53475 test_loss: 0.9076002371355955 test_accuracy: 0.5279\n",
      "Iteraions 39: train_loss: 0.8778441181294215 train_accuracy: 0.5313666666666667 test_loss: 0.9001252794328433 test_accuracy: 0.5227\n",
      "Iteraions 40: train_loss: 0.862221319493097 train_accuracy: 0.5299 test_loss: 0.8905410995721069 test_accuracy: 0.5235\n",
      "Iteraions 41: train_loss: 0.8549378783651354 train_accuracy: 0.5499166666666667 test_loss: 0.881626746707711 test_accuracy: 0.5421\n",
      "Iteraions 42: train_loss: 0.8460661719713183 train_accuracy: 0.5558833333333333 test_loss: 0.8721665199912922 test_accuracy: 0.5487\n",
      "Iteraions 43: train_loss: 0.8352498944276759 train_accuracy: 0.5512166666666667 test_loss: 0.8541214136988255 test_accuracy: 0.5465\n",
      "Iteraions 44: train_loss: 0.8272639637821895 train_accuracy: 0.5595166666666667 test_loss: 0.8488169856375467 test_accuracy: 0.5484\n",
      "Iteraions 45: train_loss: 0.8180387922363628 train_accuracy: 0.5762166666666667 test_loss: 0.8397414555243249 test_accuracy: 0.573\n",
      "Iteraions 46: train_loss: 0.808618090646623 train_accuracy: 0.5753833333333334 test_loss: 0.8368842608401206 test_accuracy: 0.5643\n",
      "Iteraions 47: train_loss: 0.8000165281077085 train_accuracy: 0.5712166666666667 test_loss: 0.8224173025412849 test_accuracy: 0.5628\n",
      "Iteraions 48: train_loss: 0.7921812388021588 train_accuracy: 0.5880166666666666 test_loss: 0.8074633503861641 test_accuracy: 0.5793\n",
      "Iteraions 49: train_loss: 0.7850532118485899 train_accuracy: 0.5956333333333333 test_loss: 0.7979407454029115 test_accuracy: 0.5848\n",
      "Iteraions 50: train_loss: 0.777584112738339 train_accuracy: 0.5937666666666667 test_loss: 0.7921646295432393 test_accuracy: 0.5867\n",
      "Iteraions 51: train_loss: 0.7664475679062166 train_accuracy: 0.5978 test_loss: 0.7918591681845931 test_accuracy: 0.5907\n",
      "Iteraions 52: train_loss: 0.7607496954197825 train_accuracy: 0.6062333333333333 test_loss: 0.7784259313885493 test_accuracy: 0.6019\n",
      "Iteraions 53: train_loss: 0.7530115375960483 train_accuracy: 0.61175 test_loss: 0.7755618708134252 test_accuracy: 0.6018\n",
      "Iteraions 54: train_loss: 0.7472432358841078 train_accuracy: 0.6142166666666666 test_loss: 0.7665191533859083 test_accuracy: 0.609\n",
      "Iteraions 55: train_loss: 0.7400910441878022 train_accuracy: 0.6177333333333334 test_loss: 0.7652609181561384 test_accuracy: 0.614\n",
      "Iteraions 56: train_loss: 0.7330360186517457 train_accuracy: 0.62525 test_loss: 0.752505537833883 test_accuracy: 0.622\n",
      "Iteraions 57: train_loss: 0.7231468811320099 train_accuracy: 0.6308166666666667 test_loss: 0.7498263063616563 test_accuracy: 0.6236\n",
      "Iteraions 58: train_loss: 0.7191494426260726 train_accuracy: 0.6314333333333333 test_loss: 0.7458950307799612 test_accuracy: 0.6208\n",
      "Iteraions 59: train_loss: 0.7154202128746604 train_accuracy: 0.6373166666666666 test_loss: 0.7344687049763097 test_accuracy: 0.6308\n",
      "Iteraions 60: train_loss: 0.7074711510160866 train_accuracy: 0.6442333333333333 test_loss: 0.7318156835280542 test_accuracy: 0.6339\n",
      "Iteraions 61: train_loss: 0.7045485048261214 train_accuracy: 0.6459166666666667 test_loss: 0.7198910387314973 test_accuracy: 0.6382\n",
      "Iteraions 62: train_loss: 0.6959754697790284 train_accuracy: 0.6496333333333333 test_loss: 0.7156421638871844 test_accuracy: 0.6438\n",
      "Iteraions 63: train_loss: 0.692150406876021 train_accuracy: 0.6561333333333333 test_loss: 0.7123627057554746 test_accuracy: 0.6473\n",
      "Iteraions 64: train_loss: 0.6859988306712126 train_accuracy: 0.6609333333333334 test_loss: 0.709236859239095 test_accuracy: 0.6535\n",
      "Iteraions 65: train_loss: 0.6777176499863323 train_accuracy: 0.6666333333333333 test_loss: 0.7067093770491321 test_accuracy: 0.6571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 66: train_loss: 0.6740723550523773 train_accuracy: 0.6668833333333334 test_loss: 0.6970208270329589 test_accuracy: 0.6602\n",
      "Iteraions 67: train_loss: 0.6695167065198083 train_accuracy: 0.6708666666666666 test_loss: 0.6920363516184963 test_accuracy: 0.6663\n",
      "Iteraions 68: train_loss: 0.6648200334419642 train_accuracy: 0.6776333333333333 test_loss: 0.6853468822883815 test_accuracy: 0.6703\n",
      "Iteraions 69: train_loss: 0.659332674256219 train_accuracy: 0.6773666666666667 test_loss: 0.6857097287786162 test_accuracy: 0.6684\n",
      "Iteraions 70: train_loss: 0.6546599861667958 train_accuracy: 0.6828166666666666 test_loss: 0.677894630573348 test_accuracy: 0.6749\n",
      "Iteraions 71: train_loss: 0.6488501260435403 train_accuracy: 0.68835 test_loss: 0.6715258175032108 test_accuracy: 0.6748\n",
      "Iteraions 72: train_loss: 0.6411206350620385 train_accuracy: 0.69055 test_loss: 0.6696310507203906 test_accuracy: 0.6771\n",
      "Iteraions 73: train_loss: 0.6377914159259708 train_accuracy: 0.6942666666666667 test_loss: 0.6638164527610714 test_accuracy: 0.684\n",
      "Iteraions 74: train_loss: 0.6346350865352707 train_accuracy: 0.6966833333333333 test_loss: 0.6653635597355174 test_accuracy: 0.6823\n",
      "Iteraions 75: train_loss: 0.6291712560348336 train_accuracy: 0.7012666666666667 test_loss: 0.6556146110704395 test_accuracy: 0.6905\n",
      "Iteraions 76: train_loss: 0.6244942647671211 train_accuracy: 0.7021833333333334 test_loss: 0.6464355900561338 test_accuracy: 0.6917\n",
      "Iteraions 77: train_loss: 0.6199626086770451 train_accuracy: 0.7039666666666666 test_loss: 0.6404610436903576 test_accuracy: 0.6938\n",
      "Iteraions 78: train_loss: 0.6164641042917646 train_accuracy: 0.7084666666666667 test_loss: 0.6425655749539082 test_accuracy: 0.6975\n",
      "Iteraions 79: train_loss: 0.611954797612791 train_accuracy: 0.7096 test_loss: 0.6383683585113544 test_accuracy: 0.6992\n",
      "Iteraions 80: train_loss: 0.6076183870298805 train_accuracy: 0.7129 test_loss: 0.6346260535407224 test_accuracy: 0.7004\n",
      "Iteraions 81: train_loss: 0.6032486997216091 train_accuracy: 0.7143333333333334 test_loss: 0.6308993777762415 test_accuracy: 0.7036\n",
      "Iteraions 82: train_loss: 0.5983784937404226 train_accuracy: 0.7178666666666667 test_loss: 0.6256131459799819 test_accuracy: 0.7072\n",
      "Iteraions 83: train_loss: 0.5962210398635085 train_accuracy: 0.7212333333333333 test_loss: 0.6198158509669289 test_accuracy: 0.7133\n",
      "Iteraions 84: train_loss: 0.5918815443366103 train_accuracy: 0.7227333333333333 test_loss: 0.6148072329106634 test_accuracy: 0.7127\n",
      "Iteraions 85: train_loss: 0.5890534355135986 train_accuracy: 0.7242666666666666 test_loss: 0.614469154850835 test_accuracy: 0.7141\n",
      "Iteraions 86: train_loss: 0.5839418809880088 train_accuracy: 0.7266166666666667 test_loss: 0.6052193561031795 test_accuracy: 0.7167\n",
      "Iteraions 87: train_loss: 0.5781876019235922 train_accuracy: 0.7288666666666667 test_loss: 0.6072971496295536 test_accuracy: 0.7161\n",
      "Iteraions 88: train_loss: 0.5751586622427659 train_accuracy: 0.7318833333333333 test_loss: 0.602560037773669 test_accuracy: 0.7193\n",
      "Iteraions 89: train_loss: 0.5714297181498661 train_accuracy: 0.7340333333333333 test_loss: 0.597654569678911 test_accuracy: 0.7219\n",
      "Iteraions 90: train_loss: 0.5667752704185127 train_accuracy: 0.7379666666666667 test_loss: 0.5956994320962301 test_accuracy: 0.7269\n",
      "Iteraions 91: train_loss: 0.566080613686816 train_accuracy: 0.7366833333333334 test_loss: 0.5909024385986925 test_accuracy: 0.7274\n",
      "Iteraions 92: train_loss: 0.5611546870318591 train_accuracy: 0.7409833333333333 test_loss: 0.5884901343158417 test_accuracy: 0.7298\n",
      "Iteraions 93: train_loss: 0.5577261509426962 train_accuracy: 0.7414166666666666 test_loss: 0.5836355416107173 test_accuracy: 0.7281\n",
      "Iteraions 94: train_loss: 0.5558247534229394 train_accuracy: 0.74525 test_loss: 0.583082317380706 test_accuracy: 0.7358\n",
      "Iteraions 95: train_loss: 0.5521326658823683 train_accuracy: 0.7468 test_loss: 0.5815519505331347 test_accuracy: 0.7361\n",
      "Iteraions 96: train_loss: 0.5483533593437644 train_accuracy: 0.7486333333333334 test_loss: 0.5741172499439493 test_accuracy: 0.7352\n",
      "Iteraions 97: train_loss: 0.5460073746131858 train_accuracy: 0.7509333333333333 test_loss: 0.5730550167673009 test_accuracy: 0.7408\n",
      "Iteraions 98: train_loss: 0.5411720333776371 train_accuracy: 0.75065 test_loss: 0.5696872314370727 test_accuracy: 0.7415\n",
      "Iteraions 99: train_loss: 0.5383050003313758 train_accuracy: 0.7556833333333334 test_loss: 0.567935910947214 test_accuracy: 0.7416\n",
      "Iteraions 100: train_loss: 0.5355065922193898 train_accuracy: 0.7566166666666667 test_loss: 0.5622515322020639 test_accuracy: 0.7453\n",
      "Iteraions 101: train_loss: 0.5309287420676695 train_accuracy: 0.7588833333333334 test_loss: 0.5637245781807154 test_accuracy: 0.7437\n",
      "Iteraions 102: train_loss: 0.5292694037468176 train_accuracy: 0.7603333333333333 test_loss: 0.5575271614691858 test_accuracy: 0.7498\n",
      "Iteraions 103: train_loss: 0.528000295182048 train_accuracy: 0.7617833333333334 test_loss: 0.555759028285595 test_accuracy: 0.7456\n",
      "Iteraions 104: train_loss: 0.5244330945217581 train_accuracy: 0.7650666666666667 test_loss: 0.5527421290823022 test_accuracy: 0.7512\n",
      "Iteraions 105: train_loss: 0.5203409337268707 train_accuracy: 0.7664166666666666 test_loss: 0.5479692178956419 test_accuracy: 0.7547\n",
      "Iteraions 106: train_loss: 0.5181580221391372 train_accuracy: 0.7690833333333333 test_loss: 0.5467668834358516 test_accuracy: 0.7585\n",
      "Iteraions 107: train_loss: 0.5160603277459296 train_accuracy: 0.7709166666666667 test_loss: 0.5438634429811291 test_accuracy: 0.7589\n",
      "Iteraions 108: train_loss: 0.5130365200537834 train_accuracy: 0.7716333333333333 test_loss: 0.5429951014356953 test_accuracy: 0.76\n",
      "Iteraions 109: train_loss: 0.5101217795315934 train_accuracy: 0.7741166666666667 test_loss: 0.5398794472465969 test_accuracy: 0.766\n",
      "Iteraions 110: train_loss: 0.5055734851951328 train_accuracy: 0.7744 test_loss: 0.5366670739964193 test_accuracy: 0.7645\n",
      "Iteraions 111: train_loss: 0.5049704088485468 train_accuracy: 0.77785 test_loss: 0.5372620827766118 test_accuracy: 0.7616\n",
      "Iteraions 112: train_loss: 0.5017452664572022 train_accuracy: 0.7795833333333333 test_loss: 0.5319133844371964 test_accuracy: 0.7685\n",
      "Iteraions 113: train_loss: 0.49888587134732376 train_accuracy: 0.7796166666666666 test_loss: 0.5310167509326419 test_accuracy: 0.7673\n",
      "Iteraions 114: train_loss: 0.4982662536220086 train_accuracy: 0.7815166666666666 test_loss: 0.5279572445123948 test_accuracy: 0.7669\n",
      "Iteraions 115: train_loss: 0.49502639429558276 train_accuracy: 0.78515 test_loss: 0.5233466576522053 test_accuracy: 0.7692\n",
      "Iteraions 116: train_loss: 0.49417898690288165 train_accuracy: 0.7848 test_loss: 0.5167773924920908 test_accuracy: 0.7753\n",
      "Iteraions 117: train_loss: 0.48972464604827254 train_accuracy: 0.7873 test_loss: 0.5220968716298444 test_accuracy: 0.7728\n",
      "Iteraions 118: train_loss: 0.48674910288161893 train_accuracy: 0.7878 test_loss: 0.5161802182860623 test_accuracy: 0.7721\n",
      "Iteraions 119: train_loss: 0.48568828099374733 train_accuracy: 0.78875 test_loss: 0.5179410815768964 test_accuracy: 0.7744\n",
      "Iteraions 120: train_loss: 0.4831312810079078 train_accuracy: 0.7895833333333333 test_loss: 0.5116954829195421 test_accuracy: 0.7821\n",
      "Iteraions 121: train_loss: 0.4809677095684675 train_accuracy: 0.7922 test_loss: 0.5116323959110785 test_accuracy: 0.7783\n",
      "Iteraions 122: train_loss: 0.47908653875065416 train_accuracy: 0.7929 test_loss: 0.5117439493074517 test_accuracy: 0.7793\n",
      "Iteraions 123: train_loss: 0.4770069433299765 train_accuracy: 0.7937666666666666 test_loss: 0.5037556986950491 test_accuracy: 0.783\n",
      "Iteraions 124: train_loss: 0.47401847809137226 train_accuracy: 0.7955833333333333 test_loss: 0.506052924542283 test_accuracy: 0.7813\n",
      "Iteraions 125: train_loss: 0.47214701353119376 train_accuracy: 0.7967666666666666 test_loss: 0.5062624469188399 test_accuracy: 0.782\n",
      "Iteraions 126: train_loss: 0.4709896706552147 train_accuracy: 0.7976333333333333 test_loss: 0.5027743072276668 test_accuracy: 0.7847\n",
      "Iteraions 127: train_loss: 0.46773213419570336 train_accuracy: 0.8010166666666667 test_loss: 0.5018346147541011 test_accuracy: 0.7861\n",
      "Iteraions 128: train_loss: 0.46573720274811686 train_accuracy: 0.80055 test_loss: 0.5029990047662138 test_accuracy: 0.7871\n",
      "Iteraions 129: train_loss: 0.46511705548769106 train_accuracy: 0.8007166666666666 test_loss: 0.49654920791029 test_accuracy: 0.7873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 130: train_loss: 0.4614668040553565 train_accuracy: 0.8039666666666667 test_loss: 0.49162995190137027 test_accuracy: 0.7893\n",
      "Iteraions 131: train_loss: 0.4592377917334309 train_accuracy: 0.8057666666666666 test_loss: 0.4943371459665841 test_accuracy: 0.789\n",
      "Iteraions 132: train_loss: 0.4579083507511638 train_accuracy: 0.8029333333333334 test_loss: 0.49480149110559923 test_accuracy: 0.7895\n",
      "Iteraions 133: train_loss: 0.4562768983652386 train_accuracy: 0.8059833333333334 test_loss: 0.4885468250368359 test_accuracy: 0.7921\n",
      "Iteraions 134: train_loss: 0.4550186341423897 train_accuracy: 0.8052 test_loss: 0.4872377200232246 test_accuracy: 0.7926\n",
      "Iteraions 135: train_loss: 0.45273878699258224 train_accuracy: 0.8077333333333333 test_loss: 0.4901968384778419 test_accuracy: 0.7919\n",
      "Iteraions 136: train_loss: 0.4521138456472329 train_accuracy: 0.8099666666666666 test_loss: 0.487691207649042 test_accuracy: 0.7941\n",
      "Iteraions 137: train_loss: 0.449101220880111 train_accuracy: 0.8078 test_loss: 0.48109168740384184 test_accuracy: 0.7907\n",
      "Iteraions 138: train_loss: 0.44807514563504874 train_accuracy: 0.8106 test_loss: 0.48015212444804356 test_accuracy: 0.7956\n",
      "Iteraions 139: train_loss: 0.4459640259268546 train_accuracy: 0.8114 test_loss: 0.4831119107147518 test_accuracy: 0.7964\n",
      "Iteraions 140: train_loss: 0.44490902623791573 train_accuracy: 0.8117833333333333 test_loss: 0.4807294321768168 test_accuracy: 0.7966\n",
      "Iteraions 141: train_loss: 0.4422153836101616 train_accuracy: 0.8136333333333333 test_loss: 0.48151215339844095 test_accuracy: 0.7964\n",
      "Iteraions 142: train_loss: 0.4416961658396837 train_accuracy: 0.8118 test_loss: 0.4747242869119835 test_accuracy: 0.8005\n",
      "Iteraions 143: train_loss: 0.44118000148283754 train_accuracy: 0.8128 test_loss: 0.47424602947931116 test_accuracy: 0.8009\n",
      "Iteraions 144: train_loss: 0.4380771130718242 train_accuracy: 0.81495 test_loss: 0.4701645928683578 test_accuracy: 0.8\n",
      "Iteraions 145: train_loss: 0.43538689285329574 train_accuracy: 0.81595 test_loss: 0.469576570852051 test_accuracy: 0.8006\n",
      "Iteraions 146: train_loss: 0.43428177990190897 train_accuracy: 0.8170666666666667 test_loss: 0.4731794092049997 test_accuracy: 0.8017\n",
      "Iteraions 147: train_loss: 0.4334366380926565 train_accuracy: 0.8154666666666667 test_loss: 0.4713801406446726 test_accuracy: 0.8014\n",
      "Iteraions 148: train_loss: 0.43099979097857827 train_accuracy: 0.8175166666666667 test_loss: 0.4685573525993259 test_accuracy: 0.8031\n",
      "Iteraions 149: train_loss: 0.4306011212645227 train_accuracy: 0.8183166666666667 test_loss: 0.4627718067994954 test_accuracy: 0.8029\n",
      "Iteraions 150: train_loss: 0.4286059618685453 train_accuracy: 0.8183 test_loss: 0.46523131523979555 test_accuracy: 0.8035\n",
      "Iteraions 151: train_loss: 0.4256603975845475 train_accuracy: 0.8199 test_loss: 0.4637794812284724 test_accuracy: 0.8036\n",
      "Iteraions 152: train_loss: 0.42556314522848665 train_accuracy: 0.8210833333333334 test_loss: 0.4635243629850767 test_accuracy: 0.8026\n",
      "Iteraions 153: train_loss: 0.4251921397983706 train_accuracy: 0.8207833333333333 test_loss: 0.46001052522352376 test_accuracy: 0.8064\n",
      "Iteraions 154: train_loss: 0.4223344314863957 train_accuracy: 0.8227333333333333 test_loss: 0.4593060330407162 test_accuracy: 0.8043\n",
      "Iteraions 155: train_loss: 0.422921014909714 train_accuracy: 0.8230333333333333 test_loss: 0.4609728957594771 test_accuracy: 0.8071\n",
      "Iteraions 156: train_loss: 0.4208428124088151 train_accuracy: 0.8221666666666667 test_loss: 0.4566115581498526 test_accuracy: 0.8099\n",
      "Iteraions 157: train_loss: 0.41916390160421907 train_accuracy: 0.8246333333333333 test_loss: 0.45169551100898664 test_accuracy: 0.8106\n",
      "Iteraions 158: train_loss: 0.41887586683116873 train_accuracy: 0.8242833333333334 test_loss: 0.45422088219093076 test_accuracy: 0.8077\n",
      "Iteraions 159: train_loss: 0.4164783644131998 train_accuracy: 0.8257333333333333 test_loss: 0.45504806815062837 test_accuracy: 0.8086\n",
      "Iteraions 160: train_loss: 0.41459444210912116 train_accuracy: 0.8242166666666667 test_loss: 0.45010414292485484 test_accuracy: 0.8093\n",
      "Iteraions 161: train_loss: 0.41379387634949366 train_accuracy: 0.8264333333333334 test_loss: 0.44907162951045104 test_accuracy: 0.8104\n",
      "Iteraions 162: train_loss: 0.4128524490270289 train_accuracy: 0.82685 test_loss: 0.45074964689361297 test_accuracy: 0.8119\n",
      "Iteraions 163: train_loss: 0.4109007475140886 train_accuracy: 0.8274833333333333 test_loss: 0.4553810791659809 test_accuracy: 0.8088\n",
      "Iteraions 164: train_loss: 0.40837743326906323 train_accuracy: 0.83005 test_loss: 0.4485574680801221 test_accuracy: 0.8141\n",
      "Iteraions 165: train_loss: 0.4091891177248913 train_accuracy: 0.8275333333333333 test_loss: 0.4431596355067055 test_accuracy: 0.8183\n",
      "Iteraions 166: train_loss: 0.40850035147912883 train_accuracy: 0.8290333333333333 test_loss: 0.44847095168227336 test_accuracy: 0.8154\n",
      "Iteraions 167: train_loss: 0.4055003120979657 train_accuracy: 0.8306833333333333 test_loss: 0.44817669715341935 test_accuracy: 0.8122\n",
      "Iteraions 168: train_loss: 0.40656503078538586 train_accuracy: 0.8290333333333333 test_loss: 0.44476694418416407 test_accuracy: 0.8142\n",
      "Iteraions 169: train_loss: 0.4051892892028125 train_accuracy: 0.8302833333333334 test_loss: 0.4436828345740617 test_accuracy: 0.8158\n",
      "Iteraions 170: train_loss: 0.40248512409446735 train_accuracy: 0.8327833333333333 test_loss: 0.4414127891816147 test_accuracy: 0.8188\n",
      "Iteraions 171: train_loss: 0.40281687806262423 train_accuracy: 0.8321833333333334 test_loss: 0.4407248125207515 test_accuracy: 0.8168\n",
      "Iteraions 172: train_loss: 0.400958207137674 train_accuracy: 0.8313 test_loss: 0.44294983100208674 test_accuracy: 0.8165\n",
      "Iteraions 173: train_loss: 0.39895935727892295 train_accuracy: 0.8348 test_loss: 0.4411120385949771 test_accuracy: 0.8154\n",
      "Iteraions 174: train_loss: 0.39805279013349293 train_accuracy: 0.8339666666666666 test_loss: 0.4413065109855743 test_accuracy: 0.8188\n",
      "Iteraions 175: train_loss: 0.3985722858286063 train_accuracy: 0.83435 test_loss: 0.43785706464829416 test_accuracy: 0.8197\n",
      "Iteraions 176: train_loss: 0.39638240426106114 train_accuracy: 0.8338666666666666 test_loss: 0.4362079680739518 test_accuracy: 0.8204\n",
      "Iteraions 177: train_loss: 0.3955954745047638 train_accuracy: 0.83485 test_loss: 0.4374037861189525 test_accuracy: 0.8202\n",
      "Iteraions 178: train_loss: 0.3928834731202393 train_accuracy: 0.8365333333333334 test_loss: 0.4375891333993729 test_accuracy: 0.8194\n",
      "Iteraions 179: train_loss: 0.3910589146592714 train_accuracy: 0.83725 test_loss: 0.43659103303259816 test_accuracy: 0.8209\n",
      "Iteraions 180: train_loss: 0.3903337421030356 train_accuracy: 0.83795 test_loss: 0.4314950745480759 test_accuracy: 0.8166\n",
      "Iteraions 181: train_loss: 0.3912660262598697 train_accuracy: 0.83605 test_loss: 0.4312355714607653 test_accuracy: 0.8206\n",
      "Iteraions 182: train_loss: 0.3893571760804846 train_accuracy: 0.8371333333333333 test_loss: 0.43671149676350207 test_accuracy: 0.8201\n",
      "Iteraions 183: train_loss: 0.3892769547764627 train_accuracy: 0.8369166666666666 test_loss: 0.4315061353546185 test_accuracy: 0.8228\n",
      "Iteraions 184: train_loss: 0.3863282566116612 train_accuracy: 0.8376 test_loss: 0.43049531088356163 test_accuracy: 0.8211\n",
      "Iteraions 185: train_loss: 0.38564756411253415 train_accuracy: 0.8399166666666666 test_loss: 0.4272764702542014 test_accuracy: 0.8218\n",
      "Iteraions 186: train_loss: 0.38521466477007693 train_accuracy: 0.8392833333333334 test_loss: 0.4299599828467326 test_accuracy: 0.8227\n",
      "Iteraions 187: train_loss: 0.3843476957708523 train_accuracy: 0.8400166666666666 test_loss: 0.42830540951570284 test_accuracy: 0.8219\n",
      "Iteraions 188: train_loss: 0.3831055486265319 train_accuracy: 0.8403333333333334 test_loss: 0.42552611538517265 test_accuracy: 0.8215\n",
      "Iteraions 189: train_loss: 0.3815561925961041 train_accuracy: 0.8417833333333333 test_loss: 0.4249907700120044 test_accuracy: 0.825\n",
      "Iteraions 190: train_loss: 0.37833348316585264 train_accuracy: 0.8427333333333333 test_loss: 0.4291425038050291 test_accuracy: 0.8214\n",
      "Iteraions 191: train_loss: 0.37839384123186975 train_accuracy: 0.8426333333333333 test_loss: 0.427001157174569 test_accuracy: 0.8211\n",
      "Iteraions 192: train_loss: 0.37856581337057926 train_accuracy: 0.8436333333333333 test_loss: 0.4253320509215728 test_accuracy: 0.827\n",
      "Iteraions 193: train_loss: 0.3769484489736035 train_accuracy: 0.8434333333333334 test_loss: 0.4228677232323433 test_accuracy: 0.8256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 194: train_loss: 0.377317747868383 train_accuracy: 0.8441333333333333 test_loss: 0.42260169535876874 test_accuracy: 0.8278\n",
      "Iteraions 195: train_loss: 0.3766116586045499 train_accuracy: 0.8441 test_loss: 0.4223800595018496 test_accuracy: 0.8284\n",
      "Iteraions 196: train_loss: 0.3757440386002979 train_accuracy: 0.8437 test_loss: 0.4183152882223044 test_accuracy: 0.828\n",
      "Iteraions 197: train_loss: 0.37421253883213385 train_accuracy: 0.8451666666666666 test_loss: 0.4219552240724637 test_accuracy: 0.8268\n",
      "Iteraions 198: train_loss: 0.37120663356153355 train_accuracy: 0.8472833333333334 test_loss: 0.4198249544432032 test_accuracy: 0.8271\n",
      "Iteraions 199: train_loss: 0.37144062186466514 train_accuracy: 0.8464333333333334 test_loss: 0.4178234974047323 test_accuracy: 0.8306\n",
      "Iteraions 200: train_loss: 0.37071586741679674 train_accuracy: 0.8467 test_loss: 0.41748557674773984 test_accuracy: 0.8276\n",
      "Iteraions 201: train_loss: 0.3677375266786258 train_accuracy: 0.84715 test_loss: 0.41828245150012716 test_accuracy: 0.8303\n",
      "Iteraions 202: train_loss: 0.36980772214975394 train_accuracy: 0.84675 test_loss: 0.4171627875749376 test_accuracy: 0.8288\n",
      "Iteraions 203: train_loss: 0.3690051110404265 train_accuracy: 0.8472 test_loss: 0.4173658830487656 test_accuracy: 0.8287\n",
      "Iteraions 204: train_loss: 0.36991682469414494 train_accuracy: 0.8472166666666666 test_loss: 0.4135829403392799 test_accuracy: 0.8269\n",
      "Iteraions 205: train_loss: 0.36662108341845656 train_accuracy: 0.8480666666666666 test_loss: 0.41624390678322026 test_accuracy: 0.83\n",
      "Iteraions 206: train_loss: 0.3653204756049375 train_accuracy: 0.8492833333333333 test_loss: 0.412453789096859 test_accuracy: 0.8315\n",
      "Iteraions 207: train_loss: 0.36422087599401287 train_accuracy: 0.8489333333333333 test_loss: 0.4128392921910119 test_accuracy: 0.832\n",
      "Iteraions 208: train_loss: 0.36353305912825357 train_accuracy: 0.8503666666666667 test_loss: 0.4069989280382157 test_accuracy: 0.8328\n",
      "Iteraions 209: train_loss: 0.3633699638213494 train_accuracy: 0.8490833333333333 test_loss: 0.4093930338201978 test_accuracy: 0.8311\n",
      "Iteraions 210: train_loss: 0.36212858736100734 train_accuracy: 0.85065 test_loss: 0.4087350449274297 test_accuracy: 0.8352\n",
      "Iteraions 211: train_loss: 0.36059199172049955 train_accuracy: 0.8500666666666666 test_loss: 0.4068394149765906 test_accuracy: 0.8338\n",
      "Iteraions 212: train_loss: 0.36067791850473563 train_accuracy: 0.85095 test_loss: 0.4125984132883654 test_accuracy: 0.8302\n",
      "Iteraions 213: train_loss: 0.3586931846170632 train_accuracy: 0.8516166666666667 test_loss: 0.4092591529784054 test_accuracy: 0.8309\n",
      "Iteraions 214: train_loss: 0.35921746530219084 train_accuracy: 0.85065 test_loss: 0.41191113734443235 test_accuracy: 0.83\n",
      "Iteraions 215: train_loss: 0.35794331947433455 train_accuracy: 0.8524166666666667 test_loss: 0.40805688696359826 test_accuracy: 0.8323\n",
      "Iteraions 216: train_loss: 0.3574755662595915 train_accuracy: 0.8527 test_loss: 0.4058876265662949 test_accuracy: 0.8341\n",
      "Iteraions 217: train_loss: 0.3556056602183668 train_accuracy: 0.8537166666666667 test_loss: 0.40349547290469423 test_accuracy: 0.8342\n",
      "Iteraions 218: train_loss: 0.3571765303199436 train_accuracy: 0.85245 test_loss: 0.4075437976338847 test_accuracy: 0.8337\n",
      "Iteraions 219: train_loss: 0.3550839624937929 train_accuracy: 0.8533666666666667 test_loss: 0.4063098244645157 test_accuracy: 0.8335\n",
      "Iteraions 220: train_loss: 0.3544992764682385 train_accuracy: 0.8541333333333333 test_loss: 0.4049969182104197 test_accuracy: 0.8354\n",
      "Iteraions 221: train_loss: 0.35229385531928725 train_accuracy: 0.8540833333333333 test_loss: 0.4057025387813737 test_accuracy: 0.8355\n",
      "Iteraions 222: train_loss: 0.3529152096999342 train_accuracy: 0.8548166666666667 test_loss: 0.4039249634953649 test_accuracy: 0.8355\n",
      "Iteraions 223: train_loss: 0.35098080129706183 train_accuracy: 0.8557166666666667 test_loss: 0.4035820825016178 test_accuracy: 0.8357\n",
      "Iteraions 224: train_loss: 0.3492967549567457 train_accuracy: 0.8568 test_loss: 0.40536398305595994 test_accuracy: 0.8381\n",
      "Iteraions 225: train_loss: 0.3504400894600544 train_accuracy: 0.8552833333333333 test_loss: 0.40289152074939594 test_accuracy: 0.8359\n",
      "Iteraions 226: train_loss: 0.3486174545276705 train_accuracy: 0.8563166666666666 test_loss: 0.40313813319704306 test_accuracy: 0.8366\n",
      "Iteraions 227: train_loss: 0.34939859945127605 train_accuracy: 0.8559333333333333 test_loss: 0.40088402476914614 test_accuracy: 0.8397\n",
      "Iteraions 228: train_loss: 0.3488462943695969 train_accuracy: 0.8564166666666667 test_loss: 0.40182027236473095 test_accuracy: 0.8342\n",
      "Iteraions 229: train_loss: 0.3471745753063048 train_accuracy: 0.8568833333333333 test_loss: 0.4018492263831104 test_accuracy: 0.8378\n",
      "Iteraions 230: train_loss: 0.34715527302597243 train_accuracy: 0.8566833333333334 test_loss: 0.4008607371264828 test_accuracy: 0.8369\n",
      "Iteraions 231: train_loss: 0.3461705784063669 train_accuracy: 0.85785 test_loss: 0.39974669349903025 test_accuracy: 0.8383\n",
      "Iteraions 232: train_loss: 0.3453283155127682 train_accuracy: 0.8578 test_loss: 0.39682534153983906 test_accuracy: 0.8412\n",
      "Iteraions 233: train_loss: 0.34338115927132107 train_accuracy: 0.8581666666666666 test_loss: 0.39587034671182525 test_accuracy: 0.8396\n",
      "Iteraions 234: train_loss: 0.341708944756823 train_accuracy: 0.8589833333333333 test_loss: 0.3967613428307504 test_accuracy: 0.8409\n",
      "Iteraions 235: train_loss: 0.34174882315297417 train_accuracy: 0.8597 test_loss: 0.392610006370165 test_accuracy: 0.8392\n",
      "Iteraions 236: train_loss: 0.34107113274997586 train_accuracy: 0.8591833333333333 test_loss: 0.3966866734592582 test_accuracy: 0.8407\n",
      "Iteraions 237: train_loss: 0.3401981054134525 train_accuracy: 0.85955 test_loss: 0.39189140948267226 test_accuracy: 0.8375\n",
      "Iteraions 238: train_loss: 0.338763756352589 train_accuracy: 0.8604833333333334 test_loss: 0.396065411556928 test_accuracy: 0.8375\n",
      "Iteraions 239: train_loss: 0.3391736397535872 train_accuracy: 0.8606 test_loss: 0.3932637725940993 test_accuracy: 0.8393\n",
      "Iteraions 240: train_loss: 0.33781931690999295 train_accuracy: 0.8628666666666667 test_loss: 0.3961548632353645 test_accuracy: 0.8389\n",
      "Iteraions 241: train_loss: 0.3387736190364963 train_accuracy: 0.8626666666666667 test_loss: 0.394281160134269 test_accuracy: 0.8426\n",
      "Iteraions 242: train_loss: 0.33674168438814084 train_accuracy: 0.8619333333333333 test_loss: 0.3949664251096935 test_accuracy: 0.8394\n",
      "Iteraions 243: train_loss: 0.335072823690558 train_accuracy: 0.8615666666666667 test_loss: 0.3892693980939486 test_accuracy: 0.8416\n",
      "Iteraions 244: train_loss: 0.3351005243576188 train_accuracy: 0.8633 test_loss: 0.3845157452909109 test_accuracy: 0.8453\n",
      "Iteraions 245: train_loss: 0.33559279860223956 train_accuracy: 0.8626333333333334 test_loss: 0.38966717562846204 test_accuracy: 0.8412\n",
      "Iteraions 246: train_loss: 0.33509471664432744 train_accuracy: 0.8635666666666667 test_loss: 0.3874640219317061 test_accuracy: 0.844\n",
      "Iteraions 247: train_loss: 0.3342392355250949 train_accuracy: 0.8630166666666667 test_loss: 0.3900070701215429 test_accuracy: 0.8421\n",
      "Iteraions 248: train_loss: 0.33275584975626077 train_accuracy: 0.86385 test_loss: 0.3957565513683751 test_accuracy: 0.8397\n",
      "Iteraions 249: train_loss: 0.33309854161197183 train_accuracy: 0.8636166666666667 test_loss: 0.3895865924401065 test_accuracy: 0.845\n",
      "Iteraions 250: train_loss: 0.33320106911333 train_accuracy: 0.8633 test_loss: 0.3908768961645697 test_accuracy: 0.8428\n",
      "Iteraions 251: train_loss: 0.32971133568274585 train_accuracy: 0.86445 test_loss: 0.38413811509811646 test_accuracy: 0.8431\n",
      "Iteraions 252: train_loss: 0.3323099059972286 train_accuracy: 0.8641833333333333 test_loss: 0.38458396624965074 test_accuracy: 0.8444\n",
      "Iteraions 253: train_loss: 0.3311407392914815 train_accuracy: 0.8643666666666666 test_loss: 0.39462107352206605 test_accuracy: 0.8434\n",
      "Iteraions 254: train_loss: 0.32974797786399934 train_accuracy: 0.8657833333333333 test_loss: 0.3849806353575046 test_accuracy: 0.8454\n",
      "Iteraions 255: train_loss: 0.32787727806823797 train_accuracy: 0.8651333333333333 test_loss: 0.3878340015755638 test_accuracy: 0.8446\n",
      "Iteraions 256: train_loss: 0.32785006049331045 train_accuracy: 0.8665 test_loss: 0.39160820934275525 test_accuracy: 0.8443\n",
      "Iteraions 257: train_loss: 0.3277843959607627 train_accuracy: 0.8658666666666667 test_loss: 0.3820141411103626 test_accuracy: 0.8448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 258: train_loss: 0.32684173579452114 train_accuracy: 0.8663666666666666 test_loss: 0.38278374897097645 test_accuracy: 0.8465\n",
      "Iteraions 259: train_loss: 0.3249373997012966 train_accuracy: 0.8659833333333333 test_loss: 0.3880075716404291 test_accuracy: 0.8433\n",
      "Iteraions 260: train_loss: 0.32537807603512015 train_accuracy: 0.86705 test_loss: 0.3853700935642063 test_accuracy: 0.8456\n",
      "Iteraions 261: train_loss: 0.32517962873862394 train_accuracy: 0.86615 test_loss: 0.38507824319985084 test_accuracy: 0.8468\n",
      "Iteraions 262: train_loss: 0.3241316119893439 train_accuracy: 0.86735 test_loss: 0.3791795477863179 test_accuracy: 0.8447\n",
      "Iteraions 263: train_loss: 0.3240561426167602 train_accuracy: 0.86785 test_loss: 0.3893736342505868 test_accuracy: 0.8465\n",
      "Iteraions 264: train_loss: 0.3236724022626155 train_accuracy: 0.8684833333333334 test_loss: 0.37700010407312173 test_accuracy: 0.8488\n",
      "Iteraions 265: train_loss: 0.3246710184104348 train_accuracy: 0.86675 test_loss: 0.38325139954258314 test_accuracy: 0.8473\n",
      "Iteraions 266: train_loss: 0.32324455536450014 train_accuracy: 0.86675 test_loss: 0.3817785468195374 test_accuracy: 0.8457\n",
      "Iteraions 267: train_loss: 0.32182122109516176 train_accuracy: 0.8689166666666667 test_loss: 0.38407397064564397 test_accuracy: 0.8465\n",
      "Iteraions 268: train_loss: 0.3203637600457343 train_accuracy: 0.8694833333333334 test_loss: 0.3826942091758601 test_accuracy: 0.8466\n",
      "Iteraions 269: train_loss: 0.32176286692953043 train_accuracy: 0.8684166666666666 test_loss: 0.3837793786893799 test_accuracy: 0.8474\n",
      "Iteraions 270: train_loss: 0.3200049838965373 train_accuracy: 0.8691 test_loss: 0.37832637299570865 test_accuracy: 0.8487\n",
      "Iteraions 271: train_loss: 0.3189509913724213 train_accuracy: 0.86795 test_loss: 0.37749741855467345 test_accuracy: 0.8478\n",
      "Iteraions 272: train_loss: 0.3198334604568919 train_accuracy: 0.8685833333333334 test_loss: 0.37944794920476904 test_accuracy: 0.8475\n",
      "Iteraions 273: train_loss: 0.3192614365220945 train_accuracy: 0.86835 test_loss: 0.380824080383395 test_accuracy: 0.8475\n",
      "Iteraions 274: train_loss: 0.31777215604402503 train_accuracy: 0.8700166666666667 test_loss: 0.38043645282057775 test_accuracy: 0.8495\n",
      "Iteraions 275: train_loss: 0.31617275304400344 train_accuracy: 0.8706666666666667 test_loss: 0.38186880646996835 test_accuracy: 0.849\n",
      "Iteraions 276: train_loss: 0.3171648962264235 train_accuracy: 0.8709 test_loss: 0.3815267538403071 test_accuracy: 0.8462\n",
      "Iteraions 277: train_loss: 0.3176712413003222 train_accuracy: 0.8702666666666666 test_loss: 0.3769676937463719 test_accuracy: 0.8475\n",
      "Iteraions 278: train_loss: 0.31698815831555294 train_accuracy: 0.8707833333333334 test_loss: 0.3833768098188236 test_accuracy: 0.8483\n",
      "Iteraions 279: train_loss: 0.31553097929545326 train_accuracy: 0.8709833333333333 test_loss: 0.3796035562893904 test_accuracy: 0.8481\n",
      "Iteraions 280: train_loss: 0.3141443554166616 train_accuracy: 0.8718166666666667 test_loss: 0.3791935216003198 test_accuracy: 0.8474\n",
      "Iteraions 281: train_loss: 0.3144433191562571 train_accuracy: 0.8716 test_loss: 0.37409948007715554 test_accuracy: 0.8464\n",
      "Iteraions 282: train_loss: 0.3142000681445799 train_accuracy: 0.8710833333333333 test_loss: 0.37800082825432735 test_accuracy: 0.8478\n",
      "Iteraions 283: train_loss: 0.3116760291088442 train_accuracy: 0.8726166666666667 test_loss: 0.3743576913817525 test_accuracy: 0.8501\n",
      "Iteraions 284: train_loss: 0.31212404213536843 train_accuracy: 0.8732 test_loss: 0.37647680727517857 test_accuracy: 0.8507\n",
      "Iteraions 285: train_loss: 0.3138619899309888 train_accuracy: 0.8719666666666667 test_loss: 0.3748678364462589 test_accuracy: 0.8501\n",
      "Iteraions 286: train_loss: 0.3116056215547297 train_accuracy: 0.8730166666666667 test_loss: 0.3749511026712802 test_accuracy: 0.8516\n",
      "Iteraions 287: train_loss: 0.3117603799293288 train_accuracy: 0.8738 test_loss: 0.3763296455386881 test_accuracy: 0.8514\n",
      "Iteraions 288: train_loss: 0.31299591623730727 train_accuracy: 0.8721333333333333 test_loss: 0.3714840680493137 test_accuracy: 0.8515\n",
      "Iteraions 289: train_loss: 0.3119599098492685 train_accuracy: 0.8735333333333334 test_loss: 0.3753572214048914 test_accuracy: 0.851\n",
      "Iteraions 290: train_loss: 0.3111745083312875 train_accuracy: 0.8728 test_loss: 0.38148608728183253 test_accuracy: 0.8515\n",
      "Iteraions 291: train_loss: 0.30970729927185986 train_accuracy: 0.8733166666666666 test_loss: 0.3746238267490483 test_accuracy: 0.852\n",
      "Iteraions 292: train_loss: 0.30821623454744645 train_accuracy: 0.8743833333333333 test_loss: 0.3755084335255042 test_accuracy: 0.8503\n",
      "Iteraions 293: train_loss: 0.3074242359237551 train_accuracy: 0.8739833333333333 test_loss: 0.37609322233960657 test_accuracy: 0.8549\n",
      "Iteraions 294: train_loss: 0.30843304368607993 train_accuracy: 0.8746666666666667 test_loss: 0.3734516510745508 test_accuracy: 0.8506\n",
      "Iteraions 295: train_loss: 0.3067394496457525 train_accuracy: 0.8747666666666667 test_loss: 0.3737205473787924 test_accuracy: 0.8511\n",
      "Iteraions 296: train_loss: 0.30737676753018667 train_accuracy: 0.8747 test_loss: 0.3722154151532052 test_accuracy: 0.852\n",
      "Iteraions 297: train_loss: 0.30695063941831197 train_accuracy: 0.87625 test_loss: 0.3723176692251197 test_accuracy: 0.8501\n",
      "Iteraions 298: train_loss: 0.30677416773616034 train_accuracy: 0.8753833333333333 test_loss: 0.373395877799563 test_accuracy: 0.8523\n",
      "Iteraions 299: train_loss: 0.3064600511387124 train_accuracy: 0.8749 test_loss: 0.3780350152199806 test_accuracy: 0.8478\n",
      "Iteraions 300: train_loss: 0.3052895320739129 train_accuracy: 0.8763 test_loss: 0.3679293231634174 test_accuracy: 0.8515\n",
      "Iteraions 301: train_loss: 0.30490251892528525 train_accuracy: 0.8753166666666666 test_loss: 0.372415487961435 test_accuracy: 0.85\n",
      "Iteraions 302: train_loss: 0.30463930119886706 train_accuracy: 0.8761333333333333 test_loss: 0.3697031296175015 test_accuracy: 0.8496\n",
      "Iteraions 303: train_loss: 0.3026312060903779 train_accuracy: 0.8767333333333334 test_loss: 0.3725018536289588 test_accuracy: 0.8523\n",
      "Iteraions 304: train_loss: 0.30211314624699764 train_accuracy: 0.8766333333333334 test_loss: 0.3695166281920006 test_accuracy: 0.8535\n",
      "Iteraions 305: train_loss: 0.3031341240581939 train_accuracy: 0.8781166666666667 test_loss: 0.37353220071796406 test_accuracy: 0.851\n",
      "Iteraions 306: train_loss: 0.3029345517909705 train_accuracy: 0.8765333333333334 test_loss: 0.37150731284908295 test_accuracy: 0.8525\n",
      "Iteraions 307: train_loss: 0.3030453200538396 train_accuracy: 0.8778333333333334 test_loss: 0.3713113198069686 test_accuracy: 0.8508\n",
      "Iteraions 308: train_loss: 0.30003309463660327 train_accuracy: 0.8778 test_loss: 0.369241754885403 test_accuracy: 0.8544\n",
      "Iteraions 309: train_loss: 0.30111701102177135 train_accuracy: 0.8772166666666666 test_loss: 0.36492100424123225 test_accuracy: 0.8524\n",
      "Iteraions 310: train_loss: 0.3005734345362951 train_accuracy: 0.8778 test_loss: 0.3688763243420576 test_accuracy: 0.8538\n",
      "Iteraions 311: train_loss: 0.29956523045924816 train_accuracy: 0.8784666666666666 test_loss: 0.3779046383082185 test_accuracy: 0.8494\n",
      "Iteraions 312: train_loss: 0.2985430913809181 train_accuracy: 0.8784666666666666 test_loss: 0.3698392133794716 test_accuracy: 0.8553\n",
      "Iteraions 313: train_loss: 0.2992793508539026 train_accuracy: 0.87795 test_loss: 0.3708100808454569 test_accuracy: 0.8532\n",
      "Iteraions 314: train_loss: 0.2989721324917526 train_accuracy: 0.87865 test_loss: 0.3719375269834125 test_accuracy: 0.8563\n",
      "Iteraions 315: train_loss: 0.2983843536841022 train_accuracy: 0.8784833333333333 test_loss: 0.3668859939857912 test_accuracy: 0.8562\n",
      "Iteraions 316: train_loss: 0.2971832810245042 train_accuracy: 0.8795833333333334 test_loss: 0.36764312820068795 test_accuracy: 0.856\n",
      "Iteraions 317: train_loss: 0.29850030399329347 train_accuracy: 0.8779333333333333 test_loss: 0.36639158917497766 test_accuracy: 0.8517\n",
      "Iteraions 318: train_loss: 0.2983643121022829 train_accuracy: 0.8776333333333334 test_loss: 0.37437474217473865 test_accuracy: 0.8514\n",
      "Iteraions 319: train_loss: 0.2952670567181707 train_accuracy: 0.8798833333333334 test_loss: 0.3709370910521656 test_accuracy: 0.8533\n",
      "Iteraions 320: train_loss: 0.29724321356537436 train_accuracy: 0.87965 test_loss: 0.36857199492835135 test_accuracy: 0.8531\n",
      "Iteraions 321: train_loss: 0.2950074642952254 train_accuracy: 0.8796 test_loss: 0.3658303971270842 test_accuracy: 0.8514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 322: train_loss: 0.29383185030279235 train_accuracy: 0.8791333333333333 test_loss: 0.3683697287816086 test_accuracy: 0.8541\n",
      "Iteraions 323: train_loss: 0.29534746663842804 train_accuracy: 0.8807333333333334 test_loss: 0.3639518025223239 test_accuracy: 0.8561\n",
      "Iteraions 324: train_loss: 0.2955467080821351 train_accuracy: 0.8812333333333333 test_loss: 0.36767482268737406 test_accuracy: 0.8568\n",
      "Iteraions 325: train_loss: 0.29479994251525776 train_accuracy: 0.8806333333333334 test_loss: 0.3697796810864129 test_accuracy: 0.8578\n",
      "Iteraions 326: train_loss: 0.2937079799071544 train_accuracy: 0.88 test_loss: 0.36236874519675955 test_accuracy: 0.8578\n",
      "Iteraions 327: train_loss: 0.2929536032155618 train_accuracy: 0.8813 test_loss: 0.36626336817960425 test_accuracy: 0.8541\n",
      "Iteraions 328: train_loss: 0.2923473403171053 train_accuracy: 0.8806333333333334 test_loss: 0.3662013497167757 test_accuracy: 0.8566\n",
      "Iteraions 329: train_loss: 0.2940874312908893 train_accuracy: 0.8802666666666666 test_loss: 0.36512743874431824 test_accuracy: 0.8568\n",
      "Iteraions 330: train_loss: 0.293180994678782 train_accuracy: 0.8799 test_loss: 0.36683561200802467 test_accuracy: 0.8555\n",
      "Iteraions 331: train_loss: 0.29125109047638714 train_accuracy: 0.8822833333333333 test_loss: 0.3672290316929194 test_accuracy: 0.8573\n",
      "Iteraions 332: train_loss: 0.2909529341735188 train_accuracy: 0.8810333333333333 test_loss: 0.3660655337025719 test_accuracy: 0.8575\n",
      "Iteraions 333: train_loss: 0.29018535319557254 train_accuracy: 0.8825333333333333 test_loss: 0.36665533484001445 test_accuracy: 0.8578\n",
      "Iteraions 334: train_loss: 0.2908740238234095 train_accuracy: 0.8815 test_loss: 0.3665887681104312 test_accuracy: 0.8553\n",
      "Iteraions 335: train_loss: 0.29100984357226806 train_accuracy: 0.8812666666666666 test_loss: 0.36594123800057443 test_accuracy: 0.8552\n",
      "Iteraions 336: train_loss: 0.2908777242716814 train_accuracy: 0.8824833333333333 test_loss: 0.3618318621760603 test_accuracy: 0.8583\n",
      "Iteraions 337: train_loss: 0.28938389556469907 train_accuracy: 0.8831833333333333 test_loss: 0.36425010195406604 test_accuracy: 0.8557\n",
      "Iteraions 338: train_loss: 0.28763020091127656 train_accuracy: 0.8818666666666667 test_loss: 0.36131270153139555 test_accuracy: 0.8571\n",
      "Iteraions 339: train_loss: 0.28689080634091907 train_accuracy: 0.8822833333333333 test_loss: 0.36834787144847 test_accuracy: 0.8582\n",
      "Iteraions 340: train_loss: 0.2876866413816779 train_accuracy: 0.8827 test_loss: 0.36591877819522284 test_accuracy: 0.8566\n",
      "Iteraions 341: train_loss: 0.2887062104083084 train_accuracy: 0.88175 test_loss: 0.36410984397630836 test_accuracy: 0.8541\n",
      "Iteraions 342: train_loss: 0.28737575664386866 train_accuracy: 0.8821666666666667 test_loss: 0.363721778545845 test_accuracy: 0.8587\n",
      "Iteraions 343: train_loss: 0.2858363273132972 train_accuracy: 0.8842833333333333 test_loss: 0.362359596858634 test_accuracy: 0.8575\n",
      "Iteraions 344: train_loss: 0.28586073203092904 train_accuracy: 0.8843333333333333 test_loss: 0.3686676862904635 test_accuracy: 0.8549\n",
      "Iteraions 345: train_loss: 0.28536201349381024 train_accuracy: 0.8848 test_loss: 0.3647164134683217 test_accuracy: 0.8576\n",
      "Iteraions 346: train_loss: 0.2852390204410426 train_accuracy: 0.8842166666666667 test_loss: 0.3640769889977688 test_accuracy: 0.8587\n",
      "Iteraions 347: train_loss: 0.2859329388413645 train_accuracy: 0.8842166666666667 test_loss: 0.3615340057691728 test_accuracy: 0.8596\n",
      "Iteraions 348: train_loss: 0.2847057386686977 train_accuracy: 0.88435 test_loss: 0.36028885323377013 test_accuracy: 0.8589\n",
      "Iteraions 349: train_loss: 0.28518319226063454 train_accuracy: 0.8846666666666667 test_loss: 0.3600986136892378 test_accuracy: 0.8589\n",
      "Iteraions 350: train_loss: 0.284056847111062 train_accuracy: 0.8844333333333333 test_loss: 0.36383630599932926 test_accuracy: 0.8549\n",
      "Iteraions 351: train_loss: 0.2837553242380015 train_accuracy: 0.8840666666666667 test_loss: 0.3587158608447753 test_accuracy: 0.8628\n",
      "Iteraions 352: train_loss: 0.2832766605051331 train_accuracy: 0.8846333333333334 test_loss: 0.3628175249210981 test_accuracy: 0.8568\n",
      "Iteraions 353: train_loss: 0.28262819310067827 train_accuracy: 0.8857166666666667 test_loss: 0.360064189213752 test_accuracy: 0.8597\n",
      "Iteraions 354: train_loss: 0.28481309607114513 train_accuracy: 0.88415 test_loss: 0.3635162441017533 test_accuracy: 0.8588\n",
      "Iteraions 355: train_loss: 0.28225300435751927 train_accuracy: 0.8852333333333333 test_loss: 0.3607853588336 test_accuracy: 0.8613\n",
      "Iteraions 356: train_loss: 0.28064833442029696 train_accuracy: 0.8860333333333333 test_loss: 0.36324888982399683 test_accuracy: 0.859\n",
      "Iteraions 357: train_loss: 0.2798288559507522 train_accuracy: 0.8867 test_loss: 0.36136460164007883 test_accuracy: 0.8594\n",
      "Iteraions 358: train_loss: 0.28012281670679434 train_accuracy: 0.8864 test_loss: 0.3541437498081919 test_accuracy: 0.8632\n",
      "Iteraions 359: train_loss: 0.28167913830011954 train_accuracy: 0.8863333333333333 test_loss: 0.36110449497146174 test_accuracy: 0.8588\n",
      "Iteraions 360: train_loss: 0.2814202375058444 train_accuracy: 0.8858833333333334 test_loss: 0.3627597047749293 test_accuracy: 0.8602\n",
      "Iteraions 361: train_loss: 0.2803580736407393 train_accuracy: 0.8872 test_loss: 0.3635975843684661 test_accuracy: 0.8609\n",
      "Iteraions 362: train_loss: 0.2793623245581422 train_accuracy: 0.8874166666666666 test_loss: 0.36456508252502623 test_accuracy: 0.8564\n",
      "Iteraions 363: train_loss: 0.2791241915238536 train_accuracy: 0.8877833333333334 test_loss: 0.3644452941836136 test_accuracy: 0.8607\n",
      "Iteraions 364: train_loss: 0.2799704480338025 train_accuracy: 0.888 test_loss: 0.3552687025418084 test_accuracy: 0.8606\n",
      "Iteraions 365: train_loss: 0.2785872254557581 train_accuracy: 0.8873333333333333 test_loss: 0.3616330853571211 test_accuracy: 0.8579\n",
      "Iteraions 366: train_loss: 0.27767855676795916 train_accuracy: 0.8868 test_loss: 0.3601235531254108 test_accuracy: 0.8579\n",
      "Iteraions 367: train_loss: 0.2774386609632162 train_accuracy: 0.88785 test_loss: 0.3588645400055161 test_accuracy: 0.8597\n",
      "Iteraions 368: train_loss: 0.2771563816883359 train_accuracy: 0.8868666666666667 test_loss: 0.35854103612250554 test_accuracy: 0.8611\n",
      "Iteraions 369: train_loss: 0.2760300279411141 train_accuracy: 0.8877 test_loss: 0.35789863578477077 test_accuracy: 0.8604\n",
      "Iteraions 370: train_loss: 0.2781935687022923 train_accuracy: 0.8865 test_loss: 0.3598066932516813 test_accuracy: 0.8615\n",
      "Iteraions 371: train_loss: 0.2766106055500134 train_accuracy: 0.8878 test_loss: 0.3590341566087393 test_accuracy: 0.8598\n",
      "Iteraions 372: train_loss: 0.2766818012013654 train_accuracy: 0.8872666666666666 test_loss: 0.356622781711608 test_accuracy: 0.8603\n",
      "Iteraions 373: train_loss: 0.27588346576409956 train_accuracy: 0.8876333333333334 test_loss: 0.3601873018765034 test_accuracy: 0.8585\n",
      "Iteraions 374: train_loss: 0.2748123727724692 train_accuracy: 0.8885 test_loss: 0.35778104143810807 test_accuracy: 0.8619\n",
      "Iteraions 375: train_loss: 0.27489280525960086 train_accuracy: 0.8877833333333334 test_loss: 0.35808334742367665 test_accuracy: 0.862\n",
      "Iteraions 376: train_loss: 0.2749306449653322 train_accuracy: 0.8879333333333334 test_loss: 0.35753597034135776 test_accuracy: 0.8598\n",
      "Iteraions 377: train_loss: 0.27468790030742246 train_accuracy: 0.88845 test_loss: 0.35815281428246054 test_accuracy: 0.861\n",
      "Iteraions 378: train_loss: 0.27439549912591166 train_accuracy: 0.8878333333333334 test_loss: 0.3578895106817134 test_accuracy: 0.8616\n",
      "Iteraions 379: train_loss: 0.275095191428283 train_accuracy: 0.889 test_loss: 0.35801731641781015 test_accuracy: 0.8602\n",
      "Iteraions 380: train_loss: 0.2729032104850581 train_accuracy: 0.8891833333333333 test_loss: 0.3587357689736336 test_accuracy: 0.8625\n",
      "Iteraions 381: train_loss: 0.27475124807783613 train_accuracy: 0.8882 test_loss: 0.3577633469953123 test_accuracy: 0.8637\n",
      "Iteraions 382: train_loss: 0.27081028403609236 train_accuracy: 0.88985 test_loss: 0.3587456567556497 test_accuracy: 0.8616\n",
      "Iteraions 383: train_loss: 0.2720068336147311 train_accuracy: 0.8900666666666667 test_loss: 0.35505239585159554 test_accuracy: 0.8648\n",
      "Iteraions 384: train_loss: 0.2729255699976809 train_accuracy: 0.8900333333333333 test_loss: 0.3566313708741604 test_accuracy: 0.865\n",
      "Iteraions 385: train_loss: 0.27093811066967693 train_accuracy: 0.8906 test_loss: 0.3513365173216136 test_accuracy: 0.8676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 386: train_loss: 0.271112226835257 train_accuracy: 0.88965 test_loss: 0.356736996734632 test_accuracy: 0.8662\n",
      "Iteraions 387: train_loss: 0.27053144792286604 train_accuracy: 0.8902 test_loss: 0.3571564191794669 test_accuracy: 0.8623\n",
      "Iteraions 388: train_loss: 0.2691751110276021 train_accuracy: 0.8912833333333333 test_loss: 0.3587968694180108 test_accuracy: 0.8633\n",
      "Iteraions 389: train_loss: 0.2710668679356659 train_accuracy: 0.8901166666666667 test_loss: 0.35748448355602674 test_accuracy: 0.8636\n",
      "Iteraions 390: train_loss: 0.26989010698285093 train_accuracy: 0.8909333333333334 test_loss: 0.3571798666891923 test_accuracy: 0.8621\n",
      "Iteraions 391: train_loss: 0.26970136763570657 train_accuracy: 0.8907166666666667 test_loss: 0.3606232267493478 test_accuracy: 0.8593\n",
      "Iteraions 392: train_loss: 0.2695696481161361 train_accuracy: 0.8898333333333334 test_loss: 0.35978890836858124 test_accuracy: 0.8622\n",
      "Iteraions 393: train_loss: 0.2690226026715687 train_accuracy: 0.89125 test_loss: 0.3528279710511736 test_accuracy: 0.8646\n",
      "Iteraions 394: train_loss: 0.2695326288387384 train_accuracy: 0.8915833333333333 test_loss: 0.35329187505618903 test_accuracy: 0.8662\n",
      "Iteraions 395: train_loss: 0.26914904052821687 train_accuracy: 0.8919 test_loss: 0.3550865323908292 test_accuracy: 0.8624\n",
      "Iteraions 396: train_loss: 0.26677507531581873 train_accuracy: 0.8915833333333333 test_loss: 0.3595667312816387 test_accuracy: 0.8612\n",
      "Iteraions 397: train_loss: 0.26838329266334987 train_accuracy: 0.8905166666666666 test_loss: 0.360176592677726 test_accuracy: 0.8621\n",
      "Iteraions 398: train_loss: 0.2664573564135833 train_accuracy: 0.8908166666666667 test_loss: 0.35344712031068376 test_accuracy: 0.8655\n",
      "Iteraions 399: train_loss: 0.2668393102857536 train_accuracy: 0.8917666666666667 test_loss: 0.35452164699306843 test_accuracy: 0.8625\n",
      "Iteraions 400: train_loss: 0.26569295426576106 train_accuracy: 0.8937666666666667 test_loss: 0.35741105369249826 test_accuracy: 0.8625\n",
      "Iteraions 401: train_loss: 0.2674282561110559 train_accuracy: 0.8912833333333333 test_loss: 0.34983138079088366 test_accuracy: 0.8613\n",
      "Iteraions 402: train_loss: 0.2649812874539237 train_accuracy: 0.8920166666666667 test_loss: 0.3531898403594754 test_accuracy: 0.8626\n",
      "Iteraions 403: train_loss: 0.26601666941939917 train_accuracy: 0.8919333333333334 test_loss: 0.35888253149191746 test_accuracy: 0.8603\n",
      "Iteraions 404: train_loss: 0.264704675324556 train_accuracy: 0.8928333333333334 test_loss: 0.35879741375947 test_accuracy: 0.8622\n",
      "Iteraions 405: train_loss: 0.26597997424279485 train_accuracy: 0.8910166666666667 test_loss: 0.35583749120565483 test_accuracy: 0.8621\n",
      "Iteraions 406: train_loss: 0.26340038072259575 train_accuracy: 0.8936 test_loss: 0.35377565455104065 test_accuracy: 0.8651\n",
      "Iteraions 407: train_loss: 0.26454151254357083 train_accuracy: 0.89285 test_loss: 0.3560892105490625 test_accuracy: 0.8645\n",
      "Iteraions 408: train_loss: 0.2659420076618366 train_accuracy: 0.89165 test_loss: 0.35569458148841837 test_accuracy: 0.8617\n",
      "Iteraions 409: train_loss: 0.2623526684533274 train_accuracy: 0.89365 test_loss: 0.3563487852261203 test_accuracy: 0.8619\n",
      "Iteraions 410: train_loss: 0.26364777642062304 train_accuracy: 0.8925333333333333 test_loss: 0.35252856099500873 test_accuracy: 0.864\n",
      "Iteraions 411: train_loss: 0.26233442908184684 train_accuracy: 0.8937666666666667 test_loss: 0.3493217252590128 test_accuracy: 0.8639\n",
      "Iteraions 412: train_loss: 0.2630174362724879 train_accuracy: 0.8921166666666667 test_loss: 0.35251930316936575 test_accuracy: 0.8624\n",
      "Iteraions 413: train_loss: 0.262322543745267 train_accuracy: 0.89435 test_loss: 0.35885643711769916 test_accuracy: 0.8639\n",
      "Iteraions 414: train_loss: 0.26310699735158155 train_accuracy: 0.8935333333333333 test_loss: 0.35373501326559226 test_accuracy: 0.8643\n",
      "Iteraions 415: train_loss: 0.26202855416635523 train_accuracy: 0.8949833333333334 test_loss: 0.35163881839358 test_accuracy: 0.8661\n",
      "Iteraions 416: train_loss: 0.2633390815138368 train_accuracy: 0.8923833333333333 test_loss: 0.3540107499574358 test_accuracy: 0.8631\n",
      "Iteraions 417: train_loss: 0.2617157238577749 train_accuracy: 0.8932666666666667 test_loss: 0.35590204973309697 test_accuracy: 0.8641\n",
      "Iteraions 418: train_loss: 0.2606055952669139 train_accuracy: 0.8939833333333334 test_loss: 0.3561806662312426 test_accuracy: 0.8644\n",
      "Iteraions 419: train_loss: 0.2609702357230388 train_accuracy: 0.8940833333333333 test_loss: 0.35404772034327664 test_accuracy: 0.8651\n",
      "Iteraions 420: train_loss: 0.26088864477759793 train_accuracy: 0.8941333333333333 test_loss: 0.35348617442537045 test_accuracy: 0.866\n",
      "Iteraions 421: train_loss: 0.25969501848634047 train_accuracy: 0.8947833333333334 test_loss: 0.3541213451814605 test_accuracy: 0.8649\n",
      "Iteraions 422: train_loss: 0.2611696079862657 train_accuracy: 0.8939333333333334 test_loss: 0.35087763924115345 test_accuracy: 0.8681\n",
      "Iteraions 423: train_loss: 0.25945360730727257 train_accuracy: 0.8944833333333333 test_loss: 0.3531803323888274 test_accuracy: 0.8661\n",
      "Iteraions 424: train_loss: 0.2597184537788168 train_accuracy: 0.8946 test_loss: 0.3580214700054606 test_accuracy: 0.8649\n",
      "Iteraions 425: train_loss: 0.2602705245489395 train_accuracy: 0.8940666666666667 test_loss: 0.3540314086021871 test_accuracy: 0.8661\n",
      "Iteraions 426: train_loss: 0.25938224872278903 train_accuracy: 0.89485 test_loss: 0.35310305701756645 test_accuracy: 0.8645\n",
      "Iteraions 427: train_loss: 0.25942762522535096 train_accuracy: 0.8949666666666667 test_loss: 0.3520637050859457 test_accuracy: 0.8637\n",
      "Iteraions 428: train_loss: 0.2578053361674803 train_accuracy: 0.8943 test_loss: 0.3560590327736152 test_accuracy: 0.8654\n",
      "Iteraions 429: train_loss: 0.2580999814870887 train_accuracy: 0.8960333333333333 test_loss: 0.3507164270063105 test_accuracy: 0.8651\n",
      "Iteraions 430: train_loss: 0.2561433830388833 train_accuracy: 0.8966 test_loss: 0.35204559263208685 test_accuracy: 0.8646\n",
      "Iteraions 431: train_loss: 0.25794045598362997 train_accuracy: 0.8965 test_loss: 0.35407758868836114 test_accuracy: 0.8672\n",
      "Iteraions 432: train_loss: 0.25611418456139756 train_accuracy: 0.8960333333333333 test_loss: 0.35392376269108583 test_accuracy: 0.8653\n",
      "Iteraions 433: train_loss: 0.2562914646840682 train_accuracy: 0.8955 test_loss: 0.3537681883907754 test_accuracy: 0.8649\n",
      "Iteraions 434: train_loss: 0.255807964532435 train_accuracy: 0.8958 test_loss: 0.3496677976599458 test_accuracy: 0.8651\n",
      "Iteraions 435: train_loss: 0.255129970473853 train_accuracy: 0.8965333333333333 test_loss: 0.3541100182430381 test_accuracy: 0.8668\n",
      "Iteraions 436: train_loss: 0.2538049376435879 train_accuracy: 0.8983 test_loss: 0.35165396382876535 test_accuracy: 0.8636\n",
      "Iteraions 437: train_loss: 0.25433370192558297 train_accuracy: 0.8966 test_loss: 0.3559933418991348 test_accuracy: 0.8641\n",
      "Iteraions 438: train_loss: 0.25499361646374097 train_accuracy: 0.8966166666666666 test_loss: 0.3526883879707888 test_accuracy: 0.8648\n",
      "Iteraions 439: train_loss: 0.2538169465281942 train_accuracy: 0.8972333333333333 test_loss: 0.3481372082234203 test_accuracy: 0.8659\n",
      "Iteraions 440: train_loss: 0.25544680044678725 train_accuracy: 0.8966 test_loss: 0.3560146061526243 test_accuracy: 0.8649\n",
      "Iteraions 441: train_loss: 0.25324856326298856 train_accuracy: 0.8978 test_loss: 0.3461356413384662 test_accuracy: 0.8661\n",
      "Iteraions 442: train_loss: 0.25381600903491114 train_accuracy: 0.8969666666666667 test_loss: 0.3497140922876616 test_accuracy: 0.8662\n",
      "Iteraions 443: train_loss: 0.2539716576548269 train_accuracy: 0.8971833333333333 test_loss: 0.3491389183786962 test_accuracy: 0.8675\n",
      "Iteraions 444: train_loss: 0.2521847752702247 train_accuracy: 0.8973333333333333 test_loss: 0.3528193651212078 test_accuracy: 0.866\n",
      "Iteraions 445: train_loss: 0.25285638577678754 train_accuracy: 0.8981666666666667 test_loss: 0.35428217741075946 test_accuracy: 0.8667\n",
      "Iteraions 446: train_loss: 0.25287375011590596 train_accuracy: 0.89725 test_loss: 0.35380569435212583 test_accuracy: 0.8676\n",
      "Iteraions 447: train_loss: 0.25069462981111135 train_accuracy: 0.8986166666666666 test_loss: 0.35535506328279226 test_accuracy: 0.8647\n",
      "Iteraions 448: train_loss: 0.2509869521188161 train_accuracy: 0.8984166666666666 test_loss: 0.3514258806562577 test_accuracy: 0.8652\n",
      "Iteraions 449: train_loss: 0.2513577576698395 train_accuracy: 0.8974166666666666 test_loss: 0.3525279614464309 test_accuracy: 0.8669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 450: train_loss: 0.24999428759705977 train_accuracy: 0.89925 test_loss: 0.3500007043408287 test_accuracy: 0.8646\n",
      "Iteraions 451: train_loss: 0.2516017186841494 train_accuracy: 0.8987166666666667 test_loss: 0.35083166221417944 test_accuracy: 0.868\n",
      "Iteraions 452: train_loss: 0.25160811491875573 train_accuracy: 0.8980833333333333 test_loss: 0.3451726353402056 test_accuracy: 0.8685\n",
      "Iteraions 453: train_loss: 0.25033269637149247 train_accuracy: 0.8996666666666666 test_loss: 0.34682130357180824 test_accuracy: 0.8676\n",
      "Iteraions 454: train_loss: 0.2499590071478659 train_accuracy: 0.8988 test_loss: 0.35516325481565303 test_accuracy: 0.8657\n",
      "Iteraions 455: train_loss: 0.2517220887648648 train_accuracy: 0.8975 test_loss: 0.35766122542719714 test_accuracy: 0.8648\n",
      "Iteraions 456: train_loss: 0.24874672357183092 train_accuracy: 0.89875 test_loss: 0.3568627388760059 test_accuracy: 0.8634\n",
      "Iteraions 457: train_loss: 0.24908329153742367 train_accuracy: 0.89995 test_loss: 0.35565866963118925 test_accuracy: 0.8686\n",
      "Iteraions 458: train_loss: 0.24924953067052574 train_accuracy: 0.8997333333333334 test_loss: 0.35437037811099364 test_accuracy: 0.8666\n",
      "Iteraions 459: train_loss: 0.24852055035642673 train_accuracy: 0.8999 test_loss: 0.35712975506374967 test_accuracy: 0.8646\n",
      "Iteraions 460: train_loss: 0.24575781459002843 train_accuracy: 0.8988833333333334 test_loss: 0.34881762650027887 test_accuracy: 0.8672\n",
      "Iteraions 461: train_loss: 0.24898524239415457 train_accuracy: 0.9000333333333334 test_loss: 0.3506051845426551 test_accuracy: 0.8664\n",
      "Iteraions 462: train_loss: 0.24960617502870577 train_accuracy: 0.89845 test_loss: 0.34968578285116086 test_accuracy: 0.8689\n",
      "Iteraions 463: train_loss: 0.24718213874038078 train_accuracy: 0.9003833333333333 test_loss: 0.3539077767239009 test_accuracy: 0.864\n",
      "Iteraions 464: train_loss: 0.2471645521522186 train_accuracy: 0.9006666666666666 test_loss: 0.34805450949460365 test_accuracy: 0.8716\n",
      "Iteraions 465: train_loss: 0.24616198130269315 train_accuracy: 0.9005666666666666 test_loss: 0.3550545154444309 test_accuracy: 0.8674\n",
      "Iteraions 466: train_loss: 0.24656882565504334 train_accuracy: 0.90005 test_loss: 0.3539697379563331 test_accuracy: 0.8636\n",
      "Iteraions 467: train_loss: 0.24636113864769155 train_accuracy: 0.8991166666666667 test_loss: 0.35185397524651646 test_accuracy: 0.8666\n",
      "Iteraions 468: train_loss: 0.24509587658789309 train_accuracy: 0.89955 test_loss: 0.3528996106019164 test_accuracy: 0.8694\n",
      "Iteraions 469: train_loss: 0.24605367152541094 train_accuracy: 0.90135 test_loss: 0.35167603564172706 test_accuracy: 0.8651\n",
      "Iteraions 470: train_loss: 0.24477734498909293 train_accuracy: 0.9006666666666666 test_loss: 0.3478984379310282 test_accuracy: 0.8681\n",
      "Iteraions 471: train_loss: 0.24691924982522231 train_accuracy: 0.9005333333333333 test_loss: 0.34629459943141816 test_accuracy: 0.8684\n",
      "Iteraions 472: train_loss: 0.24456208203250257 train_accuracy: 0.9009 test_loss: 0.3549928868135716 test_accuracy: 0.8681\n",
      "Iteraions 473: train_loss: 0.24278451754655206 train_accuracy: 0.9018333333333334 test_loss: 0.3492689778787808 test_accuracy: 0.8669\n",
      "Iteraions 474: train_loss: 0.24537151767963503 train_accuracy: 0.90015 test_loss: 0.3521505115118921 test_accuracy: 0.8663\n",
      "Iteraions 475: train_loss: 0.24409584255507263 train_accuracy: 0.9012 test_loss: 0.35448869993184334 test_accuracy: 0.8693\n",
      "Iteraions 476: train_loss: 0.244819477526216 train_accuracy: 0.9012166666666667 test_loss: 0.3511865072032693 test_accuracy: 0.8688\n",
      "Iteraions 477: train_loss: 0.24390683346855596 train_accuracy: 0.90075 test_loss: 0.3456114970229489 test_accuracy: 0.8703\n",
      "Iteraions 478: train_loss: 0.24357656249076892 train_accuracy: 0.9014333333333333 test_loss: 0.3482157375173196 test_accuracy: 0.8712\n",
      "Iteraions 479: train_loss: 0.24241382830555788 train_accuracy: 0.9020833333333333 test_loss: 0.35010130411720736 test_accuracy: 0.87\n",
      "Iteraions 480: train_loss: 0.2426278017778523 train_accuracy: 0.90115 test_loss: 0.3468379143785171 test_accuracy: 0.8663\n",
      "Iteraions 481: train_loss: 0.2435168831277646 train_accuracy: 0.9017 test_loss: 0.3552746029155387 test_accuracy: 0.8659\n",
      "Iteraions 482: train_loss: 0.2421992449988123 train_accuracy: 0.9014666666666666 test_loss: 0.3533931632368355 test_accuracy: 0.8663\n",
      "Iteraions 483: train_loss: 0.2421845001916517 train_accuracy: 0.9024166666666666 test_loss: 0.34612401945675153 test_accuracy: 0.8683\n",
      "Iteraions 484: train_loss: 0.2417709152559059 train_accuracy: 0.90245 test_loss: 0.34717789859763715 test_accuracy: 0.8673\n",
      "Iteraions 485: train_loss: 0.24256387514715388 train_accuracy: 0.9025166666666666 test_loss: 0.3486452632833717 test_accuracy: 0.8685\n",
      "Iteraions 486: train_loss: 0.24255919745670734 train_accuracy: 0.9005166666666666 test_loss: 0.3478691819450436 test_accuracy: 0.8684\n",
      "Iteraions 487: train_loss: 0.23976315380243546 train_accuracy: 0.9021333333333333 test_loss: 0.35019756044961725 test_accuracy: 0.8682\n",
      "Iteraions 488: train_loss: 0.23998986072927164 train_accuracy: 0.9027166666666666 test_loss: 0.35105791772045675 test_accuracy: 0.8684\n",
      "Iteraions 489: train_loss: 0.23975523897699166 train_accuracy: 0.9035833333333333 test_loss: 0.35831256619195956 test_accuracy: 0.8682\n",
      "Iteraions 490: train_loss: 0.2410212409465599 train_accuracy: 0.9029333333333334 test_loss: 0.3474172414398891 test_accuracy: 0.8701\n",
      "Iteraions 491: train_loss: 0.2410898360158484 train_accuracy: 0.9014166666666666 test_loss: 0.34513269778512884 test_accuracy: 0.87\n",
      "Iteraions 492: train_loss: 0.24038927232973206 train_accuracy: 0.9036 test_loss: 0.3480763297691343 test_accuracy: 0.8684\n",
      "Iteraions 493: train_loss: 0.24057175579276857 train_accuracy: 0.90245 test_loss: 0.3526168235886673 test_accuracy: 0.8648\n",
      "Iteraions 494: train_loss: 0.2399446946110816 train_accuracy: 0.90255 test_loss: 0.34715843713369976 test_accuracy: 0.8678\n",
      "Iteraions 495: train_loss: 0.24016080411108456 train_accuracy: 0.90255 test_loss: 0.3478885368857624 test_accuracy: 0.8693\n",
      "Iteraions 496: train_loss: 0.2398062623607352 train_accuracy: 0.9042 test_loss: 0.3512628972259561 test_accuracy: 0.8679\n",
      "Iteraions 497: train_loss: 0.23872903317711847 train_accuracy: 0.9035833333333333 test_loss: 0.34827929246133715 test_accuracy: 0.8699\n",
      "Iteraions 498: train_loss: 0.23761719989808092 train_accuracy: 0.9042 test_loss: 0.35460357069004295 test_accuracy: 0.869\n",
      "Iteraions 499: train_loss: 0.24064048573840607 train_accuracy: 0.9037 test_loss: 0.3492252951168178 test_accuracy: 0.8692\n",
      "Iteraions 500: train_loss: 0.23861843254788 train_accuracy: 0.9026166666666666 test_loss: 0.34534883452126214 test_accuracy: 0.8692\n",
      "Iteraions 501: train_loss: 0.2369539239749069 train_accuracy: 0.90415 test_loss: 0.35202481208602293 test_accuracy: 0.8668\n",
      "Iteraions 502: train_loss: 0.2363157168903468 train_accuracy: 0.9043333333333333 test_loss: 0.34999408572517804 test_accuracy: 0.8703\n",
      "Iteraions 503: train_loss: 0.23670519820411734 train_accuracy: 0.9039 test_loss: 0.3514292818767871 test_accuracy: 0.8673\n",
      "Iteraions 504: train_loss: 0.23472554392813091 train_accuracy: 0.9050833333333334 test_loss: 0.34851223042474405 test_accuracy: 0.8681\n",
      "Iteraions 505: train_loss: 0.23673860346107123 train_accuracy: 0.9048666666666667 test_loss: 0.3451200067966876 test_accuracy: 0.872\n",
      "Iteraions 506: train_loss: 0.23499720363748738 train_accuracy: 0.9049666666666667 test_loss: 0.34656684245335195 test_accuracy: 0.8687\n",
      "Iteraions 507: train_loss: 0.23669543995795975 train_accuracy: 0.9047166666666666 test_loss: 0.34796954977304784 test_accuracy: 0.8692\n",
      "Iteraions 508: train_loss: 0.23447223579049703 train_accuracy: 0.90615 test_loss: 0.35198132668969906 test_accuracy: 0.8658\n",
      "Iteraions 509: train_loss: 0.2355059107206914 train_accuracy: 0.9057 test_loss: 0.34757333552399283 test_accuracy: 0.867\n",
      "Iteraions 510: train_loss: 0.23327667803136132 train_accuracy: 0.9062666666666667 test_loss: 0.3469608027516617 test_accuracy: 0.869\n",
      "Iteraions 511: train_loss: 0.23483507090872183 train_accuracy: 0.9051333333333333 test_loss: 0.34803995952727823 test_accuracy: 0.8693\n",
      "Iteraions 512: train_loss: 0.2344502455905106 train_accuracy: 0.9058833333333334 test_loss: 0.3454765441032892 test_accuracy: 0.8715\n",
      "Iteraions 513: train_loss: 0.2360557948626371 train_accuracy: 0.9044666666666666 test_loss: 0.3465308336760571 test_accuracy: 0.8688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 514: train_loss: 0.23304604213723132 train_accuracy: 0.9054 test_loss: 0.35304615542119255 test_accuracy: 0.8662\n",
      "Iteraions 515: train_loss: 0.23272817291706338 train_accuracy: 0.9065666666666666 test_loss: 0.349263235813956 test_accuracy: 0.8691\n",
      "Iteraions 516: train_loss: 0.23274144407841443 train_accuracy: 0.9062333333333333 test_loss: 0.35117568680957434 test_accuracy: 0.8683\n",
      "Iteraions 517: train_loss: 0.2336811682929298 train_accuracy: 0.9060333333333334 test_loss: 0.34753060412524617 test_accuracy: 0.8729\n",
      "Iteraions 518: train_loss: 0.23303305666016377 train_accuracy: 0.905 test_loss: 0.35285636234125906 test_accuracy: 0.8707\n",
      "Iteraions 519: train_loss: 0.23437433198321656 train_accuracy: 0.9049333333333334 test_loss: 0.349680534515035 test_accuracy: 0.8684\n",
      "Iteraions 520: train_loss: 0.23199299022204495 train_accuracy: 0.9072 test_loss: 0.34974981185381926 test_accuracy: 0.868\n",
      "Iteraions 521: train_loss: 0.2317588625353598 train_accuracy: 0.90705 test_loss: 0.3515068725541073 test_accuracy: 0.8705\n",
      "Iteraions 522: train_loss: 0.23140943667624694 train_accuracy: 0.9068 test_loss: 0.34770510836169577 test_accuracy: 0.8695\n",
      "Iteraions 523: train_loss: 0.231964157437081 train_accuracy: 0.9059166666666667 test_loss: 0.34274355994456857 test_accuracy: 0.8715\n",
      "Iteraions 524: train_loss: 0.2296070387440733 train_accuracy: 0.9075666666666666 test_loss: 0.3511604018024279 test_accuracy: 0.869\n",
      "Iteraions 525: train_loss: 0.2300130493275991 train_accuracy: 0.9074666666666666 test_loss: 0.34723696123695935 test_accuracy: 0.8707\n",
      "Iteraions 526: train_loss: 0.2315216681857689 train_accuracy: 0.9066166666666666 test_loss: 0.344092941613051 test_accuracy: 0.8717\n",
      "Iteraions 527: train_loss: 0.2308782426797076 train_accuracy: 0.9070166666666667 test_loss: 0.34902788384436545 test_accuracy: 0.8719\n",
      "Iteraions 528: train_loss: 0.22850529459166893 train_accuracy: 0.9078 test_loss: 0.34694973293394343 test_accuracy: 0.8731\n",
      "Iteraions 529: train_loss: 0.23106083506434716 train_accuracy: 0.9070166666666667 test_loss: 0.34998223970692227 test_accuracy: 0.8702\n",
      "Iteraions 530: train_loss: 0.23294350573587744 train_accuracy: 0.9053833333333333 test_loss: 0.3526662422742186 test_accuracy: 0.87\n",
      "Iteraions 531: train_loss: 0.2327174345151711 train_accuracy: 0.9049833333333334 test_loss: 0.3508485235937548 test_accuracy: 0.8664\n",
      "Iteraions 532: train_loss: 0.22995345402670375 train_accuracy: 0.9073333333333333 test_loss: 0.3503400145420952 test_accuracy: 0.8655\n",
      "Iteraions 533: train_loss: 0.22729307728925802 train_accuracy: 0.9086166666666666 test_loss: 0.34394783124013156 test_accuracy: 0.8711\n",
      "Iteraions 534: train_loss: 0.2302757152000356 train_accuracy: 0.9068 test_loss: 0.3529719273315964 test_accuracy: 0.8695\n",
      "Iteraions 535: train_loss: 0.23282757979004298 train_accuracy: 0.90635 test_loss: 0.347863902080374 test_accuracy: 0.8696\n",
      "Iteraions 536: train_loss: 0.2304819159503754 train_accuracy: 0.9072 test_loss: 0.3533086528563883 test_accuracy: 0.8685\n",
      "Iteraions 537: train_loss: 0.22919366199037416 train_accuracy: 0.9079666666666667 test_loss: 0.34964608154877985 test_accuracy: 0.873\n",
      "Iteraions 538: train_loss: 0.22698353826546894 train_accuracy: 0.9079833333333334 test_loss: 0.351071241026398 test_accuracy: 0.8717\n",
      "Iteraions 539: train_loss: 0.22736559907890494 train_accuracy: 0.9086166666666666 test_loss: 0.3535495454353385 test_accuracy: 0.8699\n",
      "Iteraions 540: train_loss: 0.22728887217153693 train_accuracy: 0.9092 test_loss: 0.35095332124924944 test_accuracy: 0.8708\n",
      "Iteraions 541: train_loss: 0.22782529980080726 train_accuracy: 0.90805 test_loss: 0.35293635081398583 test_accuracy: 0.872\n",
      "Iteraions 542: train_loss: 0.22824853954315188 train_accuracy: 0.9084166666666667 test_loss: 0.3524830672940166 test_accuracy: 0.8659\n",
      "Iteraions 543: train_loss: 0.2257610337588332 train_accuracy: 0.9077833333333334 test_loss: 0.35329006345861663 test_accuracy: 0.8678\n",
      "Iteraions 544: train_loss: 0.22685482011947994 train_accuracy: 0.9084666666666666 test_loss: 0.35358505035406934 test_accuracy: 0.8706\n",
      "Iteraions 545: train_loss: 0.2269130394648174 train_accuracy: 0.9080833333333334 test_loss: 0.3453952260173181 test_accuracy: 0.8695\n",
      "Iteraions 546: train_loss: 0.22766203581919242 train_accuracy: 0.9084333333333333 test_loss: 0.3479386006280612 test_accuracy: 0.8717\n",
      "Iteraions 547: train_loss: 0.2248962494675204 train_accuracy: 0.9088166666666667 test_loss: 0.35197867345853096 test_accuracy: 0.8682\n",
      "Iteraions 548: train_loss: 0.22598385549254665 train_accuracy: 0.9081666666666667 test_loss: 0.3440897264896543 test_accuracy: 0.8719\n",
      "Iteraions 549: train_loss: 0.22769843063387304 train_accuracy: 0.90815 test_loss: 0.35205490427667735 test_accuracy: 0.8722\n",
      "Iteraions 550: train_loss: 0.22475166132715274 train_accuracy: 0.90875 test_loss: 0.3480414596823083 test_accuracy: 0.8678\n",
      "Iteraions 551: train_loss: 0.22492307470681056 train_accuracy: 0.9088166666666667 test_loss: 0.3512345500708324 test_accuracy: 0.8715\n",
      "Iteraions 552: train_loss: 0.22618903968570314 train_accuracy: 0.90875 test_loss: 0.35184367451458126 test_accuracy: 0.8707\n",
      "Iteraions 553: train_loss: 0.2251721504678152 train_accuracy: 0.9089 test_loss: 0.3490709707039585 test_accuracy: 0.8684\n",
      "Iteraions 554: train_loss: 0.22357282141552523 train_accuracy: 0.9108666666666667 test_loss: 0.34880170348364925 test_accuracy: 0.8711\n",
      "Iteraions 555: train_loss: 0.22354548622758408 train_accuracy: 0.91015 test_loss: 0.3527544966764445 test_accuracy: 0.87\n",
      "Iteraions 556: train_loss: 0.22296325283591906 train_accuracy: 0.91095 test_loss: 0.3487176961562567 test_accuracy: 0.8741\n",
      "Iteraions 557: train_loss: 0.22493806297797278 train_accuracy: 0.9102333333333333 test_loss: 0.3483454688124016 test_accuracy: 0.8701\n",
      "Iteraions 558: train_loss: 0.22371995497470853 train_accuracy: 0.9096333333333333 test_loss: 0.35839958144564255 test_accuracy: 0.8666\n",
      "Iteraions 559: train_loss: 0.22180748263307917 train_accuracy: 0.9102333333333333 test_loss: 0.34649424189384787 test_accuracy: 0.8702\n",
      "Iteraions 560: train_loss: 0.2239279398657818 train_accuracy: 0.91055 test_loss: 0.3479882873533267 test_accuracy: 0.8715\n",
      "Iteraions 561: train_loss: 0.22241215833159458 train_accuracy: 0.9111833333333333 test_loss: 0.35083064792101964 test_accuracy: 0.8714\n",
      "Iteraions 562: train_loss: 0.2205453641466355 train_accuracy: 0.9109 test_loss: 0.3526255360372588 test_accuracy: 0.8707\n",
      "Iteraions 563: train_loss: 0.22157806689491627 train_accuracy: 0.91145 test_loss: 0.34388280125768966 test_accuracy: 0.8704\n",
      "Iteraions 564: train_loss: 0.22188113129658232 train_accuracy: 0.9107666666666666 test_loss: 0.34625422317847976 test_accuracy: 0.8744\n",
      "Iteraions 565: train_loss: 0.22142309282984132 train_accuracy: 0.91245 test_loss: 0.3476472236148064 test_accuracy: 0.8703\n",
      "Iteraions 566: train_loss: 0.22177814611553487 train_accuracy: 0.9111666666666667 test_loss: 0.3531552161856577 test_accuracy: 0.8708\n",
      "Iteraions 567: train_loss: 0.22173155285709567 train_accuracy: 0.91085 test_loss: 0.3493449020660287 test_accuracy: 0.8726\n",
      "Iteraions 568: train_loss: 0.2183407548922301 train_accuracy: 0.91265 test_loss: 0.3518050831783256 test_accuracy: 0.8732\n",
      "Iteraions 569: train_loss: 0.21793832589274412 train_accuracy: 0.9121333333333334 test_loss: 0.3431846071399981 test_accuracy: 0.8741\n",
      "Iteraions 570: train_loss: 0.22087029723057708 train_accuracy: 0.91115 test_loss: 0.3506069388872439 test_accuracy: 0.8722\n",
      "Iteraions 571: train_loss: 0.22026429642845027 train_accuracy: 0.9117833333333333 test_loss: 0.34783078883383917 test_accuracy: 0.8711\n",
      "Iteraions 572: train_loss: 0.21989133803148095 train_accuracy: 0.9119333333333334 test_loss: 0.35246975568784705 test_accuracy: 0.8705\n",
      "Iteraions 573: train_loss: 0.2204256134883817 train_accuracy: 0.9118833333333334 test_loss: 0.35003817167206164 test_accuracy: 0.8732\n",
      "Iteraions 574: train_loss: 0.21782659752538114 train_accuracy: 0.91245 test_loss: 0.3436232406301775 test_accuracy: 0.8747\n",
      "Iteraions 575: train_loss: 0.21778479231513853 train_accuracy: 0.9131166666666667 test_loss: 0.3567249207344742 test_accuracy: 0.8741\n",
      "Iteraions 576: train_loss: 0.2177975654442841 train_accuracy: 0.91305 test_loss: 0.35528465573961676 test_accuracy: 0.8718\n",
      "Iteraions 577: train_loss: 0.2178892224717057 train_accuracy: 0.9121333333333334 test_loss: 0.3445887052750098 test_accuracy: 0.8726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 578: train_loss: 0.21886614639010338 train_accuracy: 0.9117 test_loss: 0.35056040318696413 test_accuracy: 0.8715\n",
      "Iteraions 579: train_loss: 0.21991908663786955 train_accuracy: 0.9115166666666666 test_loss: 0.35133438938080797 test_accuracy: 0.87\n",
      "Iteraions 580: train_loss: 0.21721012805149578 train_accuracy: 0.9130833333333334 test_loss: 0.35011222900816014 test_accuracy: 0.8715\n",
      "Iteraions 581: train_loss: 0.21707773296644983 train_accuracy: 0.9127333333333333 test_loss: 0.34816282240061136 test_accuracy: 0.8719\n",
      "Iteraions 582: train_loss: 0.217621391965445 train_accuracy: 0.9120666666666667 test_loss: 0.3477887905372741 test_accuracy: 0.8685\n",
      "Iteraions 583: train_loss: 0.21746994543764722 train_accuracy: 0.9127 test_loss: 0.35027892836075014 test_accuracy: 0.872\n",
      "Iteraions 584: train_loss: 0.21651638268428794 train_accuracy: 0.91255 test_loss: 0.34579101372064946 test_accuracy: 0.8754\n",
      "Iteraions 585: train_loss: 0.21738293624089183 train_accuracy: 0.9121166666666667 test_loss: 0.35483086018454335 test_accuracy: 0.8687\n",
      "Iteraions 586: train_loss: 0.21811386730527027 train_accuracy: 0.9128333333333334 test_loss: 0.347924990745442 test_accuracy: 0.8745\n",
      "Iteraions 587: train_loss: 0.21639772890744474 train_accuracy: 0.9129666666666667 test_loss: 0.34788685877413217 test_accuracy: 0.8718\n",
      "Iteraions 588: train_loss: 0.21659007289707075 train_accuracy: 0.9127 test_loss: 0.3472287810945126 test_accuracy: 0.8722\n",
      "Iteraions 589: train_loss: 0.21528478165351572 train_accuracy: 0.9137333333333333 test_loss: 0.3499963279283453 test_accuracy: 0.8686\n",
      "Iteraions 590: train_loss: 0.2165538776925209 train_accuracy: 0.91265 test_loss: 0.3516504098931562 test_accuracy: 0.8705\n",
      "Iteraions 591: train_loss: 0.21449998482181395 train_accuracy: 0.9143833333333333 test_loss: 0.34772653832712935 test_accuracy: 0.8715\n",
      "Iteraions 592: train_loss: 0.21645891847524623 train_accuracy: 0.9138833333333334 test_loss: 0.35134208691227814 test_accuracy: 0.8683\n",
      "Iteraions 593: train_loss: 0.21519499167414147 train_accuracy: 0.9145666666666666 test_loss: 0.3470453127978596 test_accuracy: 0.8729\n",
      "Iteraions 594: train_loss: 0.21425257497023262 train_accuracy: 0.91345 test_loss: 0.35158107008762524 test_accuracy: 0.8703\n",
      "Iteraions 595: train_loss: 0.21374624333825493 train_accuracy: 0.9141 test_loss: 0.34471891302362956 test_accuracy: 0.8715\n",
      "Iteraions 596: train_loss: 0.2126910122179723 train_accuracy: 0.91465 test_loss: 0.3491651176566482 test_accuracy: 0.8739\n",
      "Iteraions 597: train_loss: 0.21301874639057833 train_accuracy: 0.9146666666666666 test_loss: 0.3460005573342865 test_accuracy: 0.8736\n",
      "Iteraions 598: train_loss: 0.21319270664644996 train_accuracy: 0.9147666666666666 test_loss: 0.3537123868440668 test_accuracy: 0.8723\n",
      "Iteraions 599: train_loss: 0.21271642539385194 train_accuracy: 0.9145166666666666 test_loss: 0.348415025351524 test_accuracy: 0.8742\n",
      "Iteraions 600: train_loss: 0.2121912692222965 train_accuracy: 0.9150166666666667 test_loss: 0.35255375289166796 test_accuracy: 0.8696\n",
      "Iteraions 601: train_loss: 0.21296438225405873 train_accuracy: 0.9141666666666667 test_loss: 0.35455406807470824 test_accuracy: 0.8735\n",
      "Iteraions 602: train_loss: 0.21198526609186974 train_accuracy: 0.9142333333333333 test_loss: 0.35117480880127755 test_accuracy: 0.8725\n",
      "Iteraions 603: train_loss: 0.21277887494556935 train_accuracy: 0.9159833333333334 test_loss: 0.3516341230769354 test_accuracy: 0.8746\n",
      "Iteraions 604: train_loss: 0.21287393032375057 train_accuracy: 0.9148666666666667 test_loss: 0.35409802443817223 test_accuracy: 0.872\n",
      "Iteraions 605: train_loss: 0.2140297483408384 train_accuracy: 0.9146333333333333 test_loss: 0.35124405589090973 test_accuracy: 0.8741\n",
      "Iteraions 606: train_loss: 0.211095910720127 train_accuracy: 0.9150166666666667 test_loss: 0.3551337212970305 test_accuracy: 0.8712\n",
      "Iteraions 607: train_loss: 0.21169632215668546 train_accuracy: 0.9145666666666666 test_loss: 0.3491547962298504 test_accuracy: 0.8727\n",
      "Iteraions 608: train_loss: 0.2104687165139744 train_accuracy: 0.9153333333333333 test_loss: 0.34656310725672307 test_accuracy: 0.8737\n",
      "Iteraions 609: train_loss: 0.21024771927315225 train_accuracy: 0.9158333333333334 test_loss: 0.3501986849863691 test_accuracy: 0.8723\n",
      "Iteraions 610: train_loss: 0.21010993876126668 train_accuracy: 0.9167 test_loss: 0.35336941025613894 test_accuracy: 0.8726\n",
      "Iteraions 611: train_loss: 0.21087794626405387 train_accuracy: 0.9158666666666667 test_loss: 0.3485434513765922 test_accuracy: 0.8748\n",
      "Iteraions 612: train_loss: 0.21017995816884377 train_accuracy: 0.9141 test_loss: 0.35183798156804796 test_accuracy: 0.8715\n",
      "Iteraions 613: train_loss: 0.21027268592056 train_accuracy: 0.9163666666666667 test_loss: 0.3474845732411512 test_accuracy: 0.8751\n",
      "Iteraions 614: train_loss: 0.20943376380435824 train_accuracy: 0.9162666666666667 test_loss: 0.35383063001002474 test_accuracy: 0.8707\n",
      "Iteraions 615: train_loss: 0.21126906440555088 train_accuracy: 0.9165666666666666 test_loss: 0.3563380184640744 test_accuracy: 0.8726\n",
      "Iteraions 616: train_loss: 0.21123885462678205 train_accuracy: 0.9153833333333333 test_loss: 0.34724989372893406 test_accuracy: 0.8729\n",
      "Iteraions 617: train_loss: 0.20937610682196003 train_accuracy: 0.9162833333333333 test_loss: 0.35280008648498634 test_accuracy: 0.874\n",
      "Iteraions 618: train_loss: 0.2074831657607354 train_accuracy: 0.9171 test_loss: 0.3467943662261454 test_accuracy: 0.8728\n",
      "Iteraions 619: train_loss: 0.20999104736448573 train_accuracy: 0.9159333333333334 test_loss: 0.34744552623535696 test_accuracy: 0.8735\n",
      "Iteraions 620: train_loss: 0.2109596380679144 train_accuracy: 0.9149666666666667 test_loss: 0.35193246852052124 test_accuracy: 0.872\n",
      "Iteraions 621: train_loss: 0.20938233508715523 train_accuracy: 0.9158666666666667 test_loss: 0.34871497531049755 test_accuracy: 0.8731\n",
      "Iteraions 622: train_loss: 0.20851674212485005 train_accuracy: 0.9165333333333333 test_loss: 0.34512935124587696 test_accuracy: 0.8746\n",
      "Iteraions 623: train_loss: 0.2092131077288094 train_accuracy: 0.9162833333333333 test_loss: 0.3589714460170538 test_accuracy: 0.8703\n",
      "Iteraions 624: train_loss: 0.20915551668953425 train_accuracy: 0.9162833333333333 test_loss: 0.3553258303719434 test_accuracy: 0.8722\n",
      "Iteraions 625: train_loss: 0.20826115226929076 train_accuracy: 0.9171666666666667 test_loss: 0.3516581159207969 test_accuracy: 0.8754\n",
      "Iteraions 626: train_loss: 0.20940252798021453 train_accuracy: 0.9168833333333334 test_loss: 0.354936279868746 test_accuracy: 0.8719\n",
      "Iteraions 627: train_loss: 0.20689130188944627 train_accuracy: 0.9168666666666667 test_loss: 0.35494609042862135 test_accuracy: 0.8706\n",
      "Iteraions 628: train_loss: 0.20468946090995757 train_accuracy: 0.91775 test_loss: 0.35369894445867067 test_accuracy: 0.8728\n",
      "Iteraions 629: train_loss: 0.20565510758522118 train_accuracy: 0.9170666666666667 test_loss: 0.3644819362630839 test_accuracy: 0.8696\n",
      "Iteraions 630: train_loss: 0.20623301269800726 train_accuracy: 0.9172333333333333 test_loss: 0.3569668212942737 test_accuracy: 0.8715\n",
      "Iteraions 631: train_loss: 0.20595035807393736 train_accuracy: 0.9176833333333333 test_loss: 0.3556408440135938 test_accuracy: 0.871\n",
      "Iteraions 632: train_loss: 0.20561705128386076 train_accuracy: 0.91765 test_loss: 0.34559663621941017 test_accuracy: 0.8734\n",
      "Iteraions 633: train_loss: 0.2061928601870469 train_accuracy: 0.9176333333333333 test_loss: 0.35153826269233884 test_accuracy: 0.8741\n",
      "Iteraions 634: train_loss: 0.20526085364455413 train_accuracy: 0.9183 test_loss: 0.34937490287710926 test_accuracy: 0.8738\n",
      "Iteraions 635: train_loss: 0.20726701024539976 train_accuracy: 0.9171833333333334 test_loss: 0.3487610772125613 test_accuracy: 0.8755\n",
      "Iteraions 636: train_loss: 0.20602249295033023 train_accuracy: 0.9186166666666666 test_loss: 0.347139912761108 test_accuracy: 0.8758\n",
      "Iteraions 637: train_loss: 0.20616569783994504 train_accuracy: 0.9167 test_loss: 0.35263043335743194 test_accuracy: 0.8742\n",
      "Iteraions 638: train_loss: 0.2064059658508601 train_accuracy: 0.9188333333333333 test_loss: 0.3486039589458382 test_accuracy: 0.8726\n",
      "Iteraions 639: train_loss: 0.20730322430409912 train_accuracy: 0.9160166666666667 test_loss: 0.352202104314976 test_accuracy: 0.8713\n",
      "Iteraions 640: train_loss: 0.20445911993859542 train_accuracy: 0.91845 test_loss: 0.34905758991285973 test_accuracy: 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 641: train_loss: 0.2040054484855588 train_accuracy: 0.9195833333333333 test_loss: 0.34829256868723846 test_accuracy: 0.8748\n",
      "Iteraions 642: train_loss: 0.2023298896891471 train_accuracy: 0.9183833333333333 test_loss: 0.3541254020152365 test_accuracy: 0.8729\n",
      "Iteraions 643: train_loss: 0.20228639626089595 train_accuracy: 0.9194166666666667 test_loss: 0.3461850110023412 test_accuracy: 0.874\n",
      "Iteraions 644: train_loss: 0.20323185452929993 train_accuracy: 0.9182333333333333 test_loss: 0.3539619908732505 test_accuracy: 0.8699\n",
      "Iteraions 645: train_loss: 0.2036188236339286 train_accuracy: 0.9181833333333334 test_loss: 0.35060767007327387 test_accuracy: 0.8757\n",
      "Iteraions 646: train_loss: 0.20327763579423086 train_accuracy: 0.9186666666666666 test_loss: 0.3519370813733426 test_accuracy: 0.8737\n",
      "Iteraions 647: train_loss: 0.2033124538913509 train_accuracy: 0.9180833333333334 test_loss: 0.35256713468266726 test_accuracy: 0.8738\n",
      "Iteraions 648: train_loss: 0.20043731936204146 train_accuracy: 0.919 test_loss: 0.3476036241999164 test_accuracy: 0.8746\n",
      "Iteraions 649: train_loss: 0.20241837596145557 train_accuracy: 0.9201666666666667 test_loss: 0.35320839123292064 test_accuracy: 0.8726\n",
      "Iteraions 650: train_loss: 0.2031635196076945 train_accuracy: 0.9189666666666667 test_loss: 0.34700634852475354 test_accuracy: 0.875\n",
      "Iteraions 651: train_loss: 0.2011221867762177 train_accuracy: 0.9207 test_loss: 0.3585437394133946 test_accuracy: 0.8735\n",
      "Iteraions 652: train_loss: 0.2023227132885772 train_accuracy: 0.9187833333333333 test_loss: 0.3526071370454668 test_accuracy: 0.8753\n",
      "Iteraions 653: train_loss: 0.20053756689178734 train_accuracy: 0.91995 test_loss: 0.35078835409978193 test_accuracy: 0.8729\n",
      "Iteraions 654: train_loss: 0.2006845015777594 train_accuracy: 0.9195 test_loss: 0.3574302997637881 test_accuracy: 0.8713\n",
      "Iteraions 655: train_loss: 0.19807166684695904 train_accuracy: 0.9208 test_loss: 0.35605085855317686 test_accuracy: 0.8746\n",
      "Iteraions 656: train_loss: 0.1995112449122292 train_accuracy: 0.9206833333333333 test_loss: 0.35363817025655764 test_accuracy: 0.8743\n",
      "Iteraions 657: train_loss: 0.19950273303939417 train_accuracy: 0.9206666666666666 test_loss: 0.3482857112336172 test_accuracy: 0.8734\n",
      "Iteraions 658: train_loss: 0.20074021165609368 train_accuracy: 0.9191833333333334 test_loss: 0.35188508769155535 test_accuracy: 0.8745\n",
      "Iteraions 659: train_loss: 0.20000731821668963 train_accuracy: 0.9200333333333334 test_loss: 0.35635074692702357 test_accuracy: 0.8732\n",
      "Iteraions 660: train_loss: 0.19936374245331628 train_accuracy: 0.9209333333333334 test_loss: 0.35713599466121265 test_accuracy: 0.8677\n",
      "Iteraions 661: train_loss: 0.2008961795031648 train_accuracy: 0.9190666666666667 test_loss: 0.3545027363180588 test_accuracy: 0.8734\n",
      "Iteraions 662: train_loss: 0.20174295343424348 train_accuracy: 0.9190333333333334 test_loss: 0.355553187320883 test_accuracy: 0.8711\n",
      "Iteraions 663: train_loss: 0.19873822139656405 train_accuracy: 0.9212333333333333 test_loss: 0.35269130046515756 test_accuracy: 0.8751\n",
      "Iteraions 664: train_loss: 0.19932609575780794 train_accuracy: 0.9200833333333334 test_loss: 0.3520260267633942 test_accuracy: 0.8746\n",
      "Iteraions 665: train_loss: 0.19973804916761814 train_accuracy: 0.9207333333333333 test_loss: 0.35159621342485864 test_accuracy: 0.8748\n",
      "Iteraions 666: train_loss: 0.1995619101737809 train_accuracy: 0.9192666666666667 test_loss: 0.3513507779103058 test_accuracy: 0.877\n",
      "Iteraions 667: train_loss: 0.19963277183466463 train_accuracy: 0.92045 test_loss: 0.35469040142920144 test_accuracy: 0.8751\n",
      "Iteraions 668: train_loss: 0.19869245279630407 train_accuracy: 0.9215166666666667 test_loss: 0.35215747180370555 test_accuracy: 0.8747\n",
      "Iteraions 669: train_loss: 0.19811131911973479 train_accuracy: 0.9203333333333333 test_loss: 0.3476277416152995 test_accuracy: 0.8757\n",
      "Iteraions 670: train_loss: 0.19952035094590684 train_accuracy: 0.9204166666666667 test_loss: 0.35473903440156307 test_accuracy: 0.8708\n",
      "Iteraions 671: train_loss: 0.19924971231688257 train_accuracy: 0.9194833333333333 test_loss: 0.35108110928075026 test_accuracy: 0.8758\n",
      "Iteraions 672: train_loss: 0.1990398199208389 train_accuracy: 0.92035 test_loss: 0.3601214448863896 test_accuracy: 0.8726\n",
      "Iteraions 673: train_loss: 0.1983544827444154 train_accuracy: 0.9214666666666667 test_loss: 0.3478816512005636 test_accuracy: 0.8727\n",
      "Iteraions 674: train_loss: 0.19598571622034375 train_accuracy: 0.9218666666666666 test_loss: 0.34611840378119546 test_accuracy: 0.8761\n",
      "Iteraions 675: train_loss: 0.1953252594081939 train_accuracy: 0.9216333333333333 test_loss: 0.35560119044154137 test_accuracy: 0.8749\n",
      "Iteraions 676: train_loss: 0.19495676057684386 train_accuracy: 0.9221833333333334 test_loss: 0.34465351870645555 test_accuracy: 0.8789\n",
      "Iteraions 677: train_loss: 0.1984323850321492 train_accuracy: 0.92105 test_loss: 0.35684167147705875 test_accuracy: 0.8737\n",
      "Iteraions 678: train_loss: 0.19423576164722808 train_accuracy: 0.92255 test_loss: 0.3560004200801848 test_accuracy: 0.8753\n",
      "Iteraions 679: train_loss: 0.19707538004328515 train_accuracy: 0.9217 test_loss: 0.35702748505085985 test_accuracy: 0.8761\n",
      "Iteraions 680: train_loss: 0.19444415172056517 train_accuracy: 0.9215166666666667 test_loss: 0.3548524431751221 test_accuracy: 0.8711\n",
      "Iteraions 681: train_loss: 0.1967673273744885 train_accuracy: 0.9220166666666667 test_loss: 0.35571454631475263 test_accuracy: 0.8743\n",
      "Iteraions 682: train_loss: 0.1951104529802531 train_accuracy: 0.9225833333333333 test_loss: 0.3539215167956769 test_accuracy: 0.8748\n",
      "Iteraions 683: train_loss: 0.1957235060322148 train_accuracy: 0.9229 test_loss: 0.3538248276091855 test_accuracy: 0.8742\n",
      "Iteraions 684: train_loss: 0.19465147926385487 train_accuracy: 0.9226833333333333 test_loss: 0.34922177262302667 test_accuracy: 0.8757\n",
      "Iteraions 685: train_loss: 0.19633588389386897 train_accuracy: 0.9221333333333334 test_loss: 0.35641708057326865 test_accuracy: 0.8762\n",
      "Iteraions 686: train_loss: 0.196001459316048 train_accuracy: 0.92145 test_loss: 0.354872454627724 test_accuracy: 0.8759\n",
      "Iteraions 687: train_loss: 0.19514100977153054 train_accuracy: 0.9214833333333333 test_loss: 0.35575695991747003 test_accuracy: 0.8751\n",
      "Iteraions 688: train_loss: 0.19379853762373886 train_accuracy: 0.92205 test_loss: 0.35021961344568175 test_accuracy: 0.8742\n",
      "Iteraions 689: train_loss: 0.19596963152548655 train_accuracy: 0.9216333333333333 test_loss: 0.35780145253785317 test_accuracy: 0.8697\n",
      "Iteraions 690: train_loss: 0.19647856087157456 train_accuracy: 0.9202166666666667 test_loss: 0.35534712124945256 test_accuracy: 0.876\n",
      "Iteraions 691: train_loss: 0.19428922806820992 train_accuracy: 0.9228666666666666 test_loss: 0.35499105719755425 test_accuracy: 0.8701\n",
      "Iteraions 692: train_loss: 0.19277990670400832 train_accuracy: 0.9236666666666666 test_loss: 0.35865071515406316 test_accuracy: 0.8764\n",
      "Iteraions 693: train_loss: 0.1936399328454808 train_accuracy: 0.9228333333333333 test_loss: 0.3494888229886401 test_accuracy: 0.8746\n",
      "Iteraions 694: train_loss: 0.19476898339585907 train_accuracy: 0.9227666666666666 test_loss: 0.3580355417323713 test_accuracy: 0.8736\n",
      "Iteraions 695: train_loss: 0.19302192612847588 train_accuracy: 0.9239333333333334 test_loss: 0.3537345010883532 test_accuracy: 0.8717\n",
      "Iteraions 696: train_loss: 0.19217781612293694 train_accuracy: 0.9231 test_loss: 0.34887719030587466 test_accuracy: 0.8735\n",
      "Iteraions 697: train_loss: 0.19212312169792028 train_accuracy: 0.9244 test_loss: 0.3484831915266859 test_accuracy: 0.8763\n",
      "Iteraions 698: train_loss: 0.1916244018708069 train_accuracy: 0.9232166666666667 test_loss: 0.35529431175738885 test_accuracy: 0.8761\n",
      "Iteraions 699: train_loss: 0.1929071372467218 train_accuracy: 0.9234166666666667 test_loss: 0.3564347005702184 test_accuracy: 0.8734\n",
      "Iteraions 700: train_loss: 0.19056205984882887 train_accuracy: 0.9231 test_loss: 0.36249449124596966 test_accuracy: 0.8726\n",
      "Iteraions 701: train_loss: 0.19035997865675305 train_accuracy: 0.9240666666666667 test_loss: 0.35754484946547177 test_accuracy: 0.8753\n",
      "Iteraions 702: train_loss: 0.18973255085396498 train_accuracy: 0.92435 test_loss: 0.3609243657053204 test_accuracy: 0.8715\n",
      "Iteraions 703: train_loss: 0.19163671523022605 train_accuracy: 0.9233 test_loss: 0.34853908462564775 test_accuracy: 0.8747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 704: train_loss: 0.1907836482496304 train_accuracy: 0.9247833333333333 test_loss: 0.3509229771409447 test_accuracy: 0.8752\n",
      "Iteraions 705: train_loss: 0.1879191289988154 train_accuracy: 0.9244666666666667 test_loss: 0.3587848073701191 test_accuracy: 0.874\n",
      "Iteraions 706: train_loss: 0.19210296064218038 train_accuracy: 0.9229 test_loss: 0.3492944969513612 test_accuracy: 0.8756\n",
      "Iteraions 707: train_loss: 0.19228877583728124 train_accuracy: 0.9233333333333333 test_loss: 0.3571205403393839 test_accuracy: 0.8722\n",
      "Iteraions 708: train_loss: 0.18997177923765227 train_accuracy: 0.92525 test_loss: 0.3624964393126922 test_accuracy: 0.8706\n",
      "Iteraions 709: train_loss: 0.1879209507875615 train_accuracy: 0.9249166666666667 test_loss: 0.3571514592800505 test_accuracy: 0.8755\n",
      "Iteraions 710: train_loss: 0.19096402515016853 train_accuracy: 0.9237833333333333 test_loss: 0.3539662836846516 test_accuracy: 0.878\n",
      "Iteraions 711: train_loss: 0.19018893092349007 train_accuracy: 0.9249 test_loss: 0.3518307588033821 test_accuracy: 0.8761\n",
      "Iteraions 712: train_loss: 0.19032288547106418 train_accuracy: 0.9239666666666667 test_loss: 0.359860734324218 test_accuracy: 0.8751\n",
      "Iteraions 713: train_loss: 0.18832091264829215 train_accuracy: 0.92565 test_loss: 0.3505799806578048 test_accuracy: 0.8785\n",
      "Iteraions 714: train_loss: 0.188079952586665 train_accuracy: 0.926 test_loss: 0.3589203531340496 test_accuracy: 0.8754\n",
      "Iteraions 715: train_loss: 0.18740347128379642 train_accuracy: 0.9255166666666667 test_loss: 0.35647505138636915 test_accuracy: 0.8714\n",
      "Iteraions 716: train_loss: 0.18791720894501662 train_accuracy: 0.9252166666666667 test_loss: 0.3498670188160987 test_accuracy: 0.875\n",
      "Iteraions 717: train_loss: 0.18593002951873186 train_accuracy: 0.9271333333333334 test_loss: 0.35830809778132483 test_accuracy: 0.8741\n",
      "Iteraions 718: train_loss: 0.18772030931212474 train_accuracy: 0.9258 test_loss: 0.35696710548299426 test_accuracy: 0.8764\n",
      "Iteraions 719: train_loss: 0.18499689766368282 train_accuracy: 0.92655 test_loss: 0.36355128331529585 test_accuracy: 0.8756\n",
      "Iteraions 720: train_loss: 0.1864593845101255 train_accuracy: 0.9261666666666667 test_loss: 0.3586860812893664 test_accuracy: 0.8747\n",
      "Iteraions 721: train_loss: 0.18688862558679062 train_accuracy: 0.9260666666666667 test_loss: 0.34923918940398696 test_accuracy: 0.8794\n",
      "Iteraions 722: train_loss: 0.18741110409051562 train_accuracy: 0.9254833333333333 test_loss: 0.35594130311213346 test_accuracy: 0.8756\n",
      "Iteraions 723: train_loss: 0.18520443218067262 train_accuracy: 0.9252833333333333 test_loss: 0.3573482513170222 test_accuracy: 0.8763\n",
      "Iteraions 724: train_loss: 0.18627210107068778 train_accuracy: 0.9272 test_loss: 0.3572116818640135 test_accuracy: 0.8764\n",
      "Iteraions 725: train_loss: 0.1858964229497197 train_accuracy: 0.9265666666666666 test_loss: 0.35841640701231764 test_accuracy: 0.8745\n",
      "Iteraions 726: train_loss: 0.18343383806213576 train_accuracy: 0.9272666666666667 test_loss: 0.3596810898803105 test_accuracy: 0.8785\n",
      "Iteraions 727: train_loss: 0.18573218360642804 train_accuracy: 0.9270166666666667 test_loss: 0.36214757905102135 test_accuracy: 0.8755\n",
      "Iteraions 728: train_loss: 0.1862344342545817 train_accuracy: 0.9256 test_loss: 0.3556495115137301 test_accuracy: 0.8758\n",
      "Iteraions 729: train_loss: 0.18440491268892378 train_accuracy: 0.9264666666666667 test_loss: 0.357093277088244 test_accuracy: 0.8763\n",
      "Iteraions 730: train_loss: 0.1841680509593696 train_accuracy: 0.9266333333333333 test_loss: 0.35681344761545336 test_accuracy: 0.8752\n",
      "Iteraions 731: train_loss: 0.18363661726160335 train_accuracy: 0.927 test_loss: 0.3597176084693214 test_accuracy: 0.878\n",
      "Iteraions 732: train_loss: 0.18356183362111594 train_accuracy: 0.9275666666666667 test_loss: 0.3598340197208528 test_accuracy: 0.8784\n",
      "Iteraions 733: train_loss: 0.18656580211206727 train_accuracy: 0.9257833333333333 test_loss: 0.3605776251679114 test_accuracy: 0.8757\n",
      "Iteraions 734: train_loss: 0.18531274302411627 train_accuracy: 0.9268166666666666 test_loss: 0.3549471539216872 test_accuracy: 0.8748\n",
      "Iteraions 735: train_loss: 0.1846772766025905 train_accuracy: 0.9262666666666667 test_loss: 0.3588533894909047 test_accuracy: 0.8749\n",
      "Iteraions 736: train_loss: 0.18387340671299296 train_accuracy: 0.9261666666666667 test_loss: 0.35796729791766985 test_accuracy: 0.8768\n",
      "Iteraions 737: train_loss: 0.18302963917591997 train_accuracy: 0.9292666666666667 test_loss: 0.36572466828262834 test_accuracy: 0.8726\n",
      "Iteraions 738: train_loss: 0.1855072509068821 train_accuracy: 0.9271 test_loss: 0.36266725333675404 test_accuracy: 0.8745\n",
      "Iteraions 739: train_loss: 0.1852488567063226 train_accuracy: 0.9262333333333334 test_loss: 0.3522017263221761 test_accuracy: 0.8764\n",
      "Iteraions 740: train_loss: 0.18401986300973533 train_accuracy: 0.9276333333333333 test_loss: 0.3557299878286398 test_accuracy: 0.8755\n",
      "Iteraions 741: train_loss: 0.18367612630485108 train_accuracy: 0.9264333333333333 test_loss: 0.35909627872471495 test_accuracy: 0.8744\n",
      "Iteraions 742: train_loss: 0.1847767615800974 train_accuracy: 0.9270333333333334 test_loss: 0.3638265254644266 test_accuracy: 0.8779\n",
      "Iteraions 743: train_loss: 0.18229141870463392 train_accuracy: 0.9269666666666667 test_loss: 0.3569746292025636 test_accuracy: 0.8756\n",
      "Iteraions 744: train_loss: 0.18411149516562006 train_accuracy: 0.9267 test_loss: 0.36445863587510696 test_accuracy: 0.875\n",
      "Iteraions 745: train_loss: 0.18095087740012872 train_accuracy: 0.9280166666666667 test_loss: 0.3646531086224164 test_accuracy: 0.8732\n",
      "Iteraions 746: train_loss: 0.1840253654059713 train_accuracy: 0.92695 test_loss: 0.3619586902117537 test_accuracy: 0.8761\n",
      "Iteraions 747: train_loss: 0.18212867344610167 train_accuracy: 0.92755 test_loss: 0.3585539386367738 test_accuracy: 0.8734\n",
      "Iteraions 748: train_loss: 0.18214147149543253 train_accuracy: 0.9273833333333333 test_loss: 0.36365717343149606 test_accuracy: 0.8764\n",
      "Iteraions 749: train_loss: 0.181407529090833 train_accuracy: 0.9262666666666667 test_loss: 0.3584196044984119 test_accuracy: 0.8768\n",
      "Iteraions 750: train_loss: 0.1817087447537939 train_accuracy: 0.9269833333333334 test_loss: 0.3563657551664386 test_accuracy: 0.8727\n",
      "Iteraions 751: train_loss: 0.18050472293064598 train_accuracy: 0.9287666666666666 test_loss: 0.36277881338751017 test_accuracy: 0.8752\n",
      "Iteraions 752: train_loss: 0.18157310499761473 train_accuracy: 0.92775 test_loss: 0.3570008750612294 test_accuracy: 0.8774\n",
      "Iteraions 753: train_loss: 0.17900292670934173 train_accuracy: 0.9289 test_loss: 0.35059240990753143 test_accuracy: 0.8799\n",
      "Iteraions 754: train_loss: 0.18053455551113293 train_accuracy: 0.9285 test_loss: 0.36586580736715363 test_accuracy: 0.8748\n",
      "Iteraions 755: train_loss: 0.18214011681173015 train_accuracy: 0.9268333333333333 test_loss: 0.3571759166300914 test_accuracy: 0.8752\n",
      "Iteraions 756: train_loss: 0.18170455091339136 train_accuracy: 0.9277666666666666 test_loss: 0.36632048984222976 test_accuracy: 0.8756\n",
      "Iteraions 757: train_loss: 0.18186006553075623 train_accuracy: 0.9281166666666667 test_loss: 0.37495507898198166 test_accuracy: 0.8723\n",
      "Iteraions 758: train_loss: 0.18006652644847448 train_accuracy: 0.9275166666666667 test_loss: 0.3562506966327343 test_accuracy: 0.8763\n",
      "Iteraions 759: train_loss: 0.1804160228716452 train_accuracy: 0.9279333333333334 test_loss: 0.3585270108908179 test_accuracy: 0.8751\n",
      "Iteraions 760: train_loss: 0.18085442474244398 train_accuracy: 0.9287833333333333 test_loss: 0.36738187483750173 test_accuracy: 0.8736\n",
      "Iteraions 761: train_loss: 0.18027209135306868 train_accuracy: 0.9278666666666666 test_loss: 0.35704593372421406 test_accuracy: 0.8757\n",
      "Iteraions 762: train_loss: 0.17972166112985966 train_accuracy: 0.92865 test_loss: 0.36529039900857196 test_accuracy: 0.8736\n",
      "Iteraions 763: train_loss: 0.17912673159574782 train_accuracy: 0.9281833333333334 test_loss: 0.35997275576888876 test_accuracy: 0.8767\n",
      "Iteraions 764: train_loss: 0.17746194319834355 train_accuracy: 0.9285666666666667 test_loss: 0.35616518843765205 test_accuracy: 0.8762\n",
      "Iteraions 765: train_loss: 0.17975154159273557 train_accuracy: 0.9302833333333334 test_loss: 0.3556615949808249 test_accuracy: 0.8757\n",
      "Iteraions 766: train_loss: 0.17988640070504694 train_accuracy: 0.9280833333333334 test_loss: 0.35515371736985396 test_accuracy: 0.8767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 767: train_loss: 0.18000475486369094 train_accuracy: 0.9279166666666666 test_loss: 0.35804626722833344 test_accuracy: 0.878\n",
      "Iteraions 768: train_loss: 0.17987057936896955 train_accuracy: 0.9289333333333334 test_loss: 0.36200011624135314 test_accuracy: 0.8762\n",
      "Iteraions 769: train_loss: 0.1807035128326647 train_accuracy: 0.9283 test_loss: 0.3614828653444825 test_accuracy: 0.8736\n",
      "Iteraions 770: train_loss: 0.17856915571395857 train_accuracy: 0.9289666666666667 test_loss: 0.36441306021851827 test_accuracy: 0.8736\n",
      "Iteraions 771: train_loss: 0.17895631320193534 train_accuracy: 0.9284666666666667 test_loss: 0.3588369617776188 test_accuracy: 0.8766\n",
      "Iteraions 772: train_loss: 0.1778304072855112 train_accuracy: 0.9289666666666667 test_loss: 0.36249769158157674 test_accuracy: 0.8774\n",
      "Iteraions 773: train_loss: 0.17792551008321789 train_accuracy: 0.9299833333333334 test_loss: 0.3642779114812103 test_accuracy: 0.8757\n",
      "Iteraions 774: train_loss: 0.17604771189069338 train_accuracy: 0.9306166666666666 test_loss: 0.3629320920879829 test_accuracy: 0.8769\n",
      "Iteraions 775: train_loss: 0.17541638929727033 train_accuracy: 0.9307333333333333 test_loss: 0.357879088144535 test_accuracy: 0.8768\n",
      "Iteraions 776: train_loss: 0.1757269758172582 train_accuracy: 0.9311 test_loss: 0.3639889584378357 test_accuracy: 0.8772\n",
      "Iteraions 777: train_loss: 0.17686525783557794 train_accuracy: 0.9302333333333334 test_loss: 0.3544538277382122 test_accuracy: 0.8764\n",
      "Iteraions 778: train_loss: 0.17730895157946008 train_accuracy: 0.92865 test_loss: 0.3608638461180148 test_accuracy: 0.876\n",
      "Iteraions 779: train_loss: 0.1783019052528493 train_accuracy: 0.9303166666666667 test_loss: 0.3592311040564132 test_accuracy: 0.88\n",
      "Iteraions 780: train_loss: 0.17486907652184006 train_accuracy: 0.9305666666666667 test_loss: 0.3534598446659333 test_accuracy: 0.8766\n",
      "Iteraions 781: train_loss: 0.1782387684558486 train_accuracy: 0.9292666666666667 test_loss: 0.3609440873622609 test_accuracy: 0.8753\n",
      "Iteraions 782: train_loss: 0.1753008894168041 train_accuracy: 0.9314333333333333 test_loss: 0.3600329836302441 test_accuracy: 0.8772\n",
      "Iteraions 783: train_loss: 0.17540062054561906 train_accuracy: 0.9319833333333334 test_loss: 0.36344434402826564 test_accuracy: 0.8767\n",
      "Iteraions 784: train_loss: 0.17582652910452867 train_accuracy: 0.9293833333333333 test_loss: 0.3591761626140585 test_accuracy: 0.8759\n",
      "Iteraions 785: train_loss: 0.1755240775797794 train_accuracy: 0.9301166666666667 test_loss: 0.3713924538681417 test_accuracy: 0.8713\n",
      "Iteraions 786: train_loss: 0.17526788627745246 train_accuracy: 0.9301 test_loss: 0.36495186303198207 test_accuracy: 0.875\n",
      "Iteraions 787: train_loss: 0.17558951457749894 train_accuracy: 0.9304166666666667 test_loss: 0.36778614824083117 test_accuracy: 0.8749\n",
      "Iteraions 788: train_loss: 0.1747944458291084 train_accuracy: 0.9310333333333334 test_loss: 0.3738945899352262 test_accuracy: 0.875\n",
      "Iteraions 789: train_loss: 0.17357530671236898 train_accuracy: 0.9318 test_loss: 0.35967379822459156 test_accuracy: 0.8767\n",
      "Iteraions 790: train_loss: 0.17244383152545556 train_accuracy: 0.9315666666666667 test_loss: 0.36103533064424154 test_accuracy: 0.8762\n",
      "Iteraions 791: train_loss: 0.17473406603530045 train_accuracy: 0.93105 test_loss: 0.3624012829747764 test_accuracy: 0.8749\n",
      "Iteraions 792: train_loss: 0.1738930758652247 train_accuracy: 0.9322 test_loss: 0.3595009950096075 test_accuracy: 0.8767\n",
      "Iteraions 793: train_loss: 0.17207928663801741 train_accuracy: 0.9314 test_loss: 0.3652783611119673 test_accuracy: 0.876\n",
      "Iteraions 794: train_loss: 0.1740309343276195 train_accuracy: 0.9306833333333333 test_loss: 0.36677339132679 test_accuracy: 0.8769\n",
      "Iteraions 795: train_loss: 0.17322334733036845 train_accuracy: 0.93185 test_loss: 0.3660465009000504 test_accuracy: 0.8753\n",
      "Iteraions 796: train_loss: 0.17177166398000862 train_accuracy: 0.93255 test_loss: 0.36659734908413766 test_accuracy: 0.8752\n",
      "Iteraions 797: train_loss: 0.17303231919111722 train_accuracy: 0.9301166666666667 test_loss: 0.3552203835654124 test_accuracy: 0.8803\n",
      "Iteraions 798: train_loss: 0.17234620460326072 train_accuracy: 0.9320666666666667 test_loss: 0.3672572125232904 test_accuracy: 0.8741\n",
      "Iteraions 799: train_loss: 0.1743151869960465 train_accuracy: 0.9311166666666667 test_loss: 0.36949424080389237 test_accuracy: 0.8751\n",
      "Iteraions 800: train_loss: 0.17306762613207907 train_accuracy: 0.93095 test_loss: 0.36533854122376164 test_accuracy: 0.8762\n",
      "Iteraions 801: train_loss: 0.17479790167992426 train_accuracy: 0.9318333333333333 test_loss: 0.3641525647752724 test_accuracy: 0.878\n",
      "Iteraions 802: train_loss: 0.1739104154064825 train_accuracy: 0.9312166666666667 test_loss: 0.36029219773235577 test_accuracy: 0.8769\n",
      "Iteraions 803: train_loss: 0.17137936439967852 train_accuracy: 0.9325 test_loss: 0.3616277420815934 test_accuracy: 0.8758\n",
      "Iteraions 804: train_loss: 0.1713940706479035 train_accuracy: 0.93185 test_loss: 0.36755529328867226 test_accuracy: 0.8782\n",
      "Iteraions 805: train_loss: 0.1736112792310684 train_accuracy: 0.9316 test_loss: 0.37097910073820656 test_accuracy: 0.8771\n",
      "Iteraions 806: train_loss: 0.17352806103549812 train_accuracy: 0.93085 test_loss: 0.3677390318606823 test_accuracy: 0.8755\n",
      "Iteraions 807: train_loss: 0.17213198561108642 train_accuracy: 0.9314833333333333 test_loss: 0.36690143888104193 test_accuracy: 0.8753\n",
      "Iteraions 808: train_loss: 0.1719430254253309 train_accuracy: 0.9319 test_loss: 0.35870986864648824 test_accuracy: 0.8761\n",
      "Iteraions 809: train_loss: 0.17137555747257893 train_accuracy: 0.9322166666666667 test_loss: 0.3606147503195269 test_accuracy: 0.8761\n",
      "Iteraions 810: train_loss: 0.1691020281067535 train_accuracy: 0.9326166666666666 test_loss: 0.3657506987305151 test_accuracy: 0.8744\n",
      "Iteraions 811: train_loss: 0.17042879109423417 train_accuracy: 0.9317833333333333 test_loss: 0.3700886577558581 test_accuracy: 0.8779\n",
      "Iteraions 812: train_loss: 0.17013939839905287 train_accuracy: 0.9336833333333333 test_loss: 0.35752721278396393 test_accuracy: 0.88\n",
      "Iteraions 813: train_loss: 0.17086211044996433 train_accuracy: 0.9323666666666667 test_loss: 0.36751461982269157 test_accuracy: 0.8766\n",
      "Iteraions 814: train_loss: 0.16907309876989693 train_accuracy: 0.9330166666666667 test_loss: 0.36004541821660513 test_accuracy: 0.8744\n",
      "Iteraions 815: train_loss: 0.1701566302917059 train_accuracy: 0.9330333333333334 test_loss: 0.35979057896230116 test_accuracy: 0.8779\n",
      "Iteraions 816: train_loss: 0.1696570119957764 train_accuracy: 0.9336666666666666 test_loss: 0.35432746712911656 test_accuracy: 0.8783\n",
      "Iteraions 817: train_loss: 0.1689382317603014 train_accuracy: 0.9334833333333333 test_loss: 0.3615620432174258 test_accuracy: 0.8806\n",
      "Iteraions 818: train_loss: 0.16886095455908623 train_accuracy: 0.9324 test_loss: 0.37051180953120605 test_accuracy: 0.8742\n",
      "Iteraions 819: train_loss: 0.1677670499578896 train_accuracy: 0.9336 test_loss: 0.35627125175326674 test_accuracy: 0.8737\n",
      "Iteraions 820: train_loss: 0.16875830817741752 train_accuracy: 0.9336166666666667 test_loss: 0.372759848651633 test_accuracy: 0.8731\n",
      "Iteraions 821: train_loss: 0.1700614001496791 train_accuracy: 0.9321333333333334 test_loss: 0.36849365409504153 test_accuracy: 0.8763\n",
      "Iteraions 822: train_loss: 0.16908139432575736 train_accuracy: 0.9340166666666667 test_loss: 0.3641825858023809 test_accuracy: 0.8786\n",
      "Iteraions 823: train_loss: 0.16748258367479585 train_accuracy: 0.93405 test_loss: 0.37389222627484137 test_accuracy: 0.8729\n",
      "Iteraions 824: train_loss: 0.16915875126115199 train_accuracy: 0.93335 test_loss: 0.3557504109408023 test_accuracy: 0.8801\n",
      "Iteraions 825: train_loss: 0.1691431268002808 train_accuracy: 0.9325333333333333 test_loss: 0.36646863623349163 test_accuracy: 0.878\n",
      "Iteraions 826: train_loss: 0.16935605137912782 train_accuracy: 0.9333166666666667 test_loss: 0.3682850371807163 test_accuracy: 0.8752\n",
      "Iteraions 827: train_loss: 0.1678357926145376 train_accuracy: 0.9339166666666666 test_loss: 0.362900226557195 test_accuracy: 0.8754\n",
      "Iteraions 828: train_loss: 0.16687654532738888 train_accuracy: 0.9333833333333333 test_loss: 0.36601377207610203 test_accuracy: 0.8775\n",
      "Iteraions 829: train_loss: 0.1684672057722834 train_accuracy: 0.9330666666666667 test_loss: 0.3588773121891148 test_accuracy: 0.8785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 830: train_loss: 0.16668522255793283 train_accuracy: 0.9340166666666667 test_loss: 0.36130463805607654 test_accuracy: 0.8782\n",
      "Iteraions 831: train_loss: 0.1655222875188535 train_accuracy: 0.9344333333333333 test_loss: 0.3678992504595001 test_accuracy: 0.8749\n",
      "Iteraions 832: train_loss: 0.16578796477154895 train_accuracy: 0.9338 test_loss: 0.3704169802339018 test_accuracy: 0.8764\n",
      "Iteraions 833: train_loss: 0.16659390598198437 train_accuracy: 0.9340666666666667 test_loss: 0.3687779060502905 test_accuracy: 0.8767\n",
      "Iteraions 834: train_loss: 0.16881687912718024 train_accuracy: 0.9319333333333333 test_loss: 0.3775947467747955 test_accuracy: 0.8704\n",
      "Iteraions 835: train_loss: 0.17008553565856854 train_accuracy: 0.9333333333333333 test_loss: 0.3651357064332671 test_accuracy: 0.8804\n",
      "Iteraions 836: train_loss: 0.1657798593965168 train_accuracy: 0.9355833333333333 test_loss: 0.3690545088752712 test_accuracy: 0.8761\n",
      "Iteraions 837: train_loss: 0.16589405584624145 train_accuracy: 0.9344166666666667 test_loss: 0.3663587433570958 test_accuracy: 0.8784\n",
      "Iteraions 838: train_loss: 0.1657911627052452 train_accuracy: 0.9350833333333334 test_loss: 0.371004822310781 test_accuracy: 0.8788\n",
      "Iteraions 839: train_loss: 0.16628708512649465 train_accuracy: 0.9333333333333333 test_loss: 0.3730044733383207 test_accuracy: 0.8792\n",
      "Iteraions 840: train_loss: 0.16615380572219202 train_accuracy: 0.9344333333333333 test_loss: 0.37666640256962675 test_accuracy: 0.8777\n",
      "Iteraions 841: train_loss: 0.16652858378146163 train_accuracy: 0.9350666666666667 test_loss: 0.3637804775005059 test_accuracy: 0.8782\n",
      "Iteraions 842: train_loss: 0.1666086687757941 train_accuracy: 0.9343 test_loss: 0.37869757209669874 test_accuracy: 0.8736\n",
      "Iteraions 843: train_loss: 0.16364786659393962 train_accuracy: 0.935 test_loss: 0.3699722463675667 test_accuracy: 0.8764\n",
      "Iteraions 844: train_loss: 0.16302562385324357 train_accuracy: 0.9357666666666666 test_loss: 0.3634909672788873 test_accuracy: 0.881\n",
      "Iteraions 845: train_loss: 0.16332755717963104 train_accuracy: 0.93555 test_loss: 0.37227907866897375 test_accuracy: 0.8767\n",
      "Iteraions 846: train_loss: 0.1665626044386619 train_accuracy: 0.9340333333333334 test_loss: 0.37288712464186075 test_accuracy: 0.8739\n",
      "Iteraions 847: train_loss: 0.16486743787737848 train_accuracy: 0.93605 test_loss: 0.36530883909309275 test_accuracy: 0.877\n",
      "Iteraions 848: train_loss: 0.16254078872651123 train_accuracy: 0.9347 test_loss: 0.3624816813225175 test_accuracy: 0.8789\n",
      "Iteraions 849: train_loss: 0.16465698537595297 train_accuracy: 0.9347166666666666 test_loss: 0.3748681849433304 test_accuracy: 0.878\n",
      "Iteraions 850: train_loss: 0.16343829159187384 train_accuracy: 0.9359833333333333 test_loss: 0.36182089290203606 test_accuracy: 0.8774\n",
      "Iteraions 851: train_loss: 0.16434601871175702 train_accuracy: 0.9352333333333334 test_loss: 0.35631573802074856 test_accuracy: 0.8779\n",
      "Iteraions 852: train_loss: 0.1638775970430231 train_accuracy: 0.9348666666666666 test_loss: 0.36405023465643227 test_accuracy: 0.88\n",
      "Iteraions 853: train_loss: 0.16277220605977502 train_accuracy: 0.9358833333333333 test_loss: 0.36727932670640423 test_accuracy: 0.8774\n",
      "Iteraions 854: train_loss: 0.16309498214481327 train_accuracy: 0.9357666666666666 test_loss: 0.36760404697878296 test_accuracy: 0.8795\n",
      "Iteraions 855: train_loss: 0.16485173702780928 train_accuracy: 0.9341166666666667 test_loss: 0.3727282973564565 test_accuracy: 0.8752\n",
      "Iteraions 856: train_loss: 0.15992602942300885 train_accuracy: 0.9364666666666667 test_loss: 0.362629699394929 test_accuracy: 0.8778\n",
      "Iteraions 857: train_loss: 0.16177056195419948 train_accuracy: 0.93725 test_loss: 0.3702523329414928 test_accuracy: 0.8768\n",
      "Iteraions 858: train_loss: 0.16595628561900921 train_accuracy: 0.9348 test_loss: 0.37089459967233396 test_accuracy: 0.8782\n",
      "Iteraions 859: train_loss: 0.1615685624223291 train_accuracy: 0.9368166666666666 test_loss: 0.36784537705418313 test_accuracy: 0.8772\n",
      "Iteraions 860: train_loss: 0.16211580610356907 train_accuracy: 0.9354333333333333 test_loss: 0.368483532089019 test_accuracy: 0.88\n",
      "Iteraions 861: train_loss: 0.16073185706281234 train_accuracy: 0.9368166666666666 test_loss: 0.3675655711954731 test_accuracy: 0.8773\n",
      "Iteraions 862: train_loss: 0.1607515282298537 train_accuracy: 0.9364 test_loss: 0.38132119596798586 test_accuracy: 0.8734\n",
      "Iteraions 863: train_loss: 0.16223774218900847 train_accuracy: 0.9357 test_loss: 0.3685544908024392 test_accuracy: 0.8798\n",
      "Iteraions 864: train_loss: 0.1607344898111692 train_accuracy: 0.93665 test_loss: 0.3741402175315753 test_accuracy: 0.8765\n",
      "Iteraions 865: train_loss: 0.160501389201421 train_accuracy: 0.9368 test_loss: 0.37195014806168863 test_accuracy: 0.8777\n",
      "Iteraions 866: train_loss: 0.1593389487987545 train_accuracy: 0.9364666666666667 test_loss: 0.37364864135340614 test_accuracy: 0.8776\n",
      "Iteraions 867: train_loss: 0.1602861995327049 train_accuracy: 0.9366666666666666 test_loss: 0.3642935372744017 test_accuracy: 0.8771\n",
      "Iteraions 868: train_loss: 0.1589424786939 train_accuracy: 0.9379166666666666 test_loss: 0.3683467703492007 test_accuracy: 0.8808\n",
      "Iteraions 869: train_loss: 0.1606132528365988 train_accuracy: 0.93585 test_loss: 0.36363344835109684 test_accuracy: 0.8796\n",
      "Iteraions 870: train_loss: 0.16015256277187842 train_accuracy: 0.93715 test_loss: 0.37258033052629264 test_accuracy: 0.8765\n",
      "Iteraions 871: train_loss: 0.15883708921706846 train_accuracy: 0.9392333333333334 test_loss: 0.3688883909150112 test_accuracy: 0.8745\n",
      "Iteraions 872: train_loss: 0.16016672422099595 train_accuracy: 0.9373166666666667 test_loss: 0.3763449539370926 test_accuracy: 0.8778\n",
      "Iteraions 873: train_loss: 0.16008350130303498 train_accuracy: 0.9374 test_loss: 0.36961915383694843 test_accuracy: 0.8785\n",
      "Iteraions 874: train_loss: 0.16102955106054354 train_accuracy: 0.9367666666666666 test_loss: 0.3661828049674867 test_accuracy: 0.8785\n",
      "Iteraions 875: train_loss: 0.1582129506117428 train_accuracy: 0.9372833333333334 test_loss: 0.3646439700262998 test_accuracy: 0.8782\n",
      "Iteraions 876: train_loss: 0.15788938543447698 train_accuracy: 0.9378833333333333 test_loss: 0.37152967644141144 test_accuracy: 0.8805\n",
      "Iteraions 877: train_loss: 0.16003218556895482 train_accuracy: 0.9367166666666666 test_loss: 0.37792224014615405 test_accuracy: 0.8768\n",
      "Iteraions 878: train_loss: 0.16143977005176668 train_accuracy: 0.9359666666666666 test_loss: 0.37163608008795423 test_accuracy: 0.8756\n",
      "Iteraions 879: train_loss: 0.15916664016898366 train_accuracy: 0.93725 test_loss: 0.36708242617040404 test_accuracy: 0.8774\n",
      "Iteraions 880: train_loss: 0.15890720467265135 train_accuracy: 0.939 test_loss: 0.3635993414300793 test_accuracy: 0.8801\n",
      "Iteraions 881: train_loss: 0.15862935684201548 train_accuracy: 0.9378166666666666 test_loss: 0.3627119776715511 test_accuracy: 0.8818\n",
      "Iteraions 882: train_loss: 0.15791604804708667 train_accuracy: 0.93765 test_loss: 0.37319806511348635 test_accuracy: 0.8778\n",
      "Iteraions 883: train_loss: 0.15934921922111056 train_accuracy: 0.9376333333333333 test_loss: 0.3739079115343902 test_accuracy: 0.8786\n",
      "Iteraions 884: train_loss: 0.15781730247061723 train_accuracy: 0.9376666666666666 test_loss: 0.3828144561908906 test_accuracy: 0.8779\n",
      "Iteraions 885: train_loss: 0.15734533898057373 train_accuracy: 0.9381833333333334 test_loss: 0.3701474946269973 test_accuracy: 0.8778\n",
      "Iteraions 886: train_loss: 0.15853373987702465 train_accuracy: 0.9382333333333334 test_loss: 0.3732993705630324 test_accuracy: 0.8772\n",
      "Iteraions 887: train_loss: 0.1579005833784986 train_accuracy: 0.9376833333333333 test_loss: 0.3774261536298767 test_accuracy: 0.8766\n",
      "Iteraions 888: train_loss: 0.1576361903439385 train_accuracy: 0.9388333333333333 test_loss: 0.3681313636263129 test_accuracy: 0.8771\n",
      "Iteraions 889: train_loss: 0.1580464239325477 train_accuracy: 0.9368833333333333 test_loss: 0.3750364629551797 test_accuracy: 0.8785\n",
      "Iteraions 890: train_loss: 0.15723262736378776 train_accuracy: 0.9372333333333334 test_loss: 0.3655189961527441 test_accuracy: 0.8779\n",
      "Iteraions 891: train_loss: 0.1566402826562026 train_accuracy: 0.9387666666666666 test_loss: 0.38020199571084307 test_accuracy: 0.879\n",
      "Iteraions 892: train_loss: 0.1580272444449561 train_accuracy: 0.9378833333333333 test_loss: 0.3703644083359305 test_accuracy: 0.8767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 893: train_loss: 0.15705253122627819 train_accuracy: 0.93745 test_loss: 0.3698598424948899 test_accuracy: 0.8785\n",
      "Iteraions 894: train_loss: 0.15691953558996646 train_accuracy: 0.9386333333333333 test_loss: 0.3746964805223837 test_accuracy: 0.878\n",
      "Iteraions 895: train_loss: 0.15838731068670064 train_accuracy: 0.9380833333333334 test_loss: 0.3683543192990819 test_accuracy: 0.8779\n",
      "Iteraions 896: train_loss: 0.157843466687165 train_accuracy: 0.9373666666666667 test_loss: 0.37864552697033543 test_accuracy: 0.8782\n",
      "Iteraions 897: train_loss: 0.15769442596728248 train_accuracy: 0.9378333333333333 test_loss: 0.3708533546596935 test_accuracy: 0.878\n",
      "Iteraions 898: train_loss: 0.15816319311625496 train_accuracy: 0.9385666666666667 test_loss: 0.3840790259612197 test_accuracy: 0.8756\n",
      "Iteraions 899: train_loss: 0.15624991651313863 train_accuracy: 0.9391166666666667 test_loss: 0.37803409112617153 test_accuracy: 0.8788\n",
      "Iteraions 900: train_loss: 0.15607509681593176 train_accuracy: 0.9389666666666666 test_loss: 0.3723716110370014 test_accuracy: 0.8775\n",
      "Iteraions 901: train_loss: 0.15371635463785738 train_accuracy: 0.9385666666666667 test_loss: 0.37236164762863566 test_accuracy: 0.8794\n",
      "Iteraions 902: train_loss: 0.15481447993426414 train_accuracy: 0.9401666666666667 test_loss: 0.36830278769621755 test_accuracy: 0.8791\n",
      "Iteraions 903: train_loss: 0.15479578927746418 train_accuracy: 0.9389333333333333 test_loss: 0.37452827182933474 test_accuracy: 0.8776\n",
      "Iteraions 904: train_loss: 0.15683262994765274 train_accuracy: 0.93745 test_loss: 0.35995103595601524 test_accuracy: 0.8805\n",
      "Iteraions 905: train_loss: 0.15495369985921184 train_accuracy: 0.9397 test_loss: 0.38055671223060855 test_accuracy: 0.8744\n",
      "Iteraions 906: train_loss: 0.15556509304122562 train_accuracy: 0.9377833333333333 test_loss: 0.37312215573737 test_accuracy: 0.8805\n",
      "Iteraions 907: train_loss: 0.15381368809514762 train_accuracy: 0.93955 test_loss: 0.3780261376618277 test_accuracy: 0.8795\n",
      "Iteraions 908: train_loss: 0.15540971244215912 train_accuracy: 0.93935 test_loss: 0.37643536589055077 test_accuracy: 0.8761\n",
      "Iteraions 909: train_loss: 0.15431138889261456 train_accuracy: 0.9397 test_loss: 0.36595703533426804 test_accuracy: 0.8792\n",
      "Iteraions 910: train_loss: 0.1557951709284644 train_accuracy: 0.9392333333333334 test_loss: 0.373636121362941 test_accuracy: 0.8762\n",
      "Iteraions 911: train_loss: 0.15495981639377598 train_accuracy: 0.9386666666666666 test_loss: 0.38362888412971285 test_accuracy: 0.8804\n",
      "Iteraions 912: train_loss: 0.15382137820155117 train_accuracy: 0.94015 test_loss: 0.3769784866263093 test_accuracy: 0.874\n",
      "Iteraions 913: train_loss: 0.1531137730090331 train_accuracy: 0.9400333333333334 test_loss: 0.37595006323484775 test_accuracy: 0.8748\n",
      "Iteraions 914: train_loss: 0.15179839415464436 train_accuracy: 0.9393666666666667 test_loss: 0.3728796128577447 test_accuracy: 0.875\n",
      "Iteraions 915: train_loss: 0.15334359442787718 train_accuracy: 0.9394166666666667 test_loss: 0.38489011313179144 test_accuracy: 0.8766\n",
      "Iteraions 916: train_loss: 0.1525279865101098 train_accuracy: 0.9400833333333334 test_loss: 0.3788716779367954 test_accuracy: 0.8755\n",
      "Iteraions 917: train_loss: 0.15423572063664567 train_accuracy: 0.9387666666666666 test_loss: 0.37826162649883394 test_accuracy: 0.8759\n",
      "Iteraions 918: train_loss: 0.1555858862629159 train_accuracy: 0.93845 test_loss: 0.3820310090953068 test_accuracy: 0.8801\n",
      "Iteraions 919: train_loss: 0.1550148053823935 train_accuracy: 0.9390666666666667 test_loss: 0.3848365593508005 test_accuracy: 0.876\n",
      "Iteraions 920: train_loss: 0.1553027537129481 train_accuracy: 0.9391833333333334 test_loss: 0.3759137170738914 test_accuracy: 0.8792\n",
      "Iteraions 921: train_loss: 0.15376607524462385 train_accuracy: 0.9402333333333334 test_loss: 0.364489185763754 test_accuracy: 0.8804\n",
      "Iteraions 922: train_loss: 0.15413541300051103 train_accuracy: 0.94015 test_loss: 0.37331102968961205 test_accuracy: 0.8779\n",
      "Iteraions 923: train_loss: 0.15506400086706876 train_accuracy: 0.9382166666666667 test_loss: 0.38189453351845276 test_accuracy: 0.8739\n",
      "Iteraions 924: train_loss: 0.1539407308342769 train_accuracy: 0.93845 test_loss: 0.3699822243711012 test_accuracy: 0.8778\n",
      "Iteraions 925: train_loss: 0.15470074341854 train_accuracy: 0.9386333333333333 test_loss: 0.38835399746269733 test_accuracy: 0.8749\n",
      "Iteraions 926: train_loss: 0.1513446136903412 train_accuracy: 0.9407 test_loss: 0.3824973520276093 test_accuracy: 0.8741\n",
      "Iteraions 927: train_loss: 0.1513914467730096 train_accuracy: 0.9405666666666667 test_loss: 0.38494361268536614 test_accuracy: 0.8773\n",
      "Iteraions 928: train_loss: 0.15327362702556335 train_accuracy: 0.9392333333333334 test_loss: 0.38154155926626265 test_accuracy: 0.8758\n",
      "Iteraions 929: train_loss: 0.1561837338128891 train_accuracy: 0.9390833333333334 test_loss: 0.38091536608238286 test_accuracy: 0.8769\n",
      "Iteraions 930: train_loss: 0.15337516773880383 train_accuracy: 0.9394 test_loss: 0.3789884257773326 test_accuracy: 0.8764\n",
      "Iteraions 931: train_loss: 0.1505016050281968 train_accuracy: 0.9415166666666667 test_loss: 0.3738442377759551 test_accuracy: 0.8794\n",
      "Iteraions 932: train_loss: 0.1512869684712222 train_accuracy: 0.941 test_loss: 0.3776605547978607 test_accuracy: 0.8781\n",
      "Iteraions 933: train_loss: 0.15054629657145663 train_accuracy: 0.9416833333333333 test_loss: 0.382060564734627 test_accuracy: 0.8777\n",
      "Iteraions 934: train_loss: 0.15386935620392733 train_accuracy: 0.9380833333333334 test_loss: 0.3731476675436672 test_accuracy: 0.8784\n",
      "Iteraions 935: train_loss: 0.15220421669465128 train_accuracy: 0.9409166666666666 test_loss: 0.38253733565339837 test_accuracy: 0.8781\n",
      "Iteraions 936: train_loss: 0.1491770490996664 train_accuracy: 0.9417166666666666 test_loss: 0.37403134448411934 test_accuracy: 0.8783\n",
      "Iteraions 937: train_loss: 0.14983468681077877 train_accuracy: 0.9408 test_loss: 0.3823619486352195 test_accuracy: 0.8801\n",
      "Iteraions 938: train_loss: 0.15136467667093398 train_accuracy: 0.94085 test_loss: 0.37951518678977597 test_accuracy: 0.877\n",
      "Iteraions 939: train_loss: 0.1524286791197501 train_accuracy: 0.94105 test_loss: 0.3734050157814613 test_accuracy: 0.8782\n",
      "Iteraions 940: train_loss: 0.14909788989775552 train_accuracy: 0.94185 test_loss: 0.3676346236739471 test_accuracy: 0.8796\n",
      "Iteraions 941: train_loss: 0.15023902717067922 train_accuracy: 0.9404666666666667 test_loss: 0.37838469215178727 test_accuracy: 0.8775\n",
      "Iteraions 942: train_loss: 0.14884065912928357 train_accuracy: 0.9407166666666666 test_loss: 0.3776507494912434 test_accuracy: 0.8805\n",
      "Iteraions 943: train_loss: 0.1510307736535552 train_accuracy: 0.9399666666666666 test_loss: 0.38841529923757256 test_accuracy: 0.8785\n",
      "Iteraions 944: train_loss: 0.14804968589355003 train_accuracy: 0.9425666666666667 test_loss: 0.3976177448652287 test_accuracy: 0.8782\n",
      "Iteraions 945: train_loss: 0.1479152404322883 train_accuracy: 0.9427333333333333 test_loss: 0.38802387187136844 test_accuracy: 0.8773\n",
      "Iteraions 946: train_loss: 0.1482686958696482 train_accuracy: 0.9416166666666667 test_loss: 0.380927154366627 test_accuracy: 0.8776\n",
      "Iteraions 947: train_loss: 0.14975516791353205 train_accuracy: 0.9420333333333333 test_loss: 0.38373989037806566 test_accuracy: 0.8773\n",
      "Iteraions 948: train_loss: 0.14814202033382196 train_accuracy: 0.9416 test_loss: 0.38278371423238794 test_accuracy: 0.8771\n",
      "Iteraions 949: train_loss: 0.15130963358319804 train_accuracy: 0.9400333333333334 test_loss: 0.38065836253393015 test_accuracy: 0.878\n",
      "Iteraions 950: train_loss: 0.15007436333216054 train_accuracy: 0.9407166666666666 test_loss: 0.3765957270752336 test_accuracy: 0.8763\n",
      "Iteraions 951: train_loss: 0.15011505900580652 train_accuracy: 0.9419 test_loss: 0.39497725132772005 test_accuracy: 0.8754\n",
      "Iteraions 952: train_loss: 0.1488054034081223 train_accuracy: 0.9412333333333334 test_loss: 0.3865308702090147 test_accuracy: 0.8748\n",
      "Iteraions 953: train_loss: 0.14759835005946828 train_accuracy: 0.94245 test_loss: 0.3788465842861011 test_accuracy: 0.8787\n",
      "Iteraions 954: train_loss: 0.14724825794294513 train_accuracy: 0.9426833333333333 test_loss: 0.37609996149707814 test_accuracy: 0.8779\n",
      "Iteraions 955: train_loss: 0.15003962160631792 train_accuracy: 0.9407666666666666 test_loss: 0.3747650097905906 test_accuracy: 0.8767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraions 956: train_loss: 0.14864190604552957 train_accuracy: 0.9418666666666666 test_loss: 0.385183527145515 test_accuracy: 0.8767\n",
      "Iteraions 957: train_loss: 0.14949032035598545 train_accuracy: 0.94165 test_loss: 0.3785443578534366 test_accuracy: 0.8789\n",
      "Iteraions 958: train_loss: 0.14897301262784848 train_accuracy: 0.9414 test_loss: 0.37251830101745387 test_accuracy: 0.8808\n",
      "Iteraions 959: train_loss: 0.1474817716993763 train_accuracy: 0.9410833333333334 test_loss: 0.37598638232833803 test_accuracy: 0.8799\n",
      "Iteraions 960: train_loss: 0.14790303624891782 train_accuracy: 0.942 test_loss: 0.38138958179836363 test_accuracy: 0.8788\n",
      "Iteraions 961: train_loss: 0.14867767863420772 train_accuracy: 0.9421333333333334 test_loss: 0.3819464782371848 test_accuracy: 0.8773\n",
      "Iteraions 962: train_loss: 0.14731766271327615 train_accuracy: 0.9415333333333333 test_loss: 0.38699881214851456 test_accuracy: 0.8772\n",
      "Iteraions 963: train_loss: 0.14604781845167855 train_accuracy: 0.94235 test_loss: 0.3862332416443279 test_accuracy: 0.8785\n",
      "Iteraions 964: train_loss: 0.14523059431293883 train_accuracy: 0.9438 test_loss: 0.38257224790687516 test_accuracy: 0.8772\n",
      "Iteraions 965: train_loss: 0.1480739616948317 train_accuracy: 0.9419166666666666 test_loss: 0.38580695274077337 test_accuracy: 0.8777\n",
      "Iteraions 966: train_loss: 0.14841099908624683 train_accuracy: 0.9409 test_loss: 0.38731805493558485 test_accuracy: 0.8789\n",
      "Iteraions 967: train_loss: 0.144701691714403 train_accuracy: 0.94305 test_loss: 0.3848643313845451 test_accuracy: 0.8794\n",
      "Iteraions 968: train_loss: 0.14523132906470573 train_accuracy: 0.9423833333333334 test_loss: 0.378426619206057 test_accuracy: 0.879\n",
      "Iteraions 969: train_loss: 0.147368077734038 train_accuracy: 0.9416666666666667 test_loss: 0.381808089266627 test_accuracy: 0.8777\n",
      "Iteraions 970: train_loss: 0.14541021145986283 train_accuracy: 0.9429333333333333 test_loss: 0.3774153578862337 test_accuracy: 0.8762\n",
      "Iteraions 971: train_loss: 0.147700368079961 train_accuracy: 0.9425666666666667 test_loss: 0.38265634515713925 test_accuracy: 0.8795\n",
      "Iteraions 972: train_loss: 0.14469641338054656 train_accuracy: 0.9429666666666666 test_loss: 0.38561296578966536 test_accuracy: 0.8769\n",
      "Iteraions 973: train_loss: 0.1426488700585039 train_accuracy: 0.9447333333333333 test_loss: 0.38272878190549336 test_accuracy: 0.879\n",
      "Iteraions 974: train_loss: 0.14432294163334156 train_accuracy: 0.9438 test_loss: 0.3919425950560305 test_accuracy: 0.8791\n",
      "Iteraions 975: train_loss: 0.1456513995619125 train_accuracy: 0.9436166666666667 test_loss: 0.3775085633770163 test_accuracy: 0.8798\n",
      "Iteraions 976: train_loss: 0.14449264137843779 train_accuracy: 0.94375 test_loss: 0.38234876926512545 test_accuracy: 0.8771\n",
      "Iteraions 977: train_loss: 0.14265552740728957 train_accuracy: 0.9437 test_loss: 0.36990970040540316 test_accuracy: 0.8842\n",
      "Iteraions 978: train_loss: 0.14398869348885873 train_accuracy: 0.9441166666666667 test_loss: 0.3820385354160545 test_accuracy: 0.8795\n",
      "Iteraions 979: train_loss: 0.14287251388189928 train_accuracy: 0.9439666666666666 test_loss: 0.3829677222002434 test_accuracy: 0.8792\n",
      "Iteraions 980: train_loss: 0.1455930673961782 train_accuracy: 0.9430333333333333 test_loss: 0.3834046335515095 test_accuracy: 0.879\n",
      "Iteraions 981: train_loss: 0.1445719343619875 train_accuracy: 0.9433333333333334 test_loss: 0.37767200502510534 test_accuracy: 0.8814\n",
      "Iteraions 982: train_loss: 0.14284968492821468 train_accuracy: 0.9455 test_loss: 0.3765882077484814 test_accuracy: 0.8777\n",
      "Iteraions 983: train_loss: 0.14377338489323144 train_accuracy: 0.94355 test_loss: 0.37880764682170887 test_accuracy: 0.8795\n",
      "Iteraions 984: train_loss: 0.1426953616288541 train_accuracy: 0.94495 test_loss: 0.3852798797338356 test_accuracy: 0.8775\n",
      "Iteraions 985: train_loss: 0.1434708290350781 train_accuracy: 0.9437666666666666 test_loss: 0.3849579986680224 test_accuracy: 0.8775\n",
      "Iteraions 986: train_loss: 0.14473397717898467 train_accuracy: 0.9439833333333333 test_loss: 0.3870458808097167 test_accuracy: 0.8772\n",
      "Iteraions 987: train_loss: 0.1427915356252114 train_accuracy: 0.9441166666666667 test_loss: 0.3768273324229793 test_accuracy: 0.8811\n",
      "Iteraions 988: train_loss: 0.14212752491092287 train_accuracy: 0.9442833333333334 test_loss: 0.38234192579754356 test_accuracy: 0.8778\n",
      "Iteraions 989: train_loss: 0.1439782060318858 train_accuracy: 0.9433333333333334 test_loss: 0.38885534287288265 test_accuracy: 0.8739\n",
      "Iteraions 990: train_loss: 0.14283205435706361 train_accuracy: 0.9443666666666667 test_loss: 0.3779426345723525 test_accuracy: 0.8776\n",
      "Iteraions 991: train_loss: 0.1458392869825598 train_accuracy: 0.9422833333333334 test_loss: 0.3928532380923722 test_accuracy: 0.8762\n",
      "Iteraions 992: train_loss: 0.14405349704294643 train_accuracy: 0.9431333333333334 test_loss: 0.3891296807735245 test_accuracy: 0.8773\n",
      "Iteraions 993: train_loss: 0.14389556159404177 train_accuracy: 0.9439166666666666 test_loss: 0.38603621660715115 test_accuracy: 0.8797\n",
      "Iteraions 994: train_loss: 0.14173465419926953 train_accuracy: 0.9444333333333333 test_loss: 0.3775807064123025 test_accuracy: 0.8785\n",
      "Iteraions 995: train_loss: 0.14221164565646321 train_accuracy: 0.9437833333333333 test_loss: 0.38641733912383996 test_accuracy: 0.8795\n",
      "Iteraions 996: train_loss: 0.14220251165409128 train_accuracy: 0.9445833333333333 test_loss: 0.39363308866439417 test_accuracy: 0.8757\n",
      "Iteraions 997: train_loss: 0.14223985397302866 train_accuracy: 0.9442833333333334 test_loss: 0.3905702125369243 test_accuracy: 0.8774\n",
      "Iteraions 998: train_loss: 0.14061070682224183 train_accuracy: 0.9441333333333334 test_loss: 0.3810410644757105 test_accuracy: 0.8781\n",
      "Iteraions 999: train_loss: 0.14070278099804914 train_accuracy: 0.9450166666666666 test_loss: 0.3912809858978757 test_accuracy: 0.8764\n"
     ]
    }
   ],
   "source": [
    "# Call train function and run it for specified number of iterations (max_iterations = 1000)\n",
    "train(tr_x, W1, b1, W2, b2, W3, b3, tr_y, te_x, te_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 405,
     "status": "ok",
     "timestamp": 1616879635979,
     "user": {
      "displayName": "Shankar Pendse",
      "photoUrl": "",
      "userId": "07611606062666259316"
     },
     "user_tz": 0
    },
    "id": "M2AceEpmRrjB",
    "outputId": "220a271c-ac60-4324-f91c-48c368608157"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tr_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 389,
     "status": "ok",
     "timestamp": 1616879662444,
     "user": {
      "displayName": "Shankar Pendse",
      "photoUrl": "",
      "userId": "07611606062666259316"
     },
     "user_tz": 0
    },
    "id": "rZQCKrvAiUxA",
    "outputId": "8babbd08-d230-4053-cd34-c472847cec62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(te_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 495,
     "status": "ok",
     "timestamp": 1616982290525,
     "user": {
      "displayName": "Shankar Pendse",
      "photoUrl": "",
      "userId": "07611606062666259316"
     },
     "user_tz": -60
    },
    "id": "ApTKJ1TviiTG"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "executionInfo": {
     "elapsed": 855,
     "status": "ok",
     "timestamp": 1616982292454,
     "user": {
      "displayName": "Shankar Pendse",
      "photoUrl": "",
      "userId": "07611606062666259316"
     },
     "user_tz": -60
    },
    "id": "5BmT0tmiibOi",
    "outputId": "88f0601c-ce38-4d38-f13f-8b03c6dc7f72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2ceb2cbc8c8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(1000), tr_loss)\n",
    "plt.plot(np.arange(1000), te_loss)\n",
    "plt.title(\"loss\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend(['train', 'val'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "executionInfo": {
     "elapsed": 543,
     "status": "ok",
     "timestamp": 1616982295983,
     "user": {
      "displayName": "Shankar Pendse",
      "photoUrl": "",
      "userId": "07611606062666259316"
     },
     "user_tz": -60
    },
    "id": "UGu8tQN4ivS3",
    "outputId": "3baa63cb-41e7-462a-c3a0-845abab431a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2ceb2d7f548>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(1000), tr_accuracy)\n",
    "plt.plot(np.arange(1000), te_accuracy)\n",
    "plt.title(\"accuracy\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend(['train', 'val'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "executionInfo": {
     "elapsed": 846,
     "status": "ok",
     "timestamp": 1616982300102,
     "user": {
      "displayName": "Shankar Pendse",
      "photoUrl": "",
      "userId": "07611606062666259316"
     },
     "user_tz": -60
    },
    "id": "L32rBWj6i6mA",
    "outputId": "1bbf3d41-dd69-48ea-c90a-b56f2f705c16",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2ceb2e22c08>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(1000), tr_accuracy)\n",
    "plt.plot(np.arange(1000), te_accuracy)\n",
    "plt.plot(np.arange(1000), tr_loss)\n",
    "plt.plot(np.arange(1000), te_loss)\n",
    "plt.title(\"accuracy/loss curves\")\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel(\"accuracy/loss\")\n",
    "plt.legend(['train_accuracy', 'val_accuracy', 'train_loss', 'test_loss'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W8i65jS-nQYg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Question1_2_1.ipynb",
   "provenance": [
    {
     "file_id": "1fk4TzA1Q0y_p9CMtP5qZfJJyVchrG1dy",
     "timestamp": 1616980043819
    },
    {
     "file_id": "1Vl2lVvPZ5groNXo2KikGXkHdAd9omlUC",
     "timestamp": 1616788327203
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
